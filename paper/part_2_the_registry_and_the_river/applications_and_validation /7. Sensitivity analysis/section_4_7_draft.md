## 4.7 Sensitivity analysis

Whereas Sections 4.2 and 4.3 examined how model structure and forcing data affect streamflow and SWE predictions, this experiment examines which parameters — and which hydrological processes — most influence model performance within each structure. Using the five process-based and conceptual models from the Section 4.2 Bow-at-Banff ensemble (FUSE, GR4J, HBV, HYPE, SUMMA), we computed sensitivity indices from the DDS calibration trajectories generated during that experiment. Rather than running a purpose-designed sampling scheme (e.g., Sobol sequences), we exploited the parameter–objective-function pairs already produced by the optimisation iterations — an approach that SYMFLUENCE automates through its `SensitivityAnalyzer` module. Two screening methods were applied: Spearman rank correlation, which is robust to the non-uniform sampling inherent in DDS trajectories, and RBD-FAST (Tissot and Prieur, 2012), a Fourier-based first-order index. RBD-FAST produced reliable indices for four of the five models; for SUMMA, only Spearman correlation passed quality filters due to the narrower parameter search trajectory. Results should therefore be interpreted as exploratory sensitivity screening rather than rigorous variance-based decomposition.

To enable cross-model comparison despite differing parameter sets, each parameter was mapped to one of eight hydrological processes (Snow, Evapotranspiration, Soil Storage, Surface Runoff, Percolation, Baseflow, Groundwater Exchange, and Routing). Per-parameter sensitivity indices were normalised by method, averaged across methods to form an ensemble mean, and then aggregated to the process level by taking the mean sensitivity among parameters belonging to each process. Table XX summarises the models, parameter counts, and available methods.

**Table XX** Models included in the sensitivity screening. *n* denotes the number of calibrated parameters; methods indicates which sensitivity indices passed quality filters.

| Model | *n* | Processes represented | Methods |
|-------|-----|-----------------------|---------|
| FUSE  | 13  | 6 / 8                | Correlation, RBD-FAST |
| GR4J  |  4  | 3 / 8                | Correlation, RBD-FAST |
| HBV   | 14  | 7 / 8                | Correlation, RBD-FAST |
| HYPE  | 10  | 5 / 8                | Correlation, RBD-FAST |
| SUMMA | 11  | 4 / 8                | Correlation           |

### 4.7.1 Process sensitivity

Figure 12 presents the cross-model sensitivity comparison at the hydrological process level. The heatmap (Figure 12a) reports the mean normalised sensitivity index for each process–model combination; hatched cells indicate processes that are absent from a model's parameter set (e.g., GR4J has no explicit Snow or Surface Runoff parameters). The radar chart (Figure 12b) displays the same values as model-specific sensitivity profiles, with line gaps where a process is not represented.

Two processes emerge as consistently sensitive across model structures. Soil Storage ranks among the top three most sensitive processes in all four models that represent it (FUSE: 0.88; SUMMA: 0.84; HBV: 0.73; GR4J: 0.70), reflecting the central role of soil water capacity in partitioning precipitation into fast and slow runoff pathways. Routing is similarly prominent, ranking in the top three for three of five models — and dominating in HYPE (0.89) and SUMMA (0.97), where the routing parameters `damp` and `rivvel` (HYPE) and `routingGammaScale` and `routingGammaShape` (SUMMA) exert strong control on the timing and attenuation of the simulated hydrograph.

Beyond these shared processes, the sensitivity profiles diverge in ways that reflect each model's structural emphasis. FUSE spans six of the eight processes and exhibits uniformly high sensitivity across all of them (range 0.69–0.92), indicating that most of its 13 parameters are actively constrained by the calibration objective. HBV, despite having 14 parameters, shows a wider range (0.36–0.78), with Surface Runoff (0.78) and Soil Storage (0.73) dominating while Routing (0.36) is comparatively insensitive. GR4J, with only four parameters and three represented processes, concentrates its sensitivity on Routing (X3: 1.00) and Groundwater Exchange (X2: 0.85) — consistent with the model's design as a production–routing store framework where each parameter controls a distinct flux pathway.

Snow parameters show moderate but consistent sensitivity in the four models that include them (range 0.54–0.74 at the process level), with model-specific parameters driving the signal: MFMIN (minimum melt factor) in FUSE, sfcf (snowfall correction factor) in HBV, and albedoMinWinter in SUMMA. Evapotranspiration is weakly to moderately sensitive where it appears (HBV: 0.60; HYPE: 0.61; SUMMA: 0.29), suggesting that ET parameters are less tightly constrained by a streamflow-only calibration objective. Percolation, represented only in FUSE (0.69) and HBV (0.58), does not rank among the top processes in either model.

### 4.7.2 Parameter sensitivity

Figure 13 presents the parameter-level detail underlying the process aggregation. Each subplot shows the normalised ensemble-mean sensitivity for every calibrated parameter in one model, with bars coloured by hydrological process.

The most striking feature is the contrast in sensitivity structure between models. FUSE exhibits a relatively flat profile: apart from its two least sensitive parameters (PXTEMP: 0.52; LAPSE: 0.47), all parameters fall within the 0.72–1.00 range, implying that reducing calibration dimensionality by fixing insensitive parameters would be difficult without sacrificing performance. GR4J, at the opposite extreme, shows clear separation: X3 (Routing store capacity: 1.00) and X2 (Groundwater exchange coefficient: 0.87) dominate, while X4 (unit hydrograph time base: 0.34) contributes little — consistent with Perrin et al.'s (2003) finding that GR4J's routing timing parameter is the least identifiable of the four.

HBV displays a graduated pattern. A group of highly sensitive parameters — k0 (fast reservoir coefficient: 1.00), sfcf (snowfall correction: 0.99), tt (threshold temperature: 0.90), fc (field capacity: 0.85) — contrasts with a lower-sensitivity group including cwh (water holding capacity: 0.38), maxbas (routing base: 0.38), and cfmax (degree-day factor: 0.60). The insensitivity of maxbas is notable given that Routing is a dominant process in other models; it suggests that HBV's triangular unit hydrograph parameterisation provides limited flexibility compared to the gamma-function routing used by SUMMA or the delay-based routing in FUSE.

HYPE's sensitivity is concentrated in its two Routing parameters — damp (1.00) and rivvel (0.90) — which together account for the model's high process-level Routing score. The remaining parameters are moderately sensitive (cevp: 0.67; lp: 0.62; ttmp: 0.62) to low (cmlt, snowmelt coefficient: 0.44; rcgrw, groundwater recharge: 0.47), indicating that HYPE's streamflow simulation at this site is primarily controlled by the translation and attenuation of runoff rather than by its generation.

SUMMA shows high sensitivity for most parameters (7 of 11 above 0.93), but with a clear separation between the top tier — albedoMinWinter (1.00), routingGammaScale (0.98), Fcapil (0.97) — and the lower tier — k_soil (0.40), albedoMax (0.29), critSoilWilting (0.29). The low sensitivity of albedoMax relative to albedoMinWinter suggests that winter albedo, which governs early-season snowmelt onset, is more influential than the fresh-snow albedo ceiling for this mid-latitude site.

### 4.7.3 Framework implications

Three aspects of these results are relevant to SYMFLUENCE's design objectives.

First, the sensitivity screening was conducted entirely from existing calibration outputs, requiring no additional model runs. SYMFLUENCE's `SensitivityAnalyzer` reads the iteration-results CSV files produced during DDS calibration, computes multiple sensitivity indices, applies quality filters (e.g., rejecting VISCOUS estimates when copula fitting fails), and writes standardised output tables. For the five-model ensemble analysed here, the full screening — from data ingestion through process-aggregated comparison — executed in under two minutes. This reuse of calibration data makes sensitivity screening a low-cost addition to any calibration workflow, rather than a separate, computationally expensive experiment.

Second, the cross-model process mapping enables a form of structural sensitivity analysis that goes beyond single-model parameter screening. By grouping parameters into hydrological processes, the framework reveals that Soil Storage and Routing are consistently influential regardless of how those processes are parameterised — a finding that would not emerge from analysing any single model in isolation. This process-level perspective complements the structural uncertainty quantification from Section 4.2, where models diverged most during evaluation periods: the processes identified as most sensitive here (storage, routing) correspond to the flux pathways where models showed the greatest inter-model spread in the hydrograph comparison (Section 4.2.1).

Third, the parameter-level results provide practical guidance for calibration efficiency. In HBV, fixing the four least sensitive parameters (cwh, maxbas, cfmax, uzl) at their default values would reduce the calibration from 14 to 10 dimensions with minimal expected impact on KGE. In SUMMA, the three least sensitive parameters (k_soil, albedoMax, critSoilWilting) could similarly be fixed, reducing dimensionality from 11 to 8. GR4J's four-parameter structure already represents a near-minimal set, as three of its four parameters show high sensitivity. These reductions could accelerate DDS convergence in subsequent calibration experiments — a practical benefit enabled by SYMFLUENCE's integration of sensitivity screening into its standard analysis pipeline.
