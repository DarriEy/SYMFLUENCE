## 4.2 Multi-Model Ensemble Streamflow Simulation

### Overview

A central design objective of SYMFLUENCE is enabling researchers to deploy and compare multiple hydrological models within a single, reproducible workflow. To demonstrate this capability, we configured an ensemble of ten structurally diverse models for the Bow River at Banff lumped catchment (drainage area ~2,210 km²) using near-identical YAML configuration files. Each model was calibrated against observed streamflow using the Dynamically Dimensioned Search (DDS) algorithm over the period 2003–2005, with an independent evaluation period of 2006–2009. Six of the ten models achieved a calibration Kling-Gupta Efficiency (KGE; Gupta et al., 2009) exceeding 0.5 and are retained for the ensemble analysis presented here. The remaining four models (VIC, RHESSys, MESH, and ngen) are excluded as their implementations within SYMFLUENCE are still under active development, resulting in poor calibration performance.

### Included Models

**SUMMA** (Clark et al., 2015) is a flexible, multi-physics framework that allows users to select among alternative process representations; here it was configured with 11 calibrated parameters governing snow, soil, and routing processes (calibration KGE = 0.90). **FUSE** (Clark et al., 2008) provides a framework for combining modular model components into unique hydrological model structures; 13 parameters were calibrated, yielding a calibration KGE of 0.90. **GR4J** (Perrin et al., 2003) is a parsimonious four-parameter lumped conceptual model that nonetheless achieved the highest calibration KGE in the ensemble (0.92). **HBV** (Bergström, 1995) is a widely used semi-distributed conceptual model with 15 calibrated parameters; its calibration KGE of 0.74 was the lowest among the included models, reflecting a persistent low-flow bias (β = 0.75). **HYPE** (Lindström et al., 2010) is a semi-distributed process-based model with 10 calibrated parameters, achieving a calibration KGE of 0.87. **LSTM** (Hochreiter & Schmidhuber, 1997), a long short-term memory neural network trained on the same forcing and streamflow data, achieved the highest calibration KGE of all models (0.97), illustrating the potential of data-driven approaches within a unified modelling framework.

### Ensemble Performance

Figure A presents the multi-model hydrograph for the full simulation period (2004–2009), with a zoomed panel highlighting the April–October 2005 snowmelt season. All six models capture the dominant seasonal cycle of the Bow River, which is characterised by low winter baseflow (5–15 m³ s⁻¹) and a pronounced snowmelt-driven peak in June–July (100–300 m³ s⁻¹). During the calibration period (2003–2005), model outputs are tightly clustered around the observed hydrograph, consistent with the high KGE values achieved during optimisation. During the evaluation period (2006–2009), the ensemble spread widens, particularly around peak flows. This divergence is expected: each model's structural assumptions about snowmelt, soil moisture partitioning, and recession behaviour lead to differing extrapolations when forced outside calibration conditions.

The KGE decomposition (Figure B) reveals instructive differences among models. All six models maintain high correlation (*r* > 0.87) in both periods, indicating that the timing of hydrological events is well represented. The primary source of performance variation lies in the variability ratio (α) and bias ratio (β). During evaluation, GR4J exhibits the largest positive α deviation (α = 1.15), overestimating flow variability, alongside a positive bias (β = 1.12). HBV shows the opposite pattern, with persistent underestimation of mean flow (β = 0.81 in evaluation), likely reflecting its simplified snow routine in this high-alpine catchment. SUMMA and FUSE, sharing similar internal process representations via the SUMMA/mizuRoute modelling chain, produce nearly identical results (evaluation KGE = 0.88 for both), confirming consistency in the SYMFLUENCE workflow. The LSTM maintains excellent evaluation performance (KGE = 0.88) with well-balanced components, though its lack of physical interpretability limits diagnostic insight.

### Ensemble Envelope and Flow Duration Curve

Figure C shows the ensemble envelope (min–max range across all six models) for the evaluation period alongside observed streamflow, the ensemble mean, and the ensemble median. The observed hydrograph falls within the ensemble envelope for the vast majority of the evaluation period, with notable exceptions during the largest peak events where the ensemble tends to underestimate extreme flows. Over the full common period, the ensemble mean achieves a KGE of 0.94 and the ensemble median a KGE of 0.92 — both exceeding every individual model's full-period performance. This is a well-known advantage of multi-model averaging that arises from the cancellation of offsetting structural biases (Ajami et al., 2006; Arsenault et al., 2015).

The flow duration curve (FDC) comparison provides additional insight into model behaviour across the discharge spectrum. At high exceedance probabilities (low flows, >80%), models diverge most, with HBV systematically underestimating low flows and HYPE overestimating them. At intermediate exceedance probabilities (20–80%), all models cluster closely around the observed FDC. The ensemble mean tracks the observed FDC more faithfully than any individual model across the full range, reinforcing the value of multi-model combination.

### Framework Implications

The results demonstrate that SYMFLUENCE can orchestrate six structurally distinct models — spanning conceptual (GR4J, HBV), process-based (SUMMA, FUSE, HYPE), and data-driven (LSTM) paradigms — from a common configuration layer. Each model was set up using the same domain definition, forcing data, observation targets, and calibration algorithm, with model-specific parameters specified in a single YAML configuration file. This uniformity reduces methodological confounds when comparing model structures and lowers the barrier to entry for multi-model studies. The automatic evaluation pipeline produces standardised JSON metric files with consistent KGE component breakdowns, enabling programmatic analysis across models without manual post-processing.

The ensemble spread observed here — modest during calibration and widening during evaluation — is consistent with the structural uncertainty literature (Clark et al., 2011) and underscores the importance of multi-model approaches for uncertainty quantification in operational forecasting. SYMFLUENCE's modular architecture makes it straightforward to extend this ensemble as additional model implementations mature (e.g., VIC, MESH, ngen) or as new models are integrated into the framework.
