"""
SYMFLUENCE Core System Module.

Provides the main SYMFLUENCE class that serves as the primary entry point
for hydrological modeling workflows. This module coordinates all manager
components and orchestrates the complete modeling pipeline from domain
definition through model calibration and analysis.

Example:
    >>> from symfluence import SYMFLUENCE
    >>> s = SYMFLUENCE("config.yaml")
    >>> s.run_workflow()
"""
try:
    from symfluence.symfluence_version import __version__
except ImportError:
    __version__ = "0+unknown"


from pathlib import Path
from datetime import datetime
from typing import Dict, Any, List, Union, Optional

from symfluence.core.mixins.project import resolve_data_subdir
from symfluence.core.exceptions import SYMFLUENCEError

# Import core components
from symfluence.project.workflow_orchestrator import WorkflowOrchestrator
from symfluence.project.logging_manager import LoggingManager
from symfluence.project.manager_factory import LazyManagerDict
from symfluence.core.config.models import SymfluenceConfig
from symfluence.core.provenance import capture_provenance, finalize as finalize_provenance


class SYMFLUENCE:
    """
    Enhanced SYMFLUENCE main class with comprehensive CLI support.

    This class serves as the central coordinator for all SYMFLUENCE operations,
    with enhanced CLI capabilities including individual step execution,
    pour point setup, SLURM job submission, and comprehensive workflow management.
    """

    def __init__(self, config_input: Union[Path, str, SymfluenceConfig], config_overrides: Dict[str, Any] = None, debug_mode: bool = False, visualize: bool = False, diagnostic: bool = False):
        """
        Initialize the SYMFLUENCE system with configuration and CLI options.

        Args:
            config_input: Path to the configuration file or a SymfluenceConfig instance
            config_overrides: Dictionary of configuration overrides from CLI
            debug_mode: Whether to enable debug mode
            visualize: Whether to enable visualization
            diagnostic: Whether to enable diagnostic plots for workflow validation
        """
        self.debug_mode = debug_mode
        self.visualize = visualize
        self.diagnostic = diagnostic
        self.config_overrides = config_overrides or {}

        # Handle different config input types
        if isinstance(config_input, SymfluenceConfig):
            self.typed_config = config_input
            # If overrides provided, we merge them into a flat dict and re-create the model
            if self.config_overrides:
                flat_config = self.typed_config.to_dict(flatten=True)
                flat_config.update(self.config_overrides)
                self.typed_config = SymfluenceConfig(**flat_config)
            self.config_path = getattr(config_input, '_source_file', None)
        else:
            self.config_path = Path(config_input)
            self.typed_config = self._load_typed_config()

        self.config = self.typed_config.to_dict(flatten=True)  # Backward compatibility

        # Ensure log level consistency with debug mode
        if self.debug_mode:
            self.config['LOG_LEVEL'] = 'DEBUG'

        # Initialize logging
        self.logging_manager = LoggingManager(self.config, debug_mode=debug_mode)
        self.logger = self.logging_manager.logger

        self.logger.info("SYMFLUENCE initialized")
        if self.config_path:
            self.logger.info(f"Config path: {self.config_path}")
        if self.config_overrides:
            self.logger.info(f"Configuration overrides applied: {list(self.config_overrides.keys())}")


        # Capture provenance metadata
        self.provenance = capture_provenance(
            experiment_id=getattr(self.typed_config.domain, 'experiment_id', 'unknown') or 'unknown',
            domain_name=getattr(self.typed_config.domain, 'name', 'unknown') or 'unknown',
            config_path=str(self.config_path) if self.config_path else None,
        )

        # Initialize managers (lazy loaded)
        self.managers = LazyManagerDict(self.typed_config, self.logger, self.visualize, self.diagnostic)

        # Initialize workflow orchestrator
        self.workflow_orchestrator = WorkflowOrchestrator(
            self.managers, self.typed_config, self.logger, self.logging_manager,
            provenance=self.provenance,
        )


    def _load_typed_config(self) -> SymfluenceConfig:
        """
        Load configuration using new hierarchical SymfluenceConfig.

        Returns:
            SymfluenceConfig: Fully validated hierarchical configuration
        """
        try:
            return SymfluenceConfig.from_file(
                self.config_path,
                overrides=self.config_overrides,
                use_env=True,
                validate=True
            )
        except FileNotFoundError:
            raise FileNotFoundError(f"Configuration file not found: {self.config_path}")

    def run_workflow(self, force_run: Optional[bool] = None) -> None:
        """Execute the complete SYMFLUENCE workflow (CLI wrapper)."""
        start = datetime.now()
        steps_completed: List[Any] = []
        errors: List[Any] = []
        warns: List[Any] = []

        try:
            self.logger.info("Starting complete SYMFLUENCE workflow execution")

            # Determine force-run behavior (CLI override beats config)
            if force_run is None:
                force_run = getattr(self.typed_config.system, "force_run_all_steps", False)

            # Run the workflow
            self.workflow_orchestrator.run_workflow(force_run=force_run)

            # Collect status information
            status_info = self.workflow_orchestrator.get_workflow_status()
            steps_completed = [s for s in status_info['step_details'] if s['complete']]
            status = "completed" if status_info['total_steps'] == status_info['completed_steps'] else "partial"

            self.logger.info("Complete SYMFLUENCE workflow execution completed")

        except (SYMFLUENCEError, FileNotFoundError, PermissionError, ValueError, RuntimeError) as e:
            status = "failed"
            errors.append({"where": "run_workflow", "error": str(e)})
            self.logger.error(f"Workflow execution failed: {e}")
            # re-raise after summary so the CI can fail meaningfully if needed
            raise
        except Exception as e:
            status = "failed"
            errors.append({"where": "run_workflow", "error": str(e)})
            self.logger.exception(f"Unexpected workflow execution failure: {e}")
            raise
        finally:
            end = datetime.now()
            elapsed_s = (end - start).total_seconds()
            # Call with the expected signature:
            self.logging_manager.create_run_summary(
                steps_completed=steps_completed,
                errors=errors,
                warnings=warns,
                execution_time=elapsed_s,
                status=status,
            )
            # Write provenance manifest
            finalize_provenance(self.provenance, status,
                                errors=[e.get("error", str(e)) for e in errors] if errors else None)
            manifest = self.provenance.write(self.logging_manager.log_dir)
            self.logger.info(f"Run manifest written to: {manifest}")

    def run_individual_steps(self, step_names: List[str]) -> None:
        """
        Execute specific workflow steps by name.

        Allows selective execution of individual workflow steps rather than
        running the complete pipeline. Useful for debugging, testing, or
        re-running specific portions of the workflow.

        Args:
            step_names: List of step names to execute (e.g., ['setup_project', 'calibrate_model'])
        """
        start = datetime.now()
        steps_completed: List[Any] = []
        errors: List[Any] = []
        warns: List[Any] = []

        status = "completed"

        try:
            continue_on_error = self.config_overrides.get("continue_on_error", False)

            # Execute individual steps via orchestrator
            results = self.workflow_orchestrator.run_individual_steps(step_names, continue_on_error)

            # Process results for summary
            for res in results:
                if res['success']:
                    steps_completed.append({"cli": res['cli'], "fn": res['fn']})
                else:
                    errors.append({"step": res['cli'], "error": res['error']})
                    status = "partial" if steps_completed else "failed"

        finally:
            end = datetime.now()
            elapsed_s = (end - start).total_seconds()
            self.logging_manager.create_run_summary(
                steps_completed=steps_completed,
                errors=errors,
                warnings=warns,
                execution_time=elapsed_s,
                status=status,
            )
            # Write provenance manifest
            finalize_provenance(self.provenance, status,
                                errors=[e.get("error", str(e)) for e in errors] if errors else None)
            manifest = self.provenance.write(self.logging_manager.log_dir)
            self.logger.info(f"Run manifest written to: {manifest}")

    def get_workflow_status(self) -> Dict[str, Any]:
        """
        Return workflow completion status from the orchestrator.

        Returns:
            Dict[str, Any]: Workflow status payload with step_details and counts.
        """
        return self.workflow_orchestrator.get_workflow_status()

    def run_diagnostics_for_step(self, step_name: str) -> List[str]:
        """
        Run diagnostic plots for a specific workflow step on existing outputs.

        This method loads existing workflow outputs from the project directory
        and generates diagnostic plots without re-running the workflow step.

        Args:
            step_name: Name of the workflow step to diagnose

        Returns:
            List of paths to generated diagnostic plots
        """
        self.logger.info(f"Running diagnostics for step: {step_name}")
        results: List[str] = []

        # Get the reporting manager
        reporting_manager = self.managers.get('reporting')
        if not reporting_manager:
            self.logger.warning("Reporting manager not available")
            return results

        # Map workflow steps to their diagnostic methods and required data
        step_diagnostics = self._get_step_diagnostic_mapping()

        if step_name not in step_diagnostics:
            self.logger.warning(f"No diagnostic available for step: {step_name}")
            return results

        diagnostic_info = step_diagnostics[step_name]
        try:
            result = diagnostic_info['func'](reporting_manager)
            if result:
                results.append(result)
        except (SYMFLUENCEError, FileNotFoundError, PermissionError, ValueError, RuntimeError) as e:
            self.logger.error(f"Failed to generate diagnostic for {step_name}: {e}")
        except Exception as e:
            self.logger.exception(f"Unexpected diagnostic failure for {step_name}: {e}")

        return results

    def run_all_diagnostics(self) -> List[str]:
        """
        Run all available diagnostic plots on existing workflow outputs.

        This method iterates through all workflow steps and generates diagnostic
        plots for any step that has existing outputs in the project directory.

        Returns:
            List of paths to generated diagnostic plots
        """
        self.logger.info("Running all available diagnostics...")
        results = []

        step_diagnostics = self._get_step_diagnostic_mapping()

        for step_name, diagnostic_info in step_diagnostics.items():
            self.logger.debug(f"Checking diagnostics for: {step_name}")
            try:
                reporting_manager = self.managers.get('reporting')
                if reporting_manager:
                    result = diagnostic_info['func'](reporting_manager)
                    if result:
                        results.append(result)
                        self.logger.info(f"Generated diagnostic for {step_name}: {result}")
            except (SYMFLUENCEError, FileNotFoundError, PermissionError, ValueError, RuntimeError) as e:
                self.logger.debug(f"Skipping {step_name} diagnostic: {e}")
            except Exception as e:
                self.logger.exception(f"Unexpected diagnostic failure for {step_name}: {e}")

        self.logger.info(f"Generated {len(results)} diagnostic plot(s)")
        return results

    def _get_step_diagnostic_mapping(self) -> Dict[str, Dict[str, Any]]:
        """
        Get mapping of workflow steps to their diagnostic functions.

        Returns:
            Dictionary mapping step names to diagnostic info
        """
        from pathlib import Path
        import geopandas as gpd
        import pandas as pd

        config = self.typed_config
        project_dir = Path(config.paths.root_path) / f"domain_{config.domain.name}"

        def _load_domain_diagnostic(rm):
            """Load data and run domain definition diagnostic."""
            basin_path = project_dir / "shapefiles" / "river_basins" / "river_basins.shp"
            dem_path = resolve_data_subdir(project_dir, 'attributes') / "dem" / "dem.tif"
            if not basin_path.exists():
                return None
            basin_gdf = gpd.read_file(basin_path)
            return rm.workflow_diagnostic_plotter.plot_domain_definition_diagnostic(
                basin_gdf=basin_gdf,
                dem_path=dem_path if dem_path.exists() else None
            )

        def _load_discretization_diagnostic(rm):
            """Load data and run discretization diagnostic."""
            hru_path = project_dir / "shapefiles" / "catchment" / "catchment.shp"
            if not hru_path.exists():
                return None
            hru_gdf = gpd.read_file(hru_path)
            method = getattr(config.discretization, 'method', 'unknown')
            return rm.workflow_diagnostic_plotter.plot_discretization_diagnostic(
                hru_gdf=hru_gdf,
                method=method
            )

        def _load_observations_diagnostic(rm):
            """Load data and run observations diagnostic."""
            obs_path = resolve_data_subdir(project_dir, 'observations') / "streamflow" / "preprocessed" / "streamflow_obs.csv"
            if not obs_path.exists():
                return None
            obs_df = pd.read_csv(obs_path, parse_dates=['datetime'], index_col='datetime')
            return rm.workflow_diagnostic_plotter.plot_observations_diagnostic(
                obs_df=obs_df,
                obs_type='streamflow'
            )

        def _load_forcing_raw_diagnostic(rm):
            """Load data and run raw forcing diagnostic."""
            forcing_dir = resolve_data_subdir(project_dir, 'forcing') / "raw_data"
            if not forcing_dir.exists():
                return None
            nc_files = list(forcing_dir.glob("*.nc"))
            if not nc_files:
                return None
            domain_shp = project_dir / "shapefiles" / "river_basins" / "river_basins.shp"
            return rm.workflow_diagnostic_plotter.plot_forcing_raw_diagnostic(
                forcing_nc=nc_files[0],
                domain_shp=domain_shp if domain_shp.exists() else None
            )

        def _load_forcing_remapped_diagnostic(rm):
            """Load data and run forcing remapped diagnostic."""
            raw_dir = resolve_data_subdir(project_dir, 'forcing') / "raw_data"
            remapped_dir = resolve_data_subdir(project_dir, 'forcing') / "basin_averaged_data"
            if not raw_dir.exists() or not remapped_dir.exists():
                return None
            raw_files = list(raw_dir.glob("*.nc"))
            remapped_files = list(remapped_dir.glob("*.nc"))
            if not raw_files or not remapped_files:
                return None
            hru_shp = project_dir / "shapefiles" / "catchment" / "catchment.shp"
            return rm.workflow_diagnostic_plotter.plot_forcing_remapped_diagnostic(
                raw_nc=raw_files[0],
                remapped_nc=remapped_files[0],
                hru_shp=hru_shp if hru_shp.exists() else None
            )

        def _load_model_preprocessing_diagnostic(rm):
            """Load data and run model preprocessing diagnostic."""
            model_name = getattr(config.model, 'name', 'SUMMA')
            input_dir = project_dir / "simulations" / model_name.lower() / "run_settings"
            if not input_dir.exists():
                return None
            return rm.workflow_diagnostic_plotter.plot_model_preprocessing_diagnostic(
                input_dir=input_dir,
                model_name=model_name
            )

        def _load_model_output_diagnostic(rm):
            """Load data and run model output diagnostic."""
            model_name = getattr(config.model, 'name', 'SUMMA')
            output_dir = project_dir / "simulations" / model_name.lower() / "output"
            if not output_dir.exists():
                return None
            nc_files = list(output_dir.glob("*.nc"))
            if not nc_files:
                return None
            return rm.workflow_diagnostic_plotter.plot_model_output_diagnostic(
                output_nc=nc_files[0],
                model_name=model_name
            )

        def _load_attributes_diagnostic(rm):
            """Load data and run attributes diagnostic."""
            dem_path = resolve_data_subdir(project_dir, 'attributes') / "dem" / "dem.tif"
            soil_path = resolve_data_subdir(project_dir, 'attributes') / "soilclass" / "soilclass.tif"
            land_path = resolve_data_subdir(project_dir, 'attributes') / "landclass" / "landclass.tif"
            if not any(p.exists() for p in [dem_path, soil_path, land_path]):
                return None
            return rm.workflow_diagnostic_plotter.plot_attributes_diagnostic(
                dem_path=dem_path if dem_path.exists() else None,
                soil_path=soil_path if soil_path.exists() else None,
                land_path=land_path if land_path.exists() else None
            )

        def _load_calibration_diagnostic(rm):
            """Load data and run calibration diagnostic."""
            model_name = getattr(config.model, 'name', 'SUMMA')
            calib_dir = project_dir / "simulations" / model_name.lower() / "calibration"
            if not calib_dir.exists():
                return None
            # Look for calibration history file
            history_file = calib_dir / "calibration_history.csv"
            if not history_file.exists():
                return None
            history_df = pd.read_csv(history_file)
            history = history_df.to_dict('records')
            return rm.workflow_diagnostic_plotter.plot_calibration_diagnostic(
                history=history,
                model_name=model_name
            )

        return {
            'define_domain': {'func': _load_domain_diagnostic},
            'discretize_domain': {'func': _load_discretization_diagnostic},
            'process_observed_data': {'func': _load_observations_diagnostic},
            'acquire_forcings': {'func': _load_forcing_raw_diagnostic},
            'model_agnostic_preprocessing': {'func': _load_forcing_remapped_diagnostic},
            'model_specific_preprocessing': {'func': _load_model_preprocessing_diagnostic},
            'run_model': {'func': _load_model_output_diagnostic},
            'acquire_attributes': {'func': _load_attributes_diagnostic},
            'calibrate_model': {'func': _load_calibration_diagnostic},
        }
