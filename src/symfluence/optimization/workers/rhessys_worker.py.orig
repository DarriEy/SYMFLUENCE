"""
RHESSys Worker

Worker implementation for RHESSys model optimization.
"""

import logging
import os
import subprocess
import sys
import pandas as pd
import numpy as np
from pathlib import Path
from typing import Dict, Any, Optional
import shutil

from .base_worker import BaseWorker, WorkerTask, WorkerResult
from ..registry import OptimizerRegistry
from symfluence.evaluation.utilities import StreamflowMetrics
from symfluence.core.constants import ModelDefaults


@OptimizerRegistry.register_worker('RHESSys')
class RHESSysWorker(BaseWorker):
    """
    Worker for RHESSys model calibration.

    Handles parameter application, RHESSys execution, and metric calculation.
    """

    def __init__(
        self,
        config: Optional[Dict[str, Any]] = None,
        logger: Optional[logging.Logger] = None
    ):
        """
        Initialize RHESSys worker.

        Args:
            config: Configuration dictionary
            logger: Logger instance
        """
        super().__init__(config, logger)

    # Shared utilities
    _streamflow_metrics = StreamflowMetrics()

    def apply_parameters(
        self,
        params: Dict[str, float],
        settings_dir: Path,
        **kwargs
    ) -> bool:
        """
        Apply parameters to RHESSys definition files.

        Args:
            params: Parameter values to apply
            settings_dir: RHESSys settings directory (contains defs/ subdirectory)
            **kwargs: Additional arguments

        Returns:
            True if successful
        """
        try:
            from symfluence.optimization.parameter_managers.rhessys_parameter_manager import RHESSysParameterManager

            # The settings_dir should contain a 'defs' subdirectory
            defs_dir = settings_dir / 'defs'
            if not defs_dir.exists():
                self.logger.error(f"defs directory not found: {defs_dir}")
                return False

            # Update definition files with new parameters
            return self._update_def_files(defs_dir, params)

        except Exception as e:
            self.logger.error(f"Error applying RHESSys parameters: {e}")
            return False

    def _update_def_files(self, defs_dir: Path, params: Dict[str, float]) -> bool:
        """
        Update RHESSys definition files with new parameter values.

        Args:
            defs_dir: Path to defs directory
            params: Parameters to update

        Returns:
            True if successful
        """
        import re

        # Mapping from parameter names to definition files
        PARAM_FILE_MAP = {
            'sat_to_gw_coeff': 'basin.def',
            'gw_loss_coeff': 'basin.def',
            'n_routing_power': 'basin.def',
            'psi_air_entry': 'basin.def',
            'pore_size_index': 'basin.def',
            'porosity_0': 'soil.def',
            'porosity_decay': 'soil.def',
            'Ksat_0': 'soil.def',
            'Ksat_0_v': 'soil.def',
            'm': 'soil.def',
            'm_z': 'soil.def',
            'soil_depth': 'soil.def',
            'active_zone_z': 'soil.def',
            'snow_melt_Tcoef': 'soil.def',
            'maximum_snow_energy_deficit': 'soil.def',
            'max_snow_temp': 'zone.def',
            'min_rain_temp': 'zone.def',
            'epc.max_lai': 'stratum.def',
            'epc.gl_smax': 'stratum.def',
            'epc.gl_c': 'stratum.def',
            'epc.vpd_open': 'stratum.def',
            'epc.vpd_close': 'stratum.def',
        }

        # Group parameters by file
        params_by_file: Dict[str, Dict[str, float]] = {}
        for param_name, value in params.items():
            def_file_name = PARAM_FILE_MAP.get(param_name)
            if def_file_name:
                if def_file_name not in params_by_file:
                    params_by_file[def_file_name] = {}
                params_by_file[def_file_name][param_name] = value

        # Update each file
        for def_file_name, file_params in params_by_file.items():
            def_file = defs_dir / def_file_name
            if not def_file.exists():
                self.logger.warning(f"Definition file not found: {def_file}")
                continue

            with open(def_file, 'r') as f:
                lines = f.readlines()

            updated_lines = []
            for line in lines:
                updated = False
                for param_name, value in file_params.items():
                    # Match: value<whitespace>param_name
                    pattern = rf'^([\d\.\-\+eE]+)(\s+)({re.escape(param_name)})(\s*)$'
                    match = re.match(pattern, line)
                    if match:
                        new_line = f"{value:.6f}{match.group(2)}{match.group(3)}{match.group(4)}"
                        updated_lines.append(new_line)
                        updated = True
                        break
                if not updated:
                    updated_lines.append(line)

            with open(def_file, 'w') as f:
                f.writelines(updated_lines)

        return True

    def run_model(
        self,
        config: Dict[str, Any],
        settings_dir: Path,
        output_dir: Path,
        **kwargs
    ) -> bool:
        """
        Run RHESSys model.

        Args:
            config: Configuration dictionary
            settings_dir: RHESSys settings directory
            output_dir: Output directory
            **kwargs: Additional arguments (sim_dir, proc_id)

        Returns:
            True if model ran successfully
        """
        try:
            # Get paths
            domain_name = config.get('DOMAIN_NAME')
            data_dir = Path(config.get('SYMFLUENCE_DATA_DIR', '.'))
            project_dir = data_dir / f'domain_{domain_name}'
            rhessys_input_dir = project_dir / 'RHESSys_input'

            # Use sim_dir for output if provided
            rhessys_output_dir = Path(kwargs.get('sim_dir', output_dir))
            rhessys_output_dir.mkdir(parents=True, exist_ok=True)

            # Get executable
            rhessys_exe = self._get_rhessys_executable(config, data_dir)
            if not rhessys_exe.exists():
                self.logger.error(f"RHESSys executable not found: {rhessys_exe}")
                return False

            # Build command
            cmd = self._build_command(
                rhessys_exe,
                config,
                rhessys_input_dir,
                settings_dir,
                rhessys_output_dir
            )

            # Set library path for WMFire
            env = os.environ.copy()
            lib_paths = []
            rhessys_bin_dir = rhessys_exe.parent
            wmfire_lib_dir = data_dir / "installs" / "wmfire" / "lib"

            for lib_dir in [rhessys_bin_dir, wmfire_lib_dir]:
                if lib_dir.exists():
                    lib_paths.append(str(lib_dir))

            if lib_paths:
                lib_path_str = ":".join(lib_paths)
                if sys.platform == "darwin":
                    env["DYLD_LIBRARY_PATH"] = f"{lib_path_str}:{env.get('DYLD_LIBRARY_PATH', '')}"
                else:
                    env["LD_LIBRARY_PATH"] = f"{lib_path_str}:{env.get('LD_LIBRARY_PATH', '')}"

            # Run RHESSys
            result = subprocess.run(
                cmd,
                cwd=str(rhessys_output_dir),
                env=env,
                capture_output=True,
                text=True,
                timeout=config.get('RHESSYS_TIMEOUT', 3600)
            )

            if result.returncode != 0:
                self._last_error = f"RHESSys failed: {result.stderr[-500:]}"
                self.logger.error(self._last_error)
                return False

            # Verify output exists
            output_file = rhessys_output_dir / 'rhessys_basin.daily'
            if not output_file.exists():
                self._last_error = "No basin output file produced"
                return False

            return True

        except Exception as e:
            self._last_error = str(e)
            self.logger.error(f"Error running RHESSys: {e}")
            return False

    def _get_rhessys_executable(self, config: Dict[str, Any], data_dir: Path) -> Path:
        """Get RHESSys executable path."""
        install_path = config.get('RHESSYS_INSTALL_PATH', 'default')
        exe_name = config.get('RHESSYS_EXE', 'rhessys')
        if install_path == 'default':
            return data_dir / "installs" / "rhessys" / "bin" / exe_name
        # If install_path is a directory, append exe_name
        install_path = Path(install_path)
        if install_path.is_dir():
            return install_path / exe_name
        # If it's already a full path to executable
        return install_path

    def _build_command(
        self,
        exe: Path,
        config: Dict[str, Any],
        rhessys_input_dir: Path,
        settings_dir: Path,
        output_dir: Path
    ) -> list:
        """Build RHESSys command line."""
        domain_name = config.get('DOMAIN_NAME')

        # Use worker-specific defs directory if available
        worker_defs_dir = settings_dir / 'defs'
        if worker_defs_dir.exists():
            # Create a temporary world header pointing to worker defs
            world_hdr = rhessys_input_dir / 'worldfiles' / f'{domain_name}.world.hdr'
            worker_hdr = settings_dir / f'{domain_name}.world.hdr'
            if world_hdr.exists() and not worker_hdr.exists():
                # Copy and modify header to point to worker defs
                self._create_worker_header(world_hdr, worker_hdr, worker_defs_dir, rhessys_input_dir)

        # Parse dates
        start_str = config.get('EXPERIMENT_TIME_START', '2004-01-01 01:00')
        end_str = config.get('EXPERIMENT_TIME_END', '2004-12-31 23:00')
        start_date = pd.to_datetime(start_str)
        end_date = pd.to_datetime(end_str)

        # Build command
        worldfile = rhessys_input_dir / 'worldfiles' / f'{domain_name}.world'
        world_hdr = settings_dir / f'{domain_name}.world.hdr'
        if not world_hdr.exists():
            world_hdr = rhessys_input_dir / 'worldfiles' / f'{domain_name}.world.hdr'
        tecfile = rhessys_input_dir / 'tecfiles' / f'{domain_name}.tec'
        routing = rhessys_input_dir / 'routing' / f'{domain_name}.routing'

        # Get scaling parameters from config if available
        s1 = config.get('RHESSYS_S1', 10.0)  # Ksat_0 multiplier (increased for better infiltration)
        s2 = config.get('RHESSYS_S2', 1.0)   # m multiplier
        s3 = config.get('RHESSYS_S3', 1.0)   # m_z multiplier
        gw1 = config.get('RHESSYS_GW1', 0.1) # Hillslope GW loss
        gw2 = config.get('RHESSYS_GW2', 0.1) # Riparian GW loss

        cmd = [
            str(exe),
            '-w', str(worldfile),
            '-whdr', str(world_hdr),
            '-t', str(tecfile),
            '-r', str(routing),
            '-st', str(start_date.year), str(start_date.month), str(start_date.day), '1',
            '-ed', str(end_date.year), str(end_date.month), str(end_date.day), '1',
            '-pre', 'rhessys',
            '-b',  # Basin output
            '-gw', str(gw1), str(gw2),
            '-s', str(s1), str(s2), str(s3),
            '-sv', '1.0', '1.0',
            '-svalt', '1.0', '1.0',
        ]

        return cmd

    def _create_worker_header(
        self,
        original_hdr: Path,
        worker_hdr: Path,
        worker_defs_dir: Path,
        rhessys_input_dir: Path
    ):
        """Create a worker-specific header file pointing to worker defs."""
        with open(original_hdr, 'r') as f:
            content = f.read()

        # Replace def file paths with worker-specific paths
        original_defs = rhessys_input_dir / 'defs'
        content = content.replace(str(original_defs), str(worker_defs_dir))

        with open(worker_hdr, 'w') as f:
            f.write(content)

    def calculate_metrics(
        self,
        output_dir: Path,
        config: Dict[str, Any],
        **kwargs
    ) -> Dict[str, float]:
        """
        Calculate metrics from RHESSys output.

        Args:
            output_dir: Directory containing model outputs
            config: Configuration dictionary
            **kwargs: Additional arguments

        Returns:
            Dictionary of metric names to values
        """
        try:
            # Get simulation directory
            sim_dir = Path(kwargs.get('sim_dir', output_dir))

            # Read RHESSys output
            sim_file = sim_dir / 'rhessys_basin.daily'
            if not sim_file.exists():
                return {'kge': self.penalty_score, 'error': 'rhessys_basin.daily not found'}

            sim_df = pd.read_csv(sim_file, sep=r'\s+', header=0)

            # Get streamflow in mm/day
            streamflow_mm = sim_df['streamflow'].values

            # Convert to m³/s using catchment area
            area_m2 = self._get_catchment_area(config)
            # Q (m³/s) = Q (mm/day) * area (m²) / 86400 / 1000
            streamflow_m3s = streamflow_mm * area_m2 / 86400 / 1000

            # Create dates
            sim_dates = pd.to_datetime(
                sim_df.apply(
                    lambda r: f"{int(r['year'])}-{int(r['month']):02d}-{int(r['day']):02d}",
                    axis=1
                )
            )
            sim_series = pd.Series(streamflow_m3s, index=sim_dates)

            # Load observations
            domain_name = config.get('DOMAIN_NAME')
            data_dir = Path(config.get('SYMFLUENCE_DATA_DIR', '.'))
            project_dir = data_dir / f'domain_{domain_name}'

            obs_values, obs_index = self._streamflow_metrics.load_observations(
                config, project_dir, domain_name, resample_freq='D'
            )
            if obs_values is None:
                return {'kge': self.penalty_score, 'error': 'Observations not found'}

            obs_series = pd.Series(obs_values, index=obs_index)

            # Align and calculate metrics
            try:
                obs_aligned, sim_aligned = self._streamflow_metrics.align_timeseries(
                    sim_series, obs_series
                )

                # Filter to calibration period if specified
                calib_period = config.get('CALIBRATION_PERIOD', '')
                if calib_period:
                    try:
                        start_str, end_str = calib_period.split(',')
                        start = pd.to_datetime(start_str.strip())
                        end = pd.to_datetime(end_str.strip())
                        mask = (obs_aligned.index >= start) & (obs_aligned.index <= end)
                        obs_aligned = obs_aligned[mask]
                        sim_aligned = sim_aligned[mask]
                    except Exception:
                        pass

                return self._streamflow_metrics.calculate_metrics(
                    obs_aligned, sim_aligned, metrics=['kge', 'nse']
                )

            except ValueError as e:
                return {'kge': self.penalty_score, 'error': str(e)}

        except Exception as e:
            self.logger.error(f"Error calculating RHESSys metrics: {e}")
            import traceback
            self.logger.error(traceback.format_exc())
            return {'kge': self.penalty_score}

    def _get_catchment_area(self, config: Dict[str, Any]) -> float:
        """Get catchment area in m²."""
        try:
            import geopandas as gpd

            domain_name = config.get('DOMAIN_NAME')
            data_dir = Path(config.get('SYMFLUENCE_DATA_DIR', '.'))
            project_dir = data_dir / f'domain_{domain_name}'

            # Try different catchment paths
            catchment_dir = project_dir / 'shapefiles' / 'catchment'
            catchment_files = list(catchment_dir.glob('*.shp'))

            if catchment_files:
                gdf = gpd.read_file(catchment_files[0])
                centroid = gdf.geometry.centroid.iloc[0]
                lon = centroid.x
                utm_zone = int((lon + 180) / 6) + 1
                utm_crs = f"EPSG:{32600 + utm_zone}"
                gdf_proj = gdf.to_crs(utm_crs)
                return gdf_proj.geometry.area.sum()

        except Exception as e:
            self.logger.warning(f"Could not calculate area: {e}")

        # Default to 100 km²
        return 1e8

    @staticmethod
    def evaluate_worker_function(task_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Static worker function for process pool execution.

        Args:
            task_data: Task dictionary

        Returns:
            Result dictionary
        """
        return _evaluate_rhessys_parameters_worker(task_data)


def _evaluate_rhessys_parameters_worker(task_data: Dict[str, Any]) -> Dict[str, Any]:
    """
    Module-level worker function for MPI/ProcessPool execution.

    Args:
        task_data: Task dictionary

    Returns:
        Result dictionary
    """
    import os
    import sys
    import signal
    import random
    import time
    import traceback

    # Set up signal handler for clean termination
    def signal_handler(signum, frame):
        sys.exit(1)

    try:
        signal.signal(signal.SIGTERM, signal_handler)
        signal.signal(signal.SIGINT, signal_handler)
    except ValueError:
        pass

    # Force single-threaded execution
    os.environ.update({
        'OMP_NUM_THREADS': '1',
        'MKL_NUM_THREADS': '1',
        'OPENBLAS_NUM_THREADS': '1',
        'NETCDF_DISABLE_LOCKING': '1',
        'HDF5_USE_FILE_LOCKING': 'FALSE',
        'HDF5_DISABLE_VERSION_CHECK': '1',
    })

    # Add small random delay
    initial_delay = random.uniform(0.1, 0.8)
    time.sleep(initial_delay)

    try:
        worker = RHESSysWorker(config=task_data.get('config'))
        task = WorkerTask.from_legacy_dict(task_data)
        result = worker.evaluate(task)
        return result.to_legacy_dict()
    except Exception as e:
        return {
            'individual_id': task_data.get('individual_id', -1),
            'params': task_data.get('params', {}),
            'score': ModelDefaults.PENALTY_SCORE,
            'error': f'Critical RHESSys worker exception: {str(e)}\n{traceback.format_exc()}',
            'proc_id': task_data.get('proc_id', -1)
        }
