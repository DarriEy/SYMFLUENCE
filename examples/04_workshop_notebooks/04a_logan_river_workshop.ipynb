{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# SYMFLUENCE Tutorial 04a — Logan River Workshop (Lumped SUMMA, Cloud Data)\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This workshop notebook demonstrates how to set up a lumped SUMMA model for the Logan River at Logan, Utah using cloud-based data sources. The workflow includes:\n",
    "\n",
    "1. **Configuration** — Set up a lumped basin model for the Logan River\n",
    "2. **Domain Definition** — Delineate the watershed using TauDEM\n",
    "3. **Data Acquisition** — Fetch AORC forcing data and USGS streamflow observations from cloud sources\n",
    "4. **Model Execution** — Run SUMMA with mizuRoute routing\n",
    "5. **Evaluation & Calibration** — Assess model performance and calibrate parameters\n",
    "\n",
    "The **Logan River at Logan** is a snow-dominated mountain watershed in the Bear River Range of the Wasatch Mountains. USGS station 10109000 provides streamflow observations. The watershed covers approximately 218 km² with elevations ranging from ~1,400 m to over 2,900 m.\n",
    "\n",
    "### 2i2c Environment Setup\n",
    "\n",
    "This notebook is designed to work with the 2i2c JupyterHub environment using the pre-installed SYMFLUENCE virtual environment at `/tmp/symfluence`.\n",
    "\n",
    "**Launch this notebook from the CLI:**\n",
    "```bash\n",
    "symfluence example launch 4a\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify we're using the correct virtual environment\n",
    "import sys\n",
    "print(f\"Python executable: {sys.executable}\")\n",
    "print(f\"Expected: /tmp/symfluence/bin/python\")\n",
    "assert 'symfluence' in sys.executable, \"Please activate the symfluence venv: source /tmp/symfluence/bin/activate\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Step 1 — Configuration\n",
    "\n",
    "Create a configuration for the Logan River lumped basin model. Key settings:\n",
    "- **Domain**: Lumped (single HRU) representation\n",
    "- **Forcing**: AORC (Analysis of Record for Calibration) — 1km hourly gridded data\n",
    "- **Observations**: USGS streamflow from station 10109000\n",
    "- **Period**: 4 years (2018-2021) with 1-year spinup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 — Create basin-scale configuration\n",
    "\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "\n",
    "from symfluence import SYMFLUENCE\n",
    "from symfluence.resources import get_config_template\n",
    "\n",
    "# Load template configuration\n",
    "config_template = get_config_template()\n",
    "with open(config_template, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# === Logan River Basin Configuration ===\n",
    "config['DOMAIN_NAME'] = 'Logan_River_at_Logan'\n",
    "config['EXPERIMENT_ID'] = 'workshop_run_1'\n",
    "\n",
    "# USGS gauging station 10109000 (Logan River near Logan, UT)\n",
    "# Coordinates: 41.7443°N, 111.8086°W\n",
    "config['POUR_POINT_COORDS'] = '41.7443/-111.8086'\n",
    "config['BOUNDING_BOX_COORDS'] = '42.15/-111.90/41.70/-111.40'  # lat_max/lon_min/lat_min/lon_max\n",
    "\n",
    "# Lumped basin settings\n",
    "config['DOMAIN_DEFINITION_METHOD'] = 'lumped'\n",
    "config['SUB_GRID_DISCRETIZATION'] = 'GRUs'\n",
    "config['LUMPED_WATERSHED_METHOD'] = 'TauDEM'\n",
    "\n",
    "# Model configuration\n",
    "config['HYDROLOGICAL_MODEL'] = 'SUMMA'\n",
    "config['ROUTING_MODEL'] = 'mizuRoute'\n",
    "\n",
    "# Data access and forcing\n",
    "config['DATA_ACCESS'] = 'cloud'  # Use cloud data sources\n",
    "config['FORCING_DATASET'] = 'AORC'  # NOAA Analysis of Record for Calibration\n",
    "config['FORCING_MEASUREMENT_HEIGHT'] = 10  # AORC wind at 10m\n",
    "\n",
    "# Streamflow observations from USGS\n",
    "config['STATION_ID'] = '10109000'\n",
    "config['STREAMFLOW_DATA_PROVIDER'] = 'USGS'\n",
    "config['DOWNLOAD_USGS_DATA'] = True\n",
    "\n",
    "# 4-year simulation period (2018-2021)\n",
    "# Year 1 (2018): Spinup period\n",
    "# Years 2-3 (2019-2020): Calibration period\n",
    "# Year 4 (2021): Evaluation period\n",
    "config['EXPERIMENT_TIME_START'] = '2018-01-01 01:00'\n",
    "config['EXPERIMENT_TIME_END'] = '2021-12-31 23:00'\n",
    "config['SPINUP_PERIOD'] = '2018-01-01, 2018-12-31'\n",
    "config['CALIBRATION_PERIOD'] = '2019-01-01, 2020-12-31'\n",
    "config['EVALUATION_PERIOD'] = '2021-01-01, 2021-12-31'\n",
    "\n",
    "# Calibration settings\n",
    "config['PARAMS_TO_CALIBRATE'] = 'k_soil,theta_sat,aquiferBaseflowExp,aquiferBaseflowRate,qSurfScale,summerLAI,frozenPrecipMultip,Fcapil,tempCritRain,heightCanopyTop,heightCanopyBottom,windReductionParam,vGn_n'\n",
    "config['BASIN_PARAMS_TO_CALIBRATE'] = 'routingGammaScale,routingGammaShape'\n",
    "config['OPTIMIZATION_TARGET'] = 'streamflow'\n",
    "config['ITERATIVE_OPTIMIZATION_ALGORITHM'] = 'DDS'\n",
    "config['OPTIMIZATION_METRIC'] = 'KGE'\n",
    "config['CALIBRATION_TIMESTEP'] = 'hourly'\n",
    "config['NUMBER_OF_ITERATIONS'] = 100  # Adjust based on available compute time\n",
    "\n",
    "# Save configuration\n",
    "config_path = Path('./config_logan_river_lumped.yaml')\n",
    "with open(config_path, 'w') as f:\n",
    "    yaml.dump(config, f, default_flow_style=False, sort_keys=False)\n",
    "\n",
    "print(f\"Configuration saved: {config_path}\")\n",
    "\n",
    "# Initialize SYMFLUENCE\n",
    "symfluence = SYMFLUENCE(config_path)\n",
    "\n",
    "# Create project structure\n",
    "project_dir = symfluence.managers['project'].setup_project()\n",
    "pour_point_path = symfluence.managers['project'].create_pour_point()\n",
    "\n",
    "print(f\"Project structure created at: {project_dir}\")\n",
    "print(f\"Pour point shapefile: {pour_point_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Step 2 — Domain Definition\n",
    "\n",
    "Delineate the Logan River watershed using TauDEM and create a single lumped HRU."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "### Step 2a — Geospatial Attribute Acquisition\n",
    "\n",
    "Acquire elevation, land cover, and soil data from cloud sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2a — Acquire geospatial attributes from cloud\n",
    "symfluence.managers['data'].acquire_attributes()\n",
    "print(\"Attribute acquisition complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### Step 2b — Watershed Delineation\n",
    "\n",
    "Delineate the watershed boundary from the pour point using TauDEM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2b — Watershed delineation\n",
    "watershed_path = symfluence.managers['domain'].define_domain()\n",
    "print(f\"Watershed delineation complete\")\n",
    "print(f\"Watershed file: {watershed_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "### Step 2c — Domain Discretization\n",
    "\n",
    "Create a single lumped HRU for the watershed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2c — Discretization (single lumped HRU)\n",
    "hru_path = symfluence.managers['domain'].discretize_domain()\n",
    "print(\"Domain discretization complete\")\n",
    "print(f\"HRU file: {hru_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### Step 2d — Visualization\n",
    "\n",
    "Visualize the delineated watershed and pour point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2d — Basin visualization\n",
    "\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load spatial data\n",
    "basin_path = project_dir / 'shapefiles' / 'river_basins' / f\"{config['DOMAIN_NAME']}_riverBasins_lumped.shp\"\n",
    "hru_file = project_dir / 'shapefiles' / 'catchment' / f\"{config['DOMAIN_NAME']}_HRUs_GRUs.shp\"\n",
    "\n",
    "watershed_gdf = gpd.read_file(str(basin_path))\n",
    "hru_gdf = gpd.read_file(str(hru_file))\n",
    "pour_point_gdf = gpd.read_file(pour_point_path)\n",
    "\n",
    "# Calculate area (UTM Zone 12N for Utah)\n",
    "watershed_proj = watershed_gdf.to_crs('EPSG:32612')\n",
    "area_km2 = watershed_proj.geometry.area.sum() / 1e6\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "watershed_gdf.boundary.plot(ax=ax, color='blue', linewidth=2, label='Watershed')\n",
    "hru_gdf.plot(ax=ax, facecolor='lightblue', edgecolor='blue', alpha=0.3)\n",
    "pour_point_gdf.plot(ax=ax, color='red', markersize=150, marker='*', label='Pour Point (USGS 10109000)')\n",
    "\n",
    "ax.set_title(f\"Logan River at Logan\\nArea: {area_km2:.0f} km²\", fontweight='bold', fontsize=14)\n",
    "ax.legend(loc='upper right')\n",
    "ax.set_xlabel('Longitude')\n",
    "ax.set_ylabel('Latitude')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Watershed area: {area_km2:.0f} km²\")\n",
    "print(f\"Number of HRUs: {len(hru_gdf)} (lumped)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## Step 3 — Data Acquisition and Preprocessing\n",
    "\n",
    "Fetch forcing data (AORC) and streamflow observations (USGS) from cloud sources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "### Step 3a — USGS Streamflow Observations\n",
    "\n",
    "Download and process USGS streamflow data for station 10109000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3a — Download and process USGS streamflow data\n",
    "symfluence.managers['data'].acquire_observations()\n",
    "print(\"USGS streamflow data acquisition complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "### Step 3b — AORC Meteorological Forcing\n",
    "\n",
    "Download AORC forcing data from NOAA's cloud archive (AWS S3). AORC provides:\n",
    "- 1 km spatial resolution\n",
    "- Hourly temporal resolution\n",
    "- Complete forcing variables: precipitation, temperature, humidity, wind, radiation, pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3b — Acquire AORC forcing data from cloud\n",
    "symfluence.managers['data'].acquire_forcings()\n",
    "print(\"AORC forcing acquisition complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "### Step 3c — Model-Agnostic Preprocessing\n",
    "\n",
    "Standardize forcing data: variable names, units, and spatial averaging over the watershed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3c — Model-agnostic preprocessing\n",
    "symfluence.managers['data'].run_model_agnostic_preprocessing()\n",
    "print(\"Model-agnostic preprocessing complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "## Step 4 — Model Configuration and Execution\n",
    "\n",
    "Configure SUMMA for the lumped basin and run the simulation with mizuRoute routing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4a — SUMMA-specific preprocessing\n",
    "symfluence.managers['model'].preprocess_models()\n",
    "print(\"SUMMA configuration complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4b — Model execution\n",
    "print(f\"Running {config['HYDROLOGICAL_MODEL']} with {config.get('ROUTING_MODEL', 'no routing')}...\")\n",
    "print(f\"Simulation period: {config['EXPERIMENT_TIME_START']} to {config['EXPERIMENT_TIME_END']}\")\n",
    "symfluence.managers['model'].run_models()\n",
    "print(\"Basin-scale simulation complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "## Step 5 — Streamflow Evaluation\n",
    "\n",
    "Compare simulated streamflow against USGS observations using standard hydrological metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5 — Streamflow evaluation\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "\n",
    "# Load basin area from shapefile\n",
    "basin_path = project_dir / 'shapefiles' / 'river_basins' / f\"{config['DOMAIN_NAME']}_riverBasins_lumped.shp\"\n",
    "watershed_gdf = gpd.read_file(str(basin_path))\n",
    "watershed_proj = watershed_gdf.to_crs('EPSG:32612')  # UTM Zone 12N for Utah\n",
    "basin_area_m2 = watershed_proj.geometry.area.sum()\n",
    "basin_area_km2 = basin_area_m2 / 1e6\n",
    "\n",
    "print(f\"Basin area: {basin_area_km2:.2f} km²\")\n",
    "\n",
    "# Load observed streamflow\n",
    "obs_path = project_dir / \"observations\" / \"streamflow\" / \"preprocessed\" / f\"{config['DOMAIN_NAME']}_streamflow_processed.csv\"\n",
    "obs_df = pd.read_csv(obs_path, parse_dates=['datetime'])\n",
    "obs_df.set_index('datetime', inplace=True)\n",
    "\n",
    "# Load simulated streamflow from SUMMA output\n",
    "sim_dir = project_dir / \"simulations\" / config['EXPERIMENT_ID'] / \"SUMMA\"\n",
    "sim_files = list(sim_dir.glob('*_timestep.nc'))\n",
    "if not sim_files:\n",
    "    raise FileNotFoundError(f\"No SUMMA output found in: {sim_dir}\")\n",
    "\n",
    "sim_ds = xr.open_dataset(sim_files[0])\n",
    "sim_df = sim_ds['averageRoutedRunoff'].to_dataframe().reset_index()\n",
    "sim_df = sim_df.rename(columns={'time': 'datetime', 'averageRoutedRunoff': 'discharge_m_s'})\n",
    "sim_df.set_index('datetime', inplace=True)\n",
    "\n",
    "# Convert from m/s to m³/s\n",
    "sim_df['discharge_sim'] = sim_df['discharge_m_s'] * basin_area_m2\n",
    "\n",
    "# Exclude spinup period\n",
    "spinup_end = pd.to_datetime(config['SPINUP_PERIOD'].split(',')[1].strip())\n",
    "print(f\"Excluding spinup period up to: {spinup_end}\")\n",
    "\n",
    "# Merge and align\n",
    "eval_df = obs_df.join(sim_df[['discharge_sim']], how='inner')\n",
    "eval_df = eval_df[eval_df.index > spinup_end]\n",
    "\n",
    "obs_valid = eval_df['discharge_cms'].dropna()\n",
    "sim_valid = eval_df.loc[obs_valid.index, 'discharge_sim']\n",
    "\n",
    "print(f\"Evaluation period: {obs_valid.index[0]} to {obs_valid.index[-1]}\")\n",
    "print(f\"Number of timesteps: {len(obs_valid)}\")\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "def nse(obs, sim):\n",
    "    return float(1 - np.sum((obs - sim)**2) / np.sum((obs - obs.mean())**2))\n",
    "\n",
    "def kge(obs, sim):\n",
    "    r = obs.corr(sim)\n",
    "    alpha = sim.std() / obs.std()\n",
    "    beta = sim.mean() / obs.mean()\n",
    "    return float(1 - np.sqrt((r-1)**2 + (alpha-1)**2 + (beta-1)**2))\n",
    "\n",
    "def pbias(obs, sim):\n",
    "    return float(100 * (sim.sum() - obs.sum()) / obs.sum())\n",
    "\n",
    "metrics = {\n",
    "    'NSE': round(nse(obs_valid, sim_valid), 3),\n",
    "    'KGE': round(kge(obs_valid, sim_valid), 3),\n",
    "    'PBIAS': round(pbias(obs_valid, sim_valid), 1)\n",
    "}\n",
    "\n",
    "print(\"\\nPerformance Metrics (Uncalibrated):\")\n",
    "for k, v in metrics.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Time series (top left)\n",
    "axes[0, 0].plot(obs_valid.index, obs_valid.values, 'b-', label='Observed (USGS)', linewidth=1.2, alpha=0.7)\n",
    "axes[0, 0].plot(sim_valid.index, sim_valid.values, 'r-', label='Simulated (SUMMA)', linewidth=1.2, alpha=0.7)\n",
    "axes[0, 0].set_ylabel('Discharge (m³/s)')\n",
    "axes[0, 0].set_title('Streamflow Time Series')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "axes[0, 0].text(0.02, 0.95, f\"NSE: {metrics['NSE']}\\nKGE: {metrics['KGE']}\\nBias: {metrics['PBIAS']}%\",\n",
    "                transform=axes[0, 0].transAxes, verticalalignment='top',\n",
    "                bbox=dict(facecolor='white', alpha=0.8), fontsize=9)\n",
    "\n",
    "# Scatter (top right)\n",
    "axes[0, 1].scatter(obs_valid, sim_valid, alpha=0.5, s=10)\n",
    "max_val = max(obs_valid.max(), sim_valid.max())\n",
    "axes[0, 1].plot([0, max_val], [0, max_val], 'k--', alpha=0.5)\n",
    "axes[0, 1].set_xlabel('Observed (m³/s)')\n",
    "axes[0, 1].set_ylabel('Simulated (m³/s)')\n",
    "axes[0, 1].set_title('Observed vs Simulated')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Monthly climatology (bottom left)\n",
    "monthly_obs = obs_valid.groupby(obs_valid.index.month).mean()\n",
    "monthly_sim = sim_valid.groupby(sim_valid.index.month).mean()\n",
    "month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n",
    "               'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "axes[1, 0].plot(monthly_obs.index, monthly_obs.values, 'b-o', label='Observed', markersize=6)\n",
    "axes[1, 0].plot(monthly_sim.index, monthly_sim.values, 'r-o', label='Simulated', markersize=6)\n",
    "axes[1, 0].set_xticks(range(1, 13))\n",
    "axes[1, 0].set_xticklabels(month_names)\n",
    "axes[1, 0].set_ylabel('Mean Discharge (m³/s)')\n",
    "axes[1, 0].set_title('Seasonal Flow Regime')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Flow duration curve (bottom right)\n",
    "obs_sorted = obs_valid.sort_values(ascending=False)\n",
    "sim_sorted = sim_valid.sort_values(ascending=False)\n",
    "obs_ranks = np.arange(1., len(obs_sorted) + 1) / len(obs_sorted) * 100\n",
    "sim_ranks = np.arange(1., len(sim_sorted) + 1) / len(sim_sorted) * 100\n",
    "axes[1, 1].semilogy(obs_ranks, obs_sorted, 'b-', label='Observed', linewidth=2)\n",
    "axes[1, 1].semilogy(sim_ranks, sim_sorted, 'r-', label='Simulated', linewidth=2)\n",
    "axes[1, 1].set_xlabel('Exceedance Probability (%)')\n",
    "axes[1, 1].set_ylabel('Discharge (m³/s)')\n",
    "axes[1, 1].set_title('Flow Duration Curve')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle(f'Logan River at Logan — Lumped SUMMA Evaluation', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nStreamflow evaluation complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "## Step 5b — Model Calibration\n",
    "\n",
    "Calibrate SUMMA parameters using the DDS (Dynamically Dimensioned Search) algorithm to improve model performance. The calibration optimizes KGE over the calibration period (2019-2020)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5b — Run calibration\n",
    "print(f\"Starting calibration...\")\n",
    "print(f\"Algorithm: {config['ITERATIVE_OPTIMIZATION_ALGORITHM']}\")\n",
    "print(f\"Metric: {config['OPTIMIZATION_METRIC']}\")\n",
    "print(f\"Iterations: {config['NUMBER_OF_ITERATIONS']}\")\n",
    "print(f\"Calibration period: {config['CALIBRATION_PERIOD']}\")\n",
    "\n",
    "results_file = symfluence.managers['optimization'].calibrate_model()\n",
    "print(f\"\\nCalibration complete!\")\n",
    "print(f\"Results file: {results_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "### View Calibration Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display calibration results\n",
    "if results_file and Path(results_file).exists():\n",
    "    results_df = pd.read_csv(results_file)\n",
    "    \n",
    "    print(\"Calibration Progress:\")\n",
    "    print(f\"  Best {config['OPTIMIZATION_METRIC']}: {results_df['best_score'].iloc[-1]:.4f}\")\n",
    "    print(f\"  Initial {config['OPTIMIZATION_METRIC']}: {results_df['best_score'].iloc[0]:.4f}\")\n",
    "    print(f\"  Improvement: {results_df['best_score'].iloc[-1] - results_df['best_score'].iloc[0]:.4f}\")\n",
    "    \n",
    "    # Plot calibration progress\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    ax.plot(results_df['generation'], results_df['best_score'], 'b-', linewidth=2)\n",
    "    ax.set_xlabel('Iteration')\n",
    "    ax.set_ylabel(f'Best {config[\"OPTIMIZATION_METRIC\"]}')\n",
    "    ax.set_title('Calibration Progress')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No calibration results found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated the complete SYMFLUENCE workflow for the Logan River at Logan:\n",
    "\n",
    "1. **Configuration** — Created a lumped SUMMA model configuration\n",
    "2. **Domain** — Delineated watershed using TauDEM (~218 km²)\n",
    "3. **Data** — Acquired AORC forcing and USGS streamflow from cloud sources\n",
    "4. **Simulation** — Ran SUMMA+mizuRoute for 4 years (2018-2021)\n",
    "5. **Evaluation** — Assessed uncalibrated performance with NSE, KGE, PBIAS\n",
    "6. **Calibration** — Optimized parameters using DDS algorithm\n",
    "\n",
    "### Next Steps\n",
    "- Increase calibration iterations for better optimization\n",
    "- Try semi-distributed or distributed representations\n",
    "- Experiment with different forcing datasets (ERA5, HRRR)\n",
    "- Apply the workflow to other USGS basins"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
