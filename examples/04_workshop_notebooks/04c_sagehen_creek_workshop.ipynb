{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SYMFLUENCE Tutorial 04c — Sagehen Creek Workshop (Coupled SUMMA-MODFLOW Groundwater)\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This workshop notebook demonstrates how to set up a **coupled SUMMA-MODFLOW groundwater model** for Sagehen Creek near Truckee, California. The workflow couples a land surface model (SUMMA) with a groundwater model (MODFLOW 6) to simulate both surface and subsurface flow processes.\n",
    "\n",
    "**Sagehen Creek** (USGS 10343500) is a well-known USGS research watershed in the Sierra Nevada. It is a ~27 km² snow-dominated headwater catchment (elevation ~1,930–2,660 m) with decades of hydrological observations — ideal for demonstrating coupled surface-groundwater modeling.\n",
    "\n",
    "### Coupling Architecture\n",
    "\n",
    "```\n",
    "SUMMA (Land Surface)        MODFLOW 6 (Groundwater)\n",
    "┌──────────────────┐        ┌──────────────────────┐\n",
    "│  Snow processes   │        │  Saturated zone flow  │\n",
    "│  Canopy processes │        │  (hydraulic cond. K)  │\n",
    "│  Soil column      │───────>│  Recharge (from SUMMA)│\n",
    "│  Surface runoff   │ rech.  │  Drain discharge      │\n",
    "└────────┬─────────┘        └──────────┬───────────┘\n",
    "         │                              │\n",
    "         │ surface runoff (m³/s)        │ baseflow (m³/s)\n",
    "         │                              │\n",
    "         └──────────┐  ┌───────────────┘\n",
    "                    ▼  ▼\n",
    "            Combined Streamflow\n",
    "            (compared to USGS obs)\n",
    "```\n",
    "\n",
    "The workflow includes:\n",
    "\n",
    "1. **Configuration** — Set up a coupled SUMMA-MODFLOW model for Sagehen Creek\n",
    "2. **Domain Definition** — Delineate the watershed using TauDEM\n",
    "3. **Data Acquisition** — Fetch AORC forcing data and USGS streamflow observations\n",
    "4. **Model Execution** — Run the coupled SUMMA→MODFLOW pipeline and visualize coupling\n",
    "5. **Evaluation & Calibration** — Assess performance and calibrate 17 parameters (14 SUMMA + 3 MODFLOW)\n",
    "\n",
    "**Launch this notebook from the CLI:**\n",
    "```bash\n",
    "symfluence example launch 4c\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment verification\n",
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "# Suppress experimental module warnings for cleaner output\n",
    "warnings.filterwarnings('ignore', message='.*is an EXPERIMENTAL module.*')\n",
    "warnings.filterwarnings('ignore', message='.*import failed.*')\n",
    "\n",
    "print(f\"Python executable: {sys.executable}\")\n",
    "\n",
    "# Verify SYMFLUENCE is available\n",
    "try:\n",
    "    import symfluence\n",
    "    print(f\"SYMFLUENCE version: {symfluence.__version__}\")\n",
    "    print(f\"SYMFLUENCE location: {Path(symfluence.__file__).parent}\")\n",
    "except ImportError:\n",
    "    print(\"ERROR: SYMFLUENCE not found. Please activate the symfluence environment.\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix working directory if running from .ipynb_checkpoints\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "current_dir = Path.cwd()\n",
    "print(f\"Current directory: {current_dir}\")\n",
    "\n",
    "# If we're in .ipynb_checkpoints, move up to parent directory\n",
    "if '.ipynb_checkpoints' in str(current_dir):\n",
    "    correct_dir = current_dir.parent\n",
    "    os.chdir(correct_dir)\n",
    "    print(f\"Changed to: {Path.cwd()}\")\n",
    "else:\n",
    "    print(\"Working directory is correct\")\n",
    "\n",
    "# Verify we're in the workshop notebooks directory\n",
    "expected_notebook = Path.cwd() / '04c_sagehen_creek_workshop.ipynb'\n",
    "if not expected_notebook.exists():\n",
    "    print(f\"WARNING: Expected notebook not found at {expected_notebook}\")\n",
    "else:\n",
    "    print(\"Notebook location verified\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 — Configuration\n",
    "\n",
    "Create a configuration for the Sagehen Creek coupled SUMMA-MODFLOW model. Key settings:\n",
    "- **Model**: `SUMMA` — land surface hydrology (snow, canopy, soil column, surface runoff)\n",
    "- **Groundwater**: `MODFLOW` — MODFLOW 6 groundwater flow (set via `GROUNDWATER_MODEL`)\n",
    "- **Coupling**: Sequential — SUMMA runs first, recharge feeds MODFLOW, flows are combined\n",
    "- **Routing**: MODFLOW drain (no separate routing model needed)\n",
    "- **Forcing**: AORC (Analysis of Record for Calibration) — 1km hourly gridded data\n",
    "- **Observations**: USGS streamflow from station 10343500\n",
    "- **Period**: 5 years (2016-2020) with 1-year spinup\n",
    "- **Calibration parameters**: 14 total (11 SUMMA + 3 MODFLOW)\n",
    "\n",
    "### MODFLOW Domain Setup\n",
    "\n",
    "The lumped MODFLOW cell represents the fractured granite aquifer beneath Sagehen Creek:\n",
    "- **TOP** = 2300 m, **BOT** = 2100 m (200 m aquifer thickness)\n",
    "- **Drain elevation** = 2200 m (mid-aquifer, representing stream-aquifer connection)\n",
    "- **K** = 5.0 m/d initial hydraulic conductivity\n",
    "- **SY** = 0.05 initial specific yield (fractured granite — lower than alluvial aquifers)\n",
    "- **Cell size** ≈ 5436 m (auto-computed from catchment area ~29.5 km²)\n",
    "\n",
    "### Aquifer Time Constant\n",
    "\n",
    "The lumped MODFLOW cell acts as a linear reservoir with time constant τ = SY × A / C_drain.\n",
    "With SY=0.05, A=29.5 km², C=15,000 m²/d: τ ≈ 98 days — allowing seasonal variability while\n",
    "maintaining the smoothing characteristic of groundwater storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 — Create coupled SUMMA-MODFLOW configuration\n",
    "\n",
    "from pathlib import Path\n",
    "from symfluence import SYMFLUENCE\n",
    "from symfluence.core.config.models import SymfluenceConfig\n",
    "import os\n",
    "\n",
    "# === Sagehen Creek Coupled Configuration ===\n",
    "\n",
    "# Ensure we're working from the correct directory\n",
    "current_dir = Path.cwd()\n",
    "print(f\"INITIAL working directory: {current_dir}\")\n",
    "\n",
    "if '.ipynb_checkpoints' in str(current_dir):\n",
    "    current_dir = current_dir.parent\n",
    "    os.chdir(current_dir)\n",
    "    print(f\"CHANGED to: {Path.cwd()}\")\n",
    "else:\n",
    "    print(\"Working directory is correct\")\n",
    "\n",
    "# Derive paths dynamically from repo structure\n",
    "# Notebooks live at: <repo>/examples/04_workshop_notebooks/\n",
    "repo_root = current_dir.parent.parent\n",
    "data_dir = repo_root.parent / 'SYMFLUENCE_data'\n",
    "\n",
    "print(f\"Notebook directory: {current_dir}\")\n",
    "print(f\"Repo root (CODE_DIR): {repo_root}\")\n",
    "print(f\"Data directory (DATA_DIR): {data_dir}\")\n",
    "\n",
    "config = SymfluenceConfig.from_minimal(\n",
    "    # ============================================================================\n",
    "    # BASIC IDENTIFICATION\n",
    "    # ============================================================================\n",
    "    domain_name='Sagehen_Creek_near_Truckee',\n",
    "    experiment_id='workshop_run_3',\n",
    "\n",
    "    # ============================================================================\n",
    "    # PATHS — use 'default' to auto-resolve from DATA_DIR\n",
    "    # ============================================================================\n",
    "    SYMFLUENCE_DATA_DIR=str(data_dir),\n",
    "    SYMFLUENCE_CODE_DIR=str(repo_root),\n",
    "    TAUDEM_DIR='default',\n",
    "    SUMMA_INSTALL_PATH='default',\n",
    "\n",
    "    # ============================================================================\n",
    "    # COUPLED MODEL SETUP\n",
    "    # ============================================================================\n",
    "    model='SUMMA',                               # SUMMA for land surface processes\n",
    "    GROUNDWATER_MODEL='MODFLOW',                 # MODFLOW 6 for groundwater\n",
    "    COUPLING_MODE='sequential',                  # Sequential coupling (SUMMA -> MODFLOW)\n",
    "    routing_model='none',                        # MODFLOW drain provides baseflow\n",
    "\n",
    "    # ============================================================================\n",
    "    # MODFLOW DOMAIN PARAMETERS\n",
    "    # ============================================================================\n",
    "    MODFLOW_K=5.0,                               # Hydraulic conductivity (m/d)\n",
    "    MODFLOW_SY=0.05,                             # Specific yield — fractured granite\n",
    "    MODFLOW_TOP=2300,                            # Top of aquifer (m)\n",
    "    MODFLOW_BOT=2100,                            # Bottom of aquifer (m)\n",
    "    MODFLOW_DRAIN_ELEVATION=2200,                # Drain elevation (m)\n",
    "    MODFLOW_DRAIN_CONDUCTANCE=1.5e4,             # Drain conductance (m2/d)\n",
    "\n",
    "    # ============================================================================\n",
    "    # SUMMA DECISION OVERRIDES\n",
    "    # ============================================================================\n",
    "    SUMMA_DECISION_OPTIONS={'hc_profile': ['pow_prof']},  # K decreases with depth\n",
    "\n",
    "    # ============================================================================\n",
    "    # SIMULATION PERIOD (5 years: 2016-2020)\n",
    "    # ============================================================================\n",
    "    time_start='2016-01-01 01:00',\n",
    "    time_end='2020-12-31 23:00',\n",
    "\n",
    "    # Time period definitions\n",
    "    spinup_period='2016-01-01, 2016-12-31',        # Year 1: Model spinup\n",
    "    calibration_period='2017-01-01, 2019-12-31',   # Years 2-4: Parameter calibration\n",
    "    evaluation_period='2020-01-01, 2020-12-31',    # Year 5: Model evaluation\n",
    "\n",
    "    # ============================================================================\n",
    "    # SPATIAL DOMAIN (Sagehen Creek near Truckee, CA)\n",
    "    # ============================================================================\n",
    "    # USGS station 10343500: 39.4313N, 120.2383W\n",
    "    pour_point_coords='39.4313/-120.2383',\n",
    "    bounding_box_coords='39.48/-120.30/39.38/-120.18',\n",
    "\n",
    "    # Domain discretization\n",
    "    definition_method='lumped',\n",
    "    discretization='GRUs',\n",
    "    lumped_watershed_method='TauDEM',\n",
    "\n",
    "    # ============================================================================\n",
    "    # DATA SOURCES & FORCING\n",
    "    # ============================================================================\n",
    "    data_access='cloud',\n",
    "    forcing_dataset='AORC',\n",
    "    forcing_measurement_height=10,\n",
    "    dem_source='copernicus',\n",
    "    download_dem=True,\n",
    "\n",
    "    # ============================================================================\n",
    "    # STREAMFLOW OBSERVATIONS\n",
    "    # ============================================================================\n",
    "    station_id='10343500',\n",
    "    streamflow_data_provider='USGS',\n",
    "    download_usgs_data=True,\n",
    "\n",
    "    # ============================================================================\n",
    "    # CALIBRATION PARAMETERS (14 SUMMA + 3 MODFLOW = 17 total)\n",
    "    # ============================================================================\n",
    "    OPTIMIZATION_METHODS=['iteration'],\n",
    "\n",
    "    # SUMMA land surface parameters (12 local + 2 basin = 14)\n",
    "    params_to_calibrate='albedoMax,albedoMinWinter,newSnowDenMin,Fcapil,k_soil,theta_sat,critSoilWilting,theta_res,f_impede,tempCritRain,fieldCapacity,qSurfScale',\n",
    "    BASIN_PARAMS_TO_CALIBRATE='routingGammaShape,routingGammaScale',\n",
    "\n",
    "    # MODFLOW groundwater parameters (3)\n",
    "    MODFLOW_PARAMS_TO_CALIBRATE='K,SY,DRAIN_CONDUCTANCE',\n",
    "\n",
    "    # Parameter bound overrides\n",
    "    PARAMETER_BOUNDS={\n",
    "        'K': [0.1, 100.0],\n",
    "        'SY': [0.005, 0.25],\n",
    "        'fieldCapacity': [0.05, 0.45],\n",
    "        'critSoilWilting': [0.01, 0.40],\n",
    "        'albedoMax': [0.50, 0.95],\n",
    "        'albedoMinWinter': [0.45, 0.85],\n",
    "        'theta_sat': [0.35, 0.85],\n",
    "        'theta_res': [0.01, 0.15],\n",
    "        'routingGammaShape': [1.0, 5.0],\n",
    "        'DRAIN_CONDUCTANCE': [1000.0, 500000.0],\n",
    "    },\n",
    "\n",
    "    # Optimization configuration\n",
    "    optimization_target='streamflow',\n",
    "    optimization_algorithm='DDS',\n",
    "    optimization_metric='KGE',\n",
    "    calibration_timestep='daily',\n",
    "    iterations=300,\n",
    ")\n",
    "\n",
    "# Verify\n",
    "print(f\"\\nConfig verification:\")\n",
    "print(f\"  Model: {config.model.hydrological_model}\")\n",
    "print(f\"  Groundwater: {config.model.groundwater_model}\")\n",
    "print(f\"  Data dir: {config.system.data_dir}\")\n",
    "print(f\"  Optimization methods: {config.optimization.methods}\")\n",
    "\n",
    "# Save configuration\n",
    "config_path = Path('./config_sagehen_creek_coupled.yaml')\n",
    "config_dict = config.to_dict(flatten=True)\n",
    "import yaml\n",
    "with open(config_path, 'w') as f:\n",
    "    yaml.dump(config_dict, f, default_flow_style=False, sort_keys=False)\n",
    "print(f\"\\nConfiguration saved to: {config_path}\")\n",
    "\n",
    "# Initialize SYMFLUENCE\n",
    "sf = SYMFLUENCE(config)\n",
    "project_dir = sf.managers['project'].setup_project()\n",
    "pour_point_path = sf.managers['project'].create_pour_point()\n",
    "\n",
    "print(f\"\\nProject structure created at: {project_dir}\")\n",
    "print(f\"Pour point shapefile: {pour_point_path}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 — Domain Definition\n",
    "\n",
    "Delineate the Sagehen Creek watershed using TauDEM and create a single lumped HRU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2a — Geospatial Attribute Acquisition\n",
    "\n",
    "Acquire elevation, land cover, and soil data from cloud sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2a — Acquire geospatial attributes from cloud\n",
    "sf.managers['data'].acquire_attributes()\n",
    "print(\"Attribute acquisition complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2b — Watershed Delineation\n",
    "\n",
    "Delineate the watershed boundary from the pour point using TauDEM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2b — Watershed delineation\n",
    "watershed_path = sf.managers['domain'].define_domain()\n",
    "print(f\"Watershed delineation complete\")\n",
    "print(f\"Watershed file: {watershed_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2c — Domain Discretization\n",
    "\n",
    "Create a single lumped HRU for the watershed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2c — Discretization (single lumped HRU)\n",
    "hru_path = sf.managers['domain'].discretize_domain()\n",
    "print(\"Domain discretization complete\")\n",
    "print(f\"HRU file: {hru_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2d — Visualization\n",
    "\n",
    "Visualize the delineated Sagehen Creek watershed and pour point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2d — Basin visualization\n",
    "\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load spatial data\n",
    "basin_path = project_dir / 'shapefiles' / 'river_basins' / f\"{config.domain.name}_riverBasins_lumped.shp\"\n",
    "hru_file = project_dir / 'shapefiles' / 'catchment' / 'lumped' / config.domain.experiment_id / f\"{config.domain.name}_HRUs_GRUs.shp\"\n",
    "\n",
    "watershed_gdf = gpd.read_file(str(basin_path))\n",
    "hru_gdf = gpd.read_file(str(hru_file))\n",
    "pour_point_gdf = gpd.read_file(pour_point_path)\n",
    "\n",
    "# Calculate area (UTM Zone 10N for northern California)\n",
    "watershed_proj = watershed_gdf.to_crs('EPSG:32610')\n",
    "area_km2 = watershed_proj.geometry.area.sum() / 1e6\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "watershed_gdf.boundary.plot(ax=ax, color='blue', linewidth=2, label='Watershed')\n",
    "hru_gdf.plot(ax=ax, facecolor='lightblue', edgecolor='blue', alpha=0.3)\n",
    "pour_point_gdf.plot(ax=ax, color='red', markersize=150, marker='*',\n",
    "                    label=f'Pour Point (USGS {config.evaluation.streamflow.station_id})')\n",
    "\n",
    "ax.set_title(f\"Sagehen Creek near Truckee\\nArea: {area_km2:.0f} km\\u00b2\",\n",
    "             fontweight='bold', fontsize=14)\n",
    "ax.legend(loc='upper right')\n",
    "ax.set_xlabel('Longitude')\n",
    "ax.set_ylabel('Latitude')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Watershed area: {area_km2:.0f} km\\u00b2\")\n",
    "print(f\"Number of HRUs: {len(hru_gdf)} (lumped)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 — Data Acquisition and Preprocessing\n",
    "\n",
    "Fetch forcing data (AORC) and streamflow observations (USGS) from cloud sources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3a — USGS Streamflow Observations\n",
    "\n",
    "Download and process USGS streamflow data for station 10343500 (Sagehen Creek near Truckee, CA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3a — Download and process USGS streamflow data\n",
    "sf.managers['data'].process_observed_data()\n",
    "\n",
    "print(\"USGS streamflow data acquisition complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3b — AORC Meteorological Forcing\n",
    "\n",
    "Download AORC forcing data from NOAA's cloud archive (AWS S3). AORC provides:\n",
    "- 1 km spatial resolution\n",
    "- Hourly temporal resolution\n",
    "- Complete forcing variables: precipitation, temperature, humidity, wind, radiation, pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3b — Acquire AORC forcing data from cloud\n",
    "sf.managers['data'].acquire_forcings()\n",
    "print(\"AORC forcing acquisition complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3c — Model-Agnostic Preprocessing\n",
    "\n",
    "Standardize forcing data: variable names, units, and spatial averaging over the watershed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3c — Model-agnostic preprocessing\n",
    "sf.managers['data'].run_model_agnostic_preprocessing()\n",
    "print(\"Model-agnostic preprocessing complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 — Model Configuration and Execution\n",
    "\n",
    "Configure the coupled SUMMA-MODFLOW pipeline and run the simulation. This step:\n",
    "1. Creates **SUMMA settings** (forcing lists, parameters, cold state)\n",
    "2. Creates **MODFLOW settings** (gwf.nam, gwf.dis, gwf.npf, gwf.sto, gwf.drn, gwf.rch, etc.)\n",
    "3. Runs the coupled pipeline: SUMMA → extract recharge → MODFLOW → combine flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4a — Model preprocessing (creates BOTH SUMMA and MODFLOW settings)\n",
    "sf.managers['model'].preprocess_models()\n",
    "print(\"SUMMA + MODFLOW configuration complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4b — Run coupled model\n",
    "print(f\"Running coupled pipeline: SUMMA (land surface) -> MODFLOW (groundwater)...\")\n",
    "print(f\"Simulation period: {config.domain.time_start} to {config.domain.time_end}\")\n",
    "print(f\"Coupling mode: sequential\")\n",
    "print(f\"Workflow: HYDROLOGICAL_MODEL={config.model.hydrological_model}, GROUNDWATER_MODEL={config.model.groundwater_model}\")\n",
    "sf.managers['model'].run_models()\n",
    "print(\"Coupled SUMMA-MODFLOW simulation complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4c — Verify output files exist\n",
    "sim_dir = project_dir / 'simulations' / config.domain.experiment_id\n",
    "\n",
    "# Check SUMMA output\n",
    "summa_dir = sim_dir / 'SUMMA'\n",
    "summa_files = list(summa_dir.glob('*.nc')) if summa_dir.exists() else []\n",
    "print(f\"SUMMA output directory: {summa_dir}\")\n",
    "print(f\"  NetCDF files found: {len(summa_files)}\")\n",
    "for f in summa_files:\n",
    "    print(f\"    {f.name} ({f.stat().st_size / 1e6:.1f} MB)\")\n",
    "\n",
    "# Check MODFLOW output\n",
    "modflow_dir = sim_dir / 'MODFLOW'\n",
    "modflow_files = list(modflow_dir.glob('*')) if modflow_dir.exists() else []\n",
    "print(f\"\\nMODFLOW output directory: {modflow_dir}\")\n",
    "for f in sorted(modflow_files):\n",
    "    if f.is_file():\n",
    "        print(f\"    {f.name} ({f.stat().st_size / 1e3:.1f} KB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4d — Coupling Visualization\n",
    "\n",
    "Visualize the coupling between SUMMA and MODFLOW:\n",
    "- **Recharge**: SUMMA soil drainage → MODFLOW recharge input\n",
    "- **Drain discharge**: MODFLOW baseflow contribution\n",
    "- **Flow partitioning**: Surface runoff vs. baseflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4d — Coupling visualization\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "\n",
    "from symfluence.models.modflow.coupling import SUMMAToMODFLOWCoupler\n",
    "from symfluence.models.modflow.extractor import MODFLOWResultExtractor\n",
    "\n",
    "# Get basin area for unit conversions\n",
    "basin_path = project_dir / 'shapefiles' / 'river_basins' / f\"{config.domain.name}_riverBasins_lumped.shp\"\n",
    "watershed_gdf = gpd.read_file(str(basin_path))\n",
    "watershed_proj = watershed_gdf.to_crs('EPSG:32610')  # UTM Zone 10N\n",
    "basin_area_m2 = watershed_proj.geometry.area.sum()\n",
    "basin_area_km2 = basin_area_m2 / 1e6\n",
    "print(f\"Basin area: {basin_area_km2:.2f} km\\u00b2\")\n",
    "\n",
    "# Initialize coupler and extractor\n",
    "coupler = SUMMAToMODFLOWCoupler(config.to_dict(flatten=True))\n",
    "extractor = MODFLOWResultExtractor()\n",
    "\n",
    "summa_dir = project_dir / 'simulations' / config.domain.experiment_id / 'SUMMA'\n",
    "modflow_dir = project_dir / 'simulations' / config.domain.experiment_id / 'MODFLOW'\n",
    "\n",
    "# Extract recharge (SUMMA -> MODFLOW)\n",
    "recharge = coupler.extract_recharge_from_summa(summa_dir, variable='scalarSoilDrainage')\n",
    "print(f\"Recharge: {len(recharge)} timesteps, mean = {recharge.mean():.4f} m/d\")\n",
    "\n",
    "# Extract fast runoff from SUMMA (total routed runoff minus soil drainage)\n",
    "# scalarSurfaceRunoff is only Hortonian overland flow (near-zero for most catchments).\n",
    "# The correct fast-flow component is: averageRoutedRunoff - scalarSoilDrainage\n",
    "fast_runoff = coupler.extract_fast_runoff(summa_dir)\n",
    "print(f\"Fast runoff: {len(fast_runoff)} timesteps, mean = {fast_runoff.mean():.6e} m/s\")\n",
    "\n",
    "# Extract drain discharge from MODFLOW\n",
    "drain_discharge = extractor.extract_variable(\n",
    "    modflow_dir, variable_type='drain_discharge',\n",
    "    start_date=str(config.domain.time_start)[:10],\n",
    ")\n",
    "print(f\"Drain discharge: {len(drain_discharge)} timesteps, mean = {drain_discharge.mean():.2f} m3/d\")\n",
    "\n",
    "# Combine flows (fast runoff is in m/s, same units as surface_runoff was)\n",
    "total_flow = coupler.combine_flows(fast_runoff, drain_discharge, basin_area_m2)\n",
    "\n",
    "# Convert components for plotting\n",
    "fast_m3s = fast_runoff * basin_area_m2\n",
    "fast_m3s.index = fast_m3s.index.normalize()\n",
    "baseflow_m3s = drain_discharge / 86400.0\n",
    "baseflow_m3s.index = baseflow_m3s.index.normalize()\n",
    "\n",
    "# === Coupling plots ===\n",
    "fig, axes = plt.subplots(3, 1, figsize=(14, 12), sharex=True)\n",
    "\n",
    "# Panel 1: Recharge time series (SUMMA -> MODFLOW)\n",
    "axes[0].fill_between(recharge.index, recharge.values, alpha=0.6, color='steelblue')\n",
    "axes[0].set_ylabel('Recharge (m/d)')\n",
    "axes[0].set_title('SUMMA Soil Drainage \\u2192 MODFLOW Recharge', fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Panel 2: Flow components\n",
    "common_idx = fast_m3s.index.intersection(baseflow_m3s.index)\n",
    "if len(common_idx) > 0:\n",
    "    fast_plot = fast_m3s.loc[common_idx]\n",
    "    base_plot = baseflow_m3s.loc[common_idx]\n",
    "    axes[1].fill_between(common_idx, fast_plot.values, alpha=0.6, color='coral', label='Fast runoff (routed - drainage)')\n",
    "    axes[1].fill_between(common_idx, fast_plot.values, fast_plot.values + base_plot.values,\n",
    "                         alpha=0.6, color='steelblue', label='MODFLOW baseflow')\n",
    "    axes[1].set_ylabel('Discharge (m\\u00b3/s)')\n",
    "    axes[1].set_title('Flow Component Breakdown', fontweight='bold')\n",
    "    axes[1].legend(loc='upper right')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Panel 3: Combined streamflow\n",
    "axes[2].plot(total_flow.index, total_flow.values, 'k-', linewidth=1.5, label='Combined streamflow')\n",
    "axes[2].set_ylabel('Discharge (m\\u00b3/s)')\n",
    "axes[2].set_xlabel('Date')\n",
    "axes[2].set_title('Combined Streamflow (Fast Runoff + Baseflow)', fontweight='bold')\n",
    "axes[2].legend(loc='upper right')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Sagehen Creek \\u2014 SUMMA-MODFLOW Coupling Overview', fontsize=14, fontweight='bold', y=1.01)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print baseflow index\n",
    "if len(common_idx) > 0:\n",
    "    total_mean = (fast_plot + base_plot).mean()\n",
    "    bfi = base_plot.mean() / total_mean if total_mean > 0 else 0\n",
    "    print(f\"\\nBaseflow Index (BFI): {bfi:.2f}\")\n",
    "    print(f\"Mean fast runoff: {fast_plot.mean():.4f} m\\u00b3/s\")\n",
    "    print(f\"Mean baseflow: {base_plot.mean():.4f} m\\u00b3/s\")\n",
    "    print(f\"Mean total flow: {total_mean:.4f} m\\u00b3/s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 — Evaluation and Calibration\n",
    "\n",
    "Compare simulated combined streamflow against USGS observations and calibrate parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5a — Uncalibrated Evaluation\n",
    "\n",
    "Evaluate the uncalibrated coupled model against USGS observations at station 10343500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5a — Uncalibrated evaluation\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "\n",
    "# Load observed streamflow\n",
    "obs_path = project_dir / 'observations' / 'streamflow' / 'preprocessed' / f\"{config.domain.name}_streamflow_processed.csv\"\n",
    "obs_df = pd.read_csv(obs_path, parse_dates=['datetime'])\n",
    "obs_df.set_index('datetime', inplace=True)\n",
    "\n",
    "# Use the combined flow from Step 4d (already computed)\n",
    "sim_daily = total_flow.copy()\n",
    "sim_daily.name = 'discharge_sim'\n",
    "\n",
    "# Exclude spinup period\n",
    "spinup_end = pd.to_datetime(config.domain.spinup_period.split(',')[1].strip())\n",
    "print(f\"Excluding spinup period up to: {spinup_end}\")\n",
    "\n",
    "# Resample observations to daily for comparison with MODFLOW daily output\n",
    "obs_daily = obs_df['discharge_cms'].resample('D').mean().dropna()\n",
    "\n",
    "# Align observed and simulated\n",
    "common_idx = obs_daily.index.intersection(sim_daily.index)\n",
    "common_idx = common_idx[common_idx > spinup_end]\n",
    "\n",
    "obs_valid = obs_daily.loc[common_idx]\n",
    "sim_valid = sim_daily.loc[common_idx]\n",
    "\n",
    "print(f\"Evaluation period: {obs_valid.index[0]} to {obs_valid.index[-1]}\")\n",
    "print(f\"Number of timesteps: {len(obs_valid)}\")\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "def nse(obs, sim):\n",
    "    return float(1 - np.sum((obs - sim)**2) / np.sum((obs - obs.mean())**2))\n",
    "\n",
    "def kge(obs, sim):\n",
    "    r = obs.corr(sim)\n",
    "    alpha = sim.std() / obs.std()\n",
    "    beta = sim.mean() / obs.mean()\n",
    "    return float(1 - np.sqrt((r-1)**2 + (alpha-1)**2 + (beta-1)**2))\n",
    "\n",
    "def pbias(obs, sim):\n",
    "    return float(100 * (sim.sum() - obs.sum()) / obs.sum())\n",
    "\n",
    "uncal_metrics = {\n",
    "    'NSE': round(nse(obs_valid, sim_valid), 3),\n",
    "    'KGE': round(kge(obs_valid, sim_valid), 3),\n",
    "    'PBIAS': round(pbias(obs_valid, sim_valid), 1)\n",
    "}\n",
    "\n",
    "print(f\"\\nPerformance Metrics (Uncalibrated):\")\n",
    "for k, v in uncal_metrics.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization — standard evaluation plots + flow component breakdown\n",
    "\n",
    "fig, axes = plt.subplots(3, 2, figsize=(14, 14))\n",
    "\n",
    "# --- Row 1: Time series (top left) ---\n",
    "axes[0, 0].plot(obs_valid.index, obs_valid.values, 'b-', label='Observed (USGS)', linewidth=1.2, alpha=0.7)\n",
    "axes[0, 0].plot(sim_valid.index, sim_valid.values, 'r-', label='Simulated (SUMMA+MODFLOW)', linewidth=1.2, alpha=0.7)\n",
    "axes[0, 0].set_ylabel('Discharge (m\\u00b3/s)')\n",
    "axes[0, 0].set_title('Streamflow Time Series')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "axes[0, 0].text(0.02, 0.95, f\"NSE: {uncal_metrics['NSE']}\\nKGE: {uncal_metrics['KGE']}\\nBias: {uncal_metrics['PBIAS']}%\",\n",
    "                transform=axes[0, 0].transAxes, verticalalignment='top',\n",
    "                bbox=dict(facecolor='white', alpha=0.8), fontsize=9)\n",
    "\n",
    "# --- Row 1: Scatter (top right) ---\n",
    "axes[0, 1].scatter(obs_valid, sim_valid, alpha=0.5, s=10)\n",
    "max_val = max(obs_valid.max(), sim_valid.max())\n",
    "axes[0, 1].plot([0, max_val], [0, max_val], 'k--', alpha=0.5)\n",
    "axes[0, 1].set_xlabel('Observed (m\\u00b3/s)')\n",
    "axes[0, 1].set_ylabel('Simulated (m\\u00b3/s)')\n",
    "axes[0, 1].set_title('Observed vs Simulated')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# --- Row 2: Monthly climatology (middle left) ---\n",
    "monthly_obs = obs_valid.groupby(obs_valid.index.month).mean()\n",
    "monthly_sim = sim_valid.groupby(sim_valid.index.month).mean()\n",
    "month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n",
    "               'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "axes[1, 0].plot(monthly_obs.index, monthly_obs.values, 'b-o', label='Observed', markersize=6)\n",
    "axes[1, 0].plot(monthly_sim.index, monthly_sim.values, 'r-o', label='Simulated', markersize=6)\n",
    "axes[1, 0].set_xticks(range(1, 13))\n",
    "axes[1, 0].set_xticklabels(month_names)\n",
    "axes[1, 0].set_ylabel('Mean Discharge (m\\u00b3/s)')\n",
    "axes[1, 0].set_title('Seasonal Flow Regime')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# --- Row 2: Flow duration curve (middle right) ---\n",
    "obs_sorted = obs_valid.sort_values(ascending=False)\n",
    "sim_sorted = sim_valid.sort_values(ascending=False)\n",
    "obs_ranks = np.arange(1., len(obs_sorted) + 1) / len(obs_sorted) * 100\n",
    "sim_ranks = np.arange(1., len(sim_sorted) + 1) / len(sim_sorted) * 100\n",
    "axes[1, 1].semilogy(obs_ranks, obs_sorted, 'b-', label='Observed', linewidth=2)\n",
    "axes[1, 1].semilogy(sim_ranks, sim_sorted, 'r-', label='Simulated', linewidth=2)\n",
    "axes[1, 1].set_xlabel('Exceedance Probability (%)')\n",
    "axes[1, 1].set_ylabel('Discharge (m\\u00b3/s)')\n",
    "axes[1, 1].set_title('Flow Duration Curve')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# --- Row 3: Flow component breakdown (bottom left) ---\n",
    "comp_idx = fast_m3s.index.intersection(baseflow_m3s.index)\n",
    "comp_idx = comp_idx[comp_idx > spinup_end]\n",
    "if len(comp_idx) > 0:\n",
    "    fast_eval = fast_m3s.loc[comp_idx]\n",
    "    base_eval = baseflow_m3s.loc[comp_idx]\n",
    "    axes[2, 0].fill_between(comp_idx, 0, fast_eval.values, alpha=0.6, color='coral', label='Fast runoff')\n",
    "    axes[2, 0].fill_between(comp_idx, fast_eval.values, fast_eval.values + base_eval.values,\n",
    "                            alpha=0.6, color='steelblue', label='MODFLOW baseflow')\n",
    "    axes[2, 0].plot(obs_valid.index, obs_valid.values, 'k-', linewidth=1, alpha=0.7, label='Observed')\n",
    "axes[2, 0].set_ylabel('Discharge (m\\u00b3/s)')\n",
    "axes[2, 0].set_xlabel('Date')\n",
    "axes[2, 0].set_title('Flow Components vs Observed')\n",
    "axes[2, 0].legend(loc='upper right')\n",
    "axes[2, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# --- Row 3: Monthly baseflow fraction (bottom right) ---\n",
    "if len(comp_idx) > 0:\n",
    "    monthly_fast = fast_eval.groupby(fast_eval.index.month).mean()\n",
    "    monthly_base = base_eval.groupby(base_eval.index.month).mean()\n",
    "    monthly_total = monthly_fast + monthly_base\n",
    "\n",
    "    bars1 = axes[2, 1].bar(range(1, 13), monthly_fast.values, color='coral', alpha=0.7, label='Fast runoff')\n",
    "    bars2 = axes[2, 1].bar(range(1, 13), monthly_base.values, bottom=monthly_fast.values,\n",
    "                           color='steelblue', alpha=0.7, label='Baseflow')\n",
    "    axes[2, 1].set_xticks(range(1, 13))\n",
    "    axes[2, 1].set_xticklabels(month_names)\n",
    "    axes[2, 1].set_ylabel('Mean Discharge (m\\u00b3/s)')\n",
    "    axes[2, 1].set_title('Monthly Flow Partitioning')\n",
    "    axes[2, 1].legend()\n",
    "    axes[2, 1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.suptitle('Sagehen Creek \\u2014 Uncalibrated SUMMA+MODFLOW Evaluation', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nUncalibrated evaluation complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5b — Calibration\n",
    "\n",
    "Calibrate 17 parameters jointly using DDS (Dynamically Dimensioned Search):\n",
    "- **14 SUMMA parameters**: albedo, snow density, soil hydraulics, precipitation phase, surface runoff scaling, routing\n",
    "- **3 MODFLOW parameters**: hydraulic conductivity (K), specific yield (SY), drain conductance\n",
    "\n",
    "The optimizer jointly adjusts both SUMMA and MODFLOW parameters to maximize KGE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5b — Run calibration\n",
    "print(f\"Starting coupled calibration...\")\n",
    "print(f\"Algorithm: {config.optimization.algorithm}\")\n",
    "print(f\"Metric: {config.optimization.metric}\")\n",
    "print(f\"Iterations: {config.optimization.iterations}\")\n",
    "print(f\"Calibration period: {config.domain.calibration_period}\")\n",
    "print(f\"Parameters: 14 SUMMA + 3 MODFLOW = 17 total\")\n",
    "\n",
    "results_file = sf.managers['optimization'].calibrate_model()\n",
    "print(f\"\\nCalibration complete!\")\n",
    "print(f\"Results file: {results_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Calibration Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display calibration results\n",
    "import json as _json\n",
    "\n",
    "# Find results matching our experiment_id\n",
    "opt_base = project_dir / 'optimization' / 'COUPLED_GW'\n",
    "exp_id = config.domain.experiment_id\n",
    "run_dir = opt_base / f'dds_{exp_id}'\n",
    "\n",
    "# Fallback: search for any dds run\n",
    "if not run_dir.exists():\n",
    "    run_dirs = sorted(opt_base.glob('dds_workshop_run_*')) if opt_base.exists() else []\n",
    "    if not run_dirs:\n",
    "        opt_base = project_dir / 'optimization' / 'SUMMA'\n",
    "        run_dirs = sorted(opt_base.glob('dds_*'))\n",
    "    run_dir = run_dirs[-1] if run_dirs else None\n",
    "\n",
    "if run_dir and run_dir.exists():\n",
    "    csv_files = list(run_dir.glob('*_parallel_iteration_results.csv'))\n",
    "    bp_files = list(run_dir.glob('*_best_params.json'))\n",
    "    fe_files = list(run_dir.glob('*_final_evaluation.json'))\n",
    "\n",
    "    if csv_files:\n",
    "        results_df = pd.read_csv(csv_files[0])\n",
    "        # Compute running best\n",
    "        results_df['best_score'] = results_df['score'].cummax()\n",
    "\n",
    "        print(f\"Calibration Progress ({run_dir.name}):\")\n",
    "        print(f\"  Best {config.optimization.metric}: {results_df['score'].max():.4f}\")\n",
    "        print(f\"  Initial {config.optimization.metric}: {results_df['score'].iloc[0]:.4f}\")\n",
    "        print(f\"  Improvement: {results_df['score'].max() - results_df['score'].iloc[0]:.4f}\")\n",
    "        print(f\"  Total iterations: {len(results_df)}\")\n",
    "        if 'crash_rate' in results_df.columns:\n",
    "            print(f\"  Crash rate: {results_df['crash_rate'].iloc[-1]:.1%}\")\n",
    "\n",
    "        # Plot calibration progress\n",
    "        fig, ax = plt.subplots(figsize=(10, 5))\n",
    "        ax.scatter(results_df['iteration'], results_df['score'],\n",
    "                   alpha=0.3, s=10, color='gray', label='Per-iteration')\n",
    "        ax.plot(results_df['iteration'], results_df['best_score'],\n",
    "                'b-', linewidth=2, label='Running best')\n",
    "        ax.set_xlabel('Iteration')\n",
    "        ax.set_ylabel(f'Best {config.optimization.metric}')\n",
    "        ax.set_title('Coupled SUMMA-MODFLOW Calibration Progress (DDS)')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # Show calibrated parameters\n",
    "        modflow_params = ['K', 'SY', 'DRAIN_CONDUCTANCE']\n",
    "        best_idx = results_df['score'].idxmax()\n",
    "        best_row = results_df.loc[best_idx]\n",
    "        print(f\"\\nCalibrated MODFLOW parameters:\")\n",
    "        for p in modflow_params:\n",
    "            if p in results_df.columns:\n",
    "                print(f\"  {p}: {best_row[p]:.4f}\")\n",
    "\n",
    "    # Show final evaluation if available\n",
    "    if fe_files:\n",
    "        with open(fe_files[0]) as f:\n",
    "            fe_data = _json.load(f)\n",
    "        print(f\"\\nFinal Evaluation:\")\n",
    "        cal_m = fe_data.get('calibration_metrics', {})\n",
    "        eval_m = fe_data.get('evaluation_metrics', {})\n",
    "        print(f\"  Calibration  KGE={cal_m.get('KGE', 'N/A'):.3f}, NSE={cal_m.get('NSE', 'N/A'):.3f}, PBIAS={cal_m.get('PBIAS', 'N/A'):.1f}%\")\n",
    "        print(f\"  Evaluation   KGE={eval_m.get('KGE', 'N/A'):.3f}, NSE={eval_m.get('NSE', 'N/A'):.3f}, PBIAS={eval_m.get('PBIAS', 'N/A'):.1f}%\")\n",
    "else:\n",
    "    print(\"No calibration results found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5c — Post-Calibration Evaluation\n",
    "\n",
    "Re-run the coupled model with calibrated parameters and evaluate performance improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5c — Post-calibration evaluation\n",
    "# Re-extract combined streamflow from the calibrated final evaluation run\n",
    "\n",
    "from symfluence.models.modflow.coupling import SUMMAToMODFLOWCoupler\n",
    "from symfluence.models.modflow.extractor import MODFLOWResultExtractor\n",
    "\n",
    "# Find the calibration output matching our experiment_id\n",
    "opt_dir = project_dir / 'optimization' / 'COUPLED_GW'\n",
    "exp_id = config.domain.experiment_id\n",
    "best_dir = opt_dir / f'dds_{exp_id}'\n",
    "\n",
    "# Fallback to most recent run if exact match not found\n",
    "if not best_dir.exists():\n",
    "    cal_dirs = sorted(opt_dir.glob('dds_workshop_run_*')) if opt_dir.exists() else []\n",
    "    best_dir = cal_dirs[-1] if cal_dirs else None\n",
    "\n",
    "if best_dir and best_dir.exists():\n",
    "    print(f\"Using calibration run: {best_dir.name}\")\n",
    "\n",
    "    # Use final_evaluation subdirectory (contains calibrated SUMMA + MODFLOW output)\n",
    "    final_eval_dir = best_dir / 'final_evaluation'\n",
    "    cal_summa_dir = final_eval_dir / 'SUMMA' if final_eval_dir.exists() else best_dir / 'SUMMA'\n",
    "    cal_modflow_dir = final_eval_dir / 'MODFLOW' if final_eval_dir.exists() else best_dir / 'MODFLOW'\n",
    "\n",
    "    print(f\"  SUMMA output: {cal_summa_dir}\")\n",
    "    print(f\"  MODFLOW output: {cal_modflow_dir}\")\n",
    "\n",
    "    if cal_summa_dir.exists() and cal_modflow_dir.exists():\n",
    "        cal_coupler = SUMMAToMODFLOWCoupler(config.to_dict(flatten=True))\n",
    "        cal_extractor = MODFLOWResultExtractor()\n",
    "\n",
    "        cal_recharge = cal_coupler.extract_recharge_from_summa(cal_summa_dir)\n",
    "        cal_fast = cal_coupler.extract_fast_runoff(cal_summa_dir)\n",
    "        cal_drain = cal_extractor.extract_variable(\n",
    "            cal_modflow_dir, variable_type='drain_discharge',\n",
    "            start_date=str(config.domain.time_start)[:10],\n",
    "        )\n",
    "        cal_total = cal_coupler.combine_flows(cal_fast, cal_drain, basin_area_m2)\n",
    "\n",
    "        # Evaluate calibrated model\n",
    "        spinup_end_str = config.domain.spinup_period.split(',')[1].strip()\n",
    "        spinup_end_local = pd.to_datetime(spinup_end_str)\n",
    "        cal_common = obs_daily.index.intersection(cal_total.index)\n",
    "        cal_common = cal_common[cal_common > spinup_end_local]\n",
    "\n",
    "        obs_cal = obs_daily.loc[cal_common]\n",
    "        sim_cal = cal_total.loc[cal_common]\n",
    "\n",
    "        cal_metrics = {\n",
    "            'NSE': round(nse(obs_cal, sim_cal), 3),\n",
    "            'KGE': round(kge(obs_cal, sim_cal), 3),\n",
    "            'PBIAS': round(pbias(obs_cal, sim_cal), 1)\n",
    "        }\n",
    "\n",
    "        print(f\"\\nPerformance Metrics (Calibrated):\")\n",
    "        for k, v in cal_metrics.items():\n",
    "            print(f\"  {k}: {v}\")\n",
    "\n",
    "        # Comparison plot\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "        # Time series\n",
    "        axes[0, 0].plot(obs_cal.index, obs_cal.values, 'b-', label='Observed (USGS)', linewidth=1.2, alpha=0.7)\n",
    "        axes[0, 0].plot(sim_cal.index, sim_cal.values, 'r-', label='Calibrated (SUMMA+MODFLOW)', linewidth=1.2, alpha=0.7)\n",
    "        axes[0, 0].set_ylabel('Discharge (m\\u00b3/s)')\n",
    "        axes[0, 0].set_title('Calibrated Streamflow')\n",
    "        axes[0, 0].legend()\n",
    "        axes[0, 0].grid(True, alpha=0.3)\n",
    "        axes[0, 0].text(0.02, 0.95, f\"NSE: {cal_metrics['NSE']}\\nKGE: {cal_metrics['KGE']}\\nBias: {cal_metrics['PBIAS']}%\",\n",
    "                        transform=axes[0, 0].transAxes, verticalalignment='top',\n",
    "                        bbox=dict(facecolor='white', alpha=0.8), fontsize=9)\n",
    "\n",
    "        # Scatter\n",
    "        axes[0, 1].scatter(obs_cal, sim_cal, alpha=0.5, s=10)\n",
    "        max_val = max(obs_cal.max(), sim_cal.max())\n",
    "        axes[0, 1].plot([0, max_val], [0, max_val], 'k--', alpha=0.5)\n",
    "        axes[0, 1].set_xlabel('Observed (m\\u00b3/s)')\n",
    "        axes[0, 1].set_ylabel('Simulated (m\\u00b3/s)')\n",
    "        axes[0, 1].set_title('Observed vs Simulated (Calibrated)')\n",
    "        axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "        # Monthly climatology\n",
    "        monthly_obs_c = obs_cal.groupby(obs_cal.index.month).mean()\n",
    "        monthly_sim_c = sim_cal.groupby(sim_cal.index.month).mean()\n",
    "        axes[1, 0].plot(monthly_obs_c.index, monthly_obs_c.values, 'b-o', label='Observed', markersize=6)\n",
    "        axes[1, 0].plot(monthly_sim_c.index, monthly_sim_c.values, 'r-o', label='Calibrated', markersize=6)\n",
    "        axes[1, 0].set_xticks(range(1, 13))\n",
    "        axes[1, 0].set_xticklabels(month_names)\n",
    "        axes[1, 0].set_ylabel('Mean Discharge (m\\u00b3/s)')\n",
    "        axes[1, 0].set_title('Seasonal Flow Regime (Calibrated)')\n",
    "        axes[1, 0].legend()\n",
    "        axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "        # Flow duration curve\n",
    "        obs_s = obs_cal.sort_values(ascending=False)\n",
    "        sim_s = sim_cal.sort_values(ascending=False)\n",
    "        obs_r = np.arange(1., len(obs_s) + 1) / len(obs_s) * 100\n",
    "        sim_r = np.arange(1., len(sim_s) + 1) / len(sim_s) * 100\n",
    "        axes[1, 1].semilogy(obs_r, obs_s, 'b-', label='Observed', linewidth=2)\n",
    "        axes[1, 1].semilogy(sim_r, sim_s, 'r-', label='Calibrated', linewidth=2)\n",
    "        axes[1, 1].set_xlabel('Exceedance Probability (%)')\n",
    "        axes[1, 1].set_ylabel('Discharge (m\\u00b3/s)')\n",
    "        axes[1, 1].set_title('Flow Duration Curve (Calibrated)')\n",
    "        axes[1, 1].legend()\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "        plt.suptitle('Sagehen Creek \\u2014 Calibrated SUMMA+MODFLOW Evaluation', fontsize=14, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"Calibrated output directories not found at expected locations.\")\n",
    "        print(f\"  Checked: {cal_summa_dir}\")\n",
    "        print(f\"  Checked: {cal_modflow_dir}\")\n",
    "        cal_metrics = uncal_metrics\n",
    "else:\n",
    "    print(\"No calibration output directories found.\")\n",
    "    cal_metrics = uncal_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5d — Flow Decomposition Analysis\n",
    "\n",
    "Decompose total simulated streamflow into MODFLOW groundwater baseflow and SUMMA surface runoff components, and compare against observed USGS streamflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5d — Flow Decomposition\n",
    "\n",
    "import json, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from symfluence.models.modflow.coupling import SUMMAToMODFLOWCoupler\n",
    "from symfluence.models.modflow.extractor import MODFLOWResultExtractor\n",
    "\n",
    "# --- Data extraction (same as before) ---\n",
    "opt_dir = project_dir / 'optimization' / 'COUPLED_GW'\n",
    "exp_id = config.domain.experiment_id\n",
    "best_run = opt_dir / f'dds_{exp_id}'\n",
    "if not best_run.exists():\n",
    "    run_dirs = sorted(opt_dir.glob('dds_workshop_run_*')) if opt_dir.exists() else []\n",
    "    best_run = run_dirs[-1] if run_dirs else None\n",
    "\n",
    "final_eval_dir = best_run / 'final_evaluation' if best_run else None\n",
    "if final_eval_dir and final_eval_dir.exists():\n",
    "    summa_dir, modflow_dir = final_eval_dir / 'SUMMA', final_eval_dir / 'MODFLOW'\n",
    "else:\n",
    "    summa_dir = project_dir / 'simulations' / exp_id / 'SUMMA'\n",
    "    modflow_dir = project_dir / 'simulations' / exp_id / 'MODFLOW'\n",
    "\n",
    "config_dict = config.to_dict(flatten=True)\n",
    "coupler = SUMMAToMODFLOWCoupler(config_dict)\n",
    "extractor = MODFLOWResultExtractor()\n",
    "\n",
    "fast_runoff = coupler.extract_fast_runoff(summa_dir)\n",
    "drain_discharge = extractor.extract_variable(\n",
    "    modflow_dir, 'drain_discharge',\n",
    "    start_date=str(config.domain.time_start)[:10], stress_period_length=1.0)\n",
    "\n",
    "import xarray as xr\n",
    "with xr.open_dataset(project_dir / 'settings' / 'SUMMA' / 'attributes.nc') as ds:\n",
    "    A = float(ds['HRUarea'].values.sum())\n",
    "\n",
    "total_flow = coupler.combine_flows(fast_runoff, drain_discharge, A)\n",
    "surf = (fast_runoff * A).copy(); surf.index = pd.to_datetime(surf.index)\n",
    "base = (drain_discharge.abs() / 86400.0).copy(); base.index = pd.to_datetime(base.index)\n",
    "\n",
    "obs_csv = sorted((project_dir / 'observations' / 'streamflow' / 'preprocessed').glob('*.csv'))[0]\n",
    "obs_daily = pd.read_csv(obs_csv, parse_dates=['datetime']).set_index('datetime')['discharge_cms'].resample('D').mean().dropna()\n",
    "\n",
    "t0 = pd.Timestamp('2017-01-01')\n",
    "cal_end = pd.Timestamp(config.domain.calibration_period.split(',')[1].strip())\n",
    "ci = total_flow.index.intersection(obs_daily.index)\n",
    "ci = ci[ci >= t0]\n",
    "\n",
    "obs, sim = obs_daily.loc[ci], total_flow.reindex(ci).fillna(0)\n",
    "bf, sf = base.reindex(ci).fillna(0), surf.reindex(ci).fillna(0)\n",
    "\n",
    "def kge(o, s):\n",
    "    r = np.corrcoef(o, s)[0,1]; return 1 - np.sqrt((r-1)**2 + (np.std(s)/np.std(o)-1)**2 + (np.mean(s)/np.mean(o)-1)**2)\n",
    "\n",
    "# ============================================================================\n",
    "# Minimal 2-panel figure\n",
    "# ============================================================================\n",
    "plt.rcParams.update({'font.size': 10, 'axes.spines.top': False, 'axes.spines.right': False})\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 7), height_ratios=[3, 1.2],\n",
    "                                sharex=False, gridspec_kw={'hspace': 0.35})\n",
    "\n",
    "# --- Top: smoothed hydrograph ---\n",
    "w = 7\n",
    "bf_s, sf_s, obs_s = [s.rolling(w, center=True, min_periods=1).mean() for s in (bf, sf, obs)]\n",
    "\n",
    "ax1.fill_between(ci, 0, bf_s, color='#4A90D9', alpha=0.5, lw=0)\n",
    "ax1.fill_between(ci, bf_s, bf_s + sf_s, color='#F5A623', alpha=0.5, lw=0)\n",
    "ax1.plot(ci, obs_s, color='#333', lw=1.0, alpha=0.9)\n",
    "\n",
    "# Eval period shading\n",
    "\n",
    "ax1.set_ylabel('Q (m\\u00b3/s)')\n",
    "ax1.set_ylim(bottom=0)\n",
    "ax1.xaxis.set_major_locator(mdates.YearLocator())\n",
    "ax1.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "ax1.tick_params(axis='x', length=0)\n",
    "\n",
    "# Minimal legend\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.lines import Line2D\n",
    "handles = [\n",
    "    Patch(fc='#4A90D9', alpha=0.5, label='Baseflow'),\n",
    "    Patch(fc='#F5A623', alpha=0.5, label='Surface'),\n",
    "    Line2D([0],[0], color='#333', lw=1, label='Observed'),\n",
    "]\n",
    "ax1.legend(handles=handles, loc='upper right', frameon=False, fontsize=9, ncol=3)\n",
    "\n",
    "# KGE annotation\n",
    "ax1.text(0.01, 0.96, f'KGE = {kge(obs.values, sim.values):.3f}',\n",
    "         transform=ax1.transAxes, va='top', fontsize=11, fontweight='bold', color='#333')\n",
    "\n",
    "# Period labels\n",
    "\n",
    "# --- Bottom: monthly stacked bars ---\n",
    "mn = ['J','F','M','A','M','J','J','A','S','O','N','D']\n",
    "mo = np.arange(1, 13)\n",
    "m_bf = bf.groupby(bf.index.month).mean().reindex(mo).fillna(0).values\n",
    "m_sf = sf.groupby(sf.index.month).mean().reindex(mo).fillna(0).values\n",
    "m_obs = obs.groupby(obs.index.month).mean().reindex(mo).fillna(0).values\n",
    "m_bfi = np.where(m_bf + m_sf > 0, m_bf / (m_bf + m_sf) * 100, 0)\n",
    "\n",
    "x = np.arange(12)\n",
    "ax2.bar(x, m_bf, 0.55, color='#4A90D9', alpha=0.65, lw=0)\n",
    "ax2.bar(x, m_sf, 0.55, bottom=m_bf, color='#F5A623', alpha=0.65, lw=0)\n",
    "ax2.scatter(x, m_obs, s=28, color='#333', zorder=5, marker='o')\n",
    "\n",
    "# BFI on secondary axis\n",
    "ax2b = ax2.twinx()\n",
    "ax2b.plot(x, m_bfi, color='navy', lw=1.2, ls='--', alpha=0.6, marker='.', ms=4)\n",
    "ax2b.set_ylabel('BFI %', fontsize=9, color='navy')\n",
    "ax2b.set_ylim(0, 105)\n",
    "ax2b.tick_params(axis='y', colors='navy', labelsize=8)\n",
    "ax2b.spines['right'].set_visible(True)\n",
    "ax2b.spines['right'].set_color('navy')\n",
    "ax2b.spines['right'].set_alpha(0.3)\n",
    "ax2b.spines['top'].set_visible(False)\n",
    "\n",
    "ax2.set_xticks(x)\n",
    "ax2.set_xticklabels(mn, fontsize=9)\n",
    "ax2.set_ylabel('Mean Q (m\\u00b3/s)')\n",
    "ax2.set_xlim(-0.6, 11.6)\n",
    "ax2.tick_params(axis='x', length=0)\n",
    "\n",
    "fig.suptitle('Sagehen Creek — Flow Decomposition', fontsize=13, fontweight='bold', y=0.98)\n",
    "\n",
    "plots_dir = project_dir / 'plots'\n",
    "plots_dir.mkdir(exist_ok=True)\n",
    "plt.savefig(str(plots_dir / 'flow_decomposition.png'), dpi=200, bbox_inches='tight',\n",
    "            facecolor='white', edgecolor='none')\n",
    "plt.show()\n",
    "\n",
    "# Summary\n",
    "mean_bfi = np.nanmean(m_bfi[m_bfi > 0])\n",
    "print(f'Baseflow: {bf.mean():.3f} m\\u00b3/s ({bf.mean()/(bf.mean()+sf.mean())*100:.0f}%)  |  '\n",
    "      f'Surface: {sf.mean():.3f} m\\u00b3/s ({sf.mean()/(bf.mean()+sf.mean())*100:.0f}%)  |  '\n",
    "      f'BFI: {mean_bfi:.0f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (symfluence-root)",
   "language": "python",
   "name": "symfluence-root"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
