{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SYMFLUENCE Tutorial 1b — Point-Scale Workflow (FLUXNET CA-NS7)\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook mirrors the configuration-first style established in **Tutorial 01a** and adapts it for **energy-balance validation at a FLUXNET tower (CA-NS7)**. We simulate point-scale land–atmosphere exchanges and evaluate **evapotranspiration (LE)** and **sensible heat (H)** using FLUXNET observations.\n",
    "\n",
    "The workflow is strictly configuration-driven and fully reproducible:\n",
    "1. Create a typed config with `SymfluenceConfig.from_minimal()`\n",
    "2. Initialize SYMFLUENCE and standard project layout\n",
    "3. Define the point-scale domain\n",
    "4. Acquire & preprocess inputs\n",
    "5. Run **SUMMA**\n",
    "6. Evaluate and calibrate energy fluxes\n",
    "\n",
    "### What you will learn\n",
    "\n",
    "1. **Energy-balance evaluation** — Compare simulated LE/H against FLUXNET tower data\n",
    "2. **ET-focused calibration** — Calibrate vegetation and canopy parameters using DE\n",
    "3. **FLUXNET integration** — Use FLUXNET tower data as the observation source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment setup — HDF5 locking workaround and verification\n",
    "#\n",
    "# The HDF5_USE_FILE_LOCKING='FALSE' setting prevents file-locking errors\n",
    "# that can occur on certain filesystems (NFS, FUSE, conda-managed HDF stacks).\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "os.environ['HDF5_USE_FILE_LOCKING'] = 'FALSE'\n",
    "\n",
    "warnings.filterwarnings('ignore', message='.*is an EXPERIMENTAL module.*')\n",
    "warnings.filterwarnings('ignore', message='.*import failed.*')\n",
    "\n",
    "print(f\"Python executable: {sys.executable}\")\n",
    "\n",
    "try:\n",
    "    import symfluence\n",
    "    print(f\"SYMFLUENCE version: {symfluence.__version__}\")\n",
    "    print(f\"SYMFLUENCE location: {Path(symfluence.__file__).parent}\")\n",
    "except ImportError:\n",
    "    print(\"ERROR: SYMFLUENCE not found. Please activate the symfluence environment.\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 — Configuration\n",
    "\n",
    "We create a typed, validated configuration for the **CA-NS7** FLUXNET site using `SymfluenceConfig.from_minimal()`. This provides Pydantic-validated fields, smart model defaults, and frozen immutability.\n",
    "\n",
    "> **Note:** All configuration is frozen once created. If you need to change a setting (e.g., switch the calibration algorithm), you must re-create the config and re-initialize SYMFLUENCE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1a — Create typed configuration for CA-NS7 FLUXNET\n",
    "\n",
    "from pathlib import Path\n",
    "from symfluence.core.config.models import SymfluenceConfig\n",
    "\n",
    "# Resolve code and data directories\n",
    "# Convention: SYMFLUENCE_data sits alongside the SYMFLUENCE repo directory\n",
    "repo_root = Path(__file__).resolve().parent.parent.parent if '__file__' in dir() else Path.cwd().resolve()\n",
    "# Walk up until we find the repo root (contains src/symfluence)\n",
    "while repo_root != repo_root.parent:\n",
    "    if (repo_root / 'src' / 'symfluence').exists():\n",
    "        break\n",
    "    repo_root = repo_root.parent\n",
    "\n",
    "data_dir = repo_root.parent / 'SYMFLUENCE_data'\n",
    "if not data_dir.exists():\n",
    "    # Fallback: check environment variable or use default\n",
    "    import os\n",
    "    data_dir = Path(os.getenv('SYMFLUENCE_DATA_DIR', str(repo_root / 'data')))\n",
    "\n",
    "print(f\"Repo root: {repo_root}\")\n",
    "print(f\"Data dir:  {data_dir}\")\n",
    "\n",
    "config = SymfluenceConfig.from_minimal(\n",
    "    # === Identification ===\n",
    "    domain_name='CA-NS7',\n",
    "    experiment_id='run_fluxnet_1',\n",
    "\n",
    "    # === Paths ===\n",
    "    SYMFLUENCE_DATA_DIR=str(data_dir),\n",
    "    SYMFLUENCE_CODE_DIR=str(repo_root),\n",
    "\n",
    "    # === Model & Forcing ===\n",
    "    model='SUMMA',\n",
    "    forcing_dataset='ERA5',\n",
    "\n",
    "    # === Spatial Domain (point-scale) ===\n",
    "    definition_method='point',\n",
    "    discretization='GRUs',                          # 1 GRU => 1 HRU\n",
    "    pour_point_coords='56.6358/-99.9483',           # CA-NS7 coordinates\n",
    "    bounding_box_coords='56.6858/-99.9983/56.5858/-99.8983',\n",
    "\n",
    "    # === Temporal Extent ===\n",
    "    time_start='2001-01-01 01:00',\n",
    "    time_end='2005-12-31 23:00',\n",
    "    spinup_period='2001-01-01, 2002-09-30',\n",
    "    calibration_period='2002-10-01, 2003-09-30',\n",
    "    evaluation_period='2003-10-01, 2004-09-30',\n",
    "\n",
    "    # === Observations ===\n",
    "    DOWNLOAD_FLUXNET=True,\n",
    "    FLUXNET_STATION='CA-NS7',\n",
    "    ET_OBS_SOURCE='fluxnet',                        # Use FLUXNET tower data (not MODIS MOD16)\n",
    "\n",
    "    # === Calibration (Differential Evolution) ===\n",
    "    # DE is a generation-based algorithm that evaluates a full population each\n",
    "    # iteration, making it robust to occasional model failures from poor\n",
    "    # parameter combinations.\n",
    "    OPTIMIZATION_METHODS=['iteration'],\n",
    "    optimization_algorithm='DE',\n",
    "    optimization_metric='KGE',\n",
    "    optimization_target='et',\n",
    "    calibration_timestep='daily',\n",
    "    iterations=20,\n",
    "    POPULATION_SIZE=10,\n",
    "    PARAMS_TO_CALIBRATE='minStomatalResistance,cond2photo_slope,vcmax25_canopyTop,jmax25_scale,summerLAI,rootingDepth,z0Canopy,windReductionParam',\n",
    ")\n",
    "\n",
    "print(f\"\\nDomain:      {config.domain.name}\")\n",
    "print(f\"Model:       {config.model.hydrological_model}\")\n",
    "print(f\"Forcing:     {config.forcing.dataset}\")\n",
    "print(f\"Period:      {config.domain.time_start} to {config.domain.time_end}\")\n",
    "print(f\"Algorithm:   {config.optimization.algorithm}\")\n",
    "print(f\"Metric:      {config.optimization.metric}\")\n",
    "print(f\"Target:      {config.optimization.target}\")\n",
    "print(f\"Data dir:    {config.system.data_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1b — Initialize SYMFLUENCE & Project Setup\n",
    "\n",
    "Initialize the framework and create the standardized project directory. The config object is passed directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1b — Initialize SYMFLUENCE and create project structure\n",
    "\n",
    "from symfluence import SYMFLUENCE\n",
    "\n",
    "symfluence = SYMFLUENCE(config, visualize=True)\n",
    "\n",
    "# Create standardized project layout and pour-point feature\n",
    "project_dir = symfluence.managers['project'].setup_project()\n",
    "pour_point_path = symfluence.managers['project'].create_pour_point()\n",
    "\n",
    "print(f\"Project root: {project_dir}\")\n",
    "print(f\"Pour point:   {pour_point_path}\")\n",
    "\n",
    "# Brief top-level directory preview\n",
    "print(\"\\nTop-level structure:\")\n",
    "for p in sorted(Path(project_dir).iterdir()):\n",
    "    if p.is_dir():\n",
    "        print(f\"├── {p.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 — Domain Definition (point-scale GRU)\n",
    "\n",
    "The domain is a **single GRU** around the flux tower footprint, ensuring a strictly point-scale (non-routed) experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2a — Geospatial Attribute Acquisition\n",
    "\n",
    "Acquire site attributes (elevation, land cover, soils). These are model-agnostic inputs.\n",
    "\n",
    "- Uncomment the acquisition line below to download data (set `DATA_ACCESS` to `'cloud'` or `'maf'` in config)\n",
    "- Alternatively, copy pre-downloaded attributes, forcing, and observation directories into the domain directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2a — Acquire attributes (model-agnostic)\n",
    "# Uncomment to acquire data (set DATA_ACCESS to 'cloud' or 'maf' in config)\n",
    "# symfluence.managers['data'].acquire_attributes()\n",
    "print(\"Attribute acquisition complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2b — Domain Definition (point-scale)\n",
    "\n",
    "Define a minimal footprint around **CA-NS7** consistent with the pour point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2b — Define the point-scale domain\n",
    "watershed_path = symfluence.managers['domain'].define_domain()\n",
    "print(f\"Domain definition complete\")\n",
    "print(f\"Domain file: {watershed_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2c — Discretization\n",
    "\n",
    "Creates the **catchment HRU** artifacts required by downstream steps (1:1 with the GRU for point scale)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2c — Discretization (GRUs → HRUs 1:1)\n",
    "hru_path = symfluence.managers['domain'].discretize_domain()\n",
    "print(f\"Domain discretization complete\")\n",
    "print(f\"HRU file: {hru_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2d — Verification & Visualization\n",
    "\n",
    "Verify the expected shapefiles and draw the GRU–HRU overlay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2d — Verify domain outputs and visualize\n",
    "from IPython.display import Image, display\n",
    "\n",
    "plot_path = symfluence.managers['domain'].visualize_domain()\n",
    "print(f\"Domain plot saved to: {plot_path}\")\n",
    "\n",
    "if plot_path:\n",
    "    display(Image(filename=str(plot_path)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 — Input Preprocessing (model-agnostic)\n",
    "\n",
    "We prepare inputs in three steps:\n",
    "1. Acquire **meteorological forcings** (ERA5)\n",
    "2. Process **FLUXNET observations** (LE, H)\n",
    "3. Run **model-agnostic preprocessing** to standardize variables and time steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3a — Acquire Meteorological Forcings (ERA5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3a — Forcings\n",
    "# Uncomment to acquire data (set DATA_ACCESS to 'cloud' or 'maf' in config)\n",
    "# symfluence.managers['data'].acquire_forcings()\n",
    "print(\"Forcing data acquisition complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3b — Process Observations (FLUXNET)\n",
    "\n",
    "Parses FLUXNET tower observations (latent heat, sensible heat), applies QA/QC, and stores standardized outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3b — Observations\n",
    "# Uncomment to download and process observations\n",
    "# symfluence.managers['data'].process_observed_data()\n",
    "print(\"FLUXNET observational data processing complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3c — Model-Agnostic Preprocessing\n",
    "\n",
    "Standardizes variable names, units, and time steps so multiple models can consume the same inputs consistently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3c — Model-agnostic preprocessing\n",
    "symfluence.managers['data'].run_model_agnostic_preprocessing()\n",
    "print(\"Model-agnostic preprocessing complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3d — Verification\n",
    "\n",
    "Confirm the expected folders exist and contain files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3d — Verify preprocessing outputs\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "domain_dir = config.system.data_dir / f\"domain_{config.domain.name}\"\n",
    "\n",
    "targets = {\n",
    "    \"forcing/raw_data\":            domain_dir / \"forcing\" / \"raw_data\",\n",
    "    \"forcing/basin_averaged_data\": domain_dir / \"forcing\" / \"basin_averaged_data\",\n",
    "}\n",
    "\n",
    "def count_files(p: Path) -> int:\n",
    "    return sum(1 for x in p.iterdir() if x.is_file()) if p.exists() else 0\n",
    "\n",
    "for label, path in targets.items():\n",
    "    exists = path.exists()\n",
    "    n = count_files(path)\n",
    "    status = \"OK\" if exists and n > 0 else (\"empty\" if exists else \"missing\")\n",
    "    suffix = f\"({n} files)\" if exists else \"\"\n",
    "    print(f\"[{status:>7}] {label}  {suffix}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4 — Model-Specific Preprocessing & Run (SUMMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4a — SUMMA-Specific Preprocessing\n",
    "\n",
    "Creates the SUMMA input bundle (metadata, parameter tables, forcing links) from the standardized inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4a — SUMMA-specific preprocessing\n",
    "symfluence.managers['model'].preprocess_models()\n",
    "print(\"Model-specific preprocessing complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4b — Run the Model\n",
    "\n",
    "Executes the point-scale SUMMA simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4b — Run SUMMA\n",
    "print(f\"Running {config.model.hydrological_model} for point-scale simulation...\")\n",
    "symfluence.managers['model'].run_models()\n",
    "print(\"Point-scale model run complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4c — Verification\n",
    "\n",
    "Print where SUMMA inputs and run outputs were written."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4c — Verify SUMMA outputs\n",
    "\n",
    "domain_dir = config.system.data_dir / f\"domain_{config.domain.name}\"\n",
    "summa_in   = domain_dir / \"forcing\" / \"SUMMA_input\"\n",
    "results    = domain_dir / \"simulations\" / config.domain.experiment_id / \"SUMMA\"\n",
    "\n",
    "print(f\"SUMMA input dir: {summa_in if summa_in.exists() else '(not found)'}\")\n",
    "print(f\"Results dir:     {results if results.exists() else '(not found)'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5 — ET & H Evaluation (FLUXNET vs Simulation)\n",
    "\n",
    "Compare simulated latent heat (ET) and sensible heat against FLUXNET tower observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5a — Energy flux evaluation (uncalibrated)\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "plot_paths = symfluence.managers['reporting'].visualize_summa_outputs(\n",
    "    experiment_id=config.domain.experiment_id\n",
    ")\n",
    "\n",
    "flux_vars = ['scalarLatHeatTotal']\n",
    "found_plots = False\n",
    "\n",
    "for var in flux_vars:\n",
    "    if var in plot_paths:\n",
    "        plot_file = Path(plot_paths[var])\n",
    "        var_label = \"Latent Heat (ET)\" if \"Lat\" in var else \"Sensible Heat\"\n",
    "        print(f\"\\n{var_label} evaluation plot: {plot_file}\")\n",
    "        display(Image(filename=str(plot_file)))\n",
    "        found_plots = True\n",
    "\n",
    "if not found_plots:\n",
    "    print(\"Energy flux plots not found. Available plots:\")\n",
    "    for var, path in plot_paths.items():\n",
    "        print(f\"  - {var}: {path}\")\n",
    "\n",
    "print(\"\\nUncalibrated energy flux evaluation complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6 — Calibration (Differential Evolution)\n",
    "\n",
    "We calibrate SUMMA vegetation and canopy parameters against FLUXNET ET observations using **Differential Evolution (DE)**.\n",
    "\n",
    "### Why DE instead of DDS?\n",
    "\n",
    "- **DDS** starts from a single initial point and can fail immediately if that point produces NaN values or model failures.\n",
    "- **DE** evaluates an entire population each iteration, tolerating individual failures within a generation.\n",
    "\n",
    "### Calibration parameters\n",
    "\n",
    "| Parameter | Description |\n",
    "|-----------|-------------|\n",
    "| `minStomatalResistance` | Minimum stomatal resistance |\n",
    "| `cond2photo_slope` | Slope of the Ball–Berry stomatal conductance model |\n",
    "| `vcmax25_canopyTop` | Maximum rate of carboxylation at 25°C |\n",
    "| `jmax25_scale` | Scaling factor for electron transport rate |\n",
    "| `summerLAI` | Peak leaf area index |\n",
    "| `rootingDepth` | Maximum rooting depth |\n",
    "| `z0Canopy` | Canopy roughness length |\n",
    "| `windReductionParam` | Within-canopy wind reduction parameter |\n",
    "\n",
    "> **Note:** The configuration was set in Step 1a. If you need to change calibration settings, you must re-create the config and re-initialize SYMFLUENCE (all configs are frozen after creation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6a — Run calibration (DE + KGE on ET)\n",
    "\n",
    "print(f\"Algorithm:          {config.optimization.algorithm}\")\n",
    "print(f\"Metric:             {config.optimization.metric}\")\n",
    "print(f\"Target:             {config.optimization.target}\")\n",
    "print(f\"Iterations:         {config.optimization.iterations}\")\n",
    "print(f\"Population size:    {config.optimization.population_size}\")\n",
    "print(f\"Calibration period: {config.domain.calibration_period}\")\n",
    "print()\n",
    "\n",
    "results_file = symfluence.managers['optimization'].calibrate_model()\n",
    "print(f\"\\nCalibration results file: {results_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6b — Post-calibration visualization\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "plot_paths = symfluence.managers['reporting'].visualize_calibration_results(\n",
    "    experiment_id=config.domain.experiment_id\n",
    ")\n",
    "\n",
    "for plot_name, plot_path in plot_paths.items():\n",
    "    print(f\"\\n{plot_name}:\")\n",
    "    display(Image(filename=str(plot_path)))\n",
    "\n",
    "print(\"\\nPost-calibration visualization complete\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (symfluence-root)",
   "language": "python",
   "name": "symfluence-root"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
