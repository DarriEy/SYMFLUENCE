{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SYMFLUENCE Tutorial 02a â€” Basin-Scale Workflow (Bow River at Banff, Lumped)\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This tutorial demonstrates basin-scale hydrological modeling using SYMFLUENCE's lumped representation approach. Building on the point-scale workflows from Tutorials 01a and 01b, we now simulate streamflow from an entire watershedâ€”the Bow River at Banff in the Canadian Rockies.\n",
    "\n",
    "A lumped basin model treats the watershed as a single computational unit, spatially averaging all characteristics across the catchment. This simplified approach provides computational efficiency ideal for calibration and establishes baseline performance before adding spatial complexity.\n",
    "\n",
    "The **Bow River at Banff** watershed encompasses ~2,210 kmÂ² with elevations from 1,384 m to over 3,400 m. Water Survey of Canada station 05BB001 provides streamflow observations for model evaluation. This snow-dominated mountain system presents strong elevation gradients, complex snow dynamics, and pronounced spring freshet periods.\n",
    "\n",
    "Through this tutorial, you will see how the same SYMFLUENCE workflow scales seamlessly from point validation to basin prediction: configuration â†’ domain â†’ data â†’ model â†’ evaluation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 â€” Configuration\n",
    "\n",
    "We generate a basin-scale configuration that specifies the lumped representation approach, gauging station coordinates, and watershed delineation method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 â€” Create basin-scale configuration\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "\n",
    "\n",
    "from symfluence import SYMFLUENCE\n",
    "from symfluence.resources import get_config_template\n",
    "\n",
    "SYMFLUENCE_CODE_DIR = Path.cwd().resolve()\n",
    "# Load template configuration\n",
    "config_template = get_config_template()\n",
    "with open(config_template, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# === Modify key entries for Bow River lumped basin ===\n",
    "config['DOMAIN_NAME'] = 'Bow_at_Banff_lumped'\n",
    "config['EXPERIMENT_ID'] = 'run_1'\n",
    "\n",
    "# Gauging station coordinates (Banff WSC 05BB001)\n",
    "config['POUR_POINT_COORDS'] = '51.1722/-115.5717'\n",
    "\n",
    "# Lumped basin settings\n",
    "config['DOMAIN_DEFINITION_METHOD'] = 'lumped'\n",
    "config['DOMAIN_DISCRETIZATION'] = 'GRUs'\n",
    "\n",
    "# Model configuration\n",
    "config['HYDROLOGICAL_MODEL'] = 'SUMMA'\n",
    "config['ROUTING_MODEL'] = 'mizuRoute'\n",
    "\n",
    "# Temporal extent\n",
    "config['EXPERIMENT_TIME_START'] = '2004-01-01 01:00'\n",
    "config['EXPERIMENT_TIME_END'] = '2007-12-31 23:00'\n",
    "config['CALIBRATION_PERIOD'] = '2005-10-01, 2006-09-30'\n",
    "config['EVALUATION_PERIOD'] = '2006-10-01, 2007-09-30'\n",
    "config['SPINUP_PERIOD'] = '2004-01-01, 2005-09-30'\n",
    "\n",
    "# Streamflow observations\n",
    "config['STATION_ID'] = '05BB001'\n",
    "config['DOWNLOAD_WSC_DATA'] = True\n",
    "\n",
    "# Basic optimization knobs if desired (example only)\n",
    "config['PARAMS_TO_CALIBRATE'] = 'k_soil,theta_sat,aquiferBaseflowExp,aquiferBaseflowRate,qSurfScale,summerLAI,frozenPrecipMultip,Fcapil,tempCritRain,heightCanopyTop,heightCanopyBottom,windReductionParam,vGn_n'\n",
    "config['BASIN_PARAMS_TO_CALIBRATE'] = 'routingGammaScale,routingGammaShape'\n",
    "config['OPTIMIZATION_TARGET'] = 'streamflow'\n",
    "config['ITERATIVE_OPTIMIZATION_ALGORITHM'] = 'DDS'\n",
    "config['OPTIMIZATION_METRIC'] = 'KGE'\n",
    "config['CALIBRATION_TIMESTEP'] = 'hourly'  \n",
    "\n",
    "# Save configuration to current directory\n",
    "config_path = Path('./config_basin_lumped.yaml')\n",
    "with open(config_path, 'w') as f:\n",
    "    yaml.dump(config, f, default_flow_style=False, sort_keys=False)\n",
    "\n",
    "print(f\"âœ… Configuration saved: {config_path}\")\n",
    "\n",
    "# Initialize SYMFLUENCE\n",
    "symfluence = SYMFLUENCE(config_path)\n",
    "\n",
    "# Create project structure\n",
    "project_dir = symfluence.managers['project'].setup_project()\n",
    "pour_point_path = symfluence.managers['project'].create_pour_point()\n",
    "\n",
    "print(f\"âœ… Project structure created at: {project_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Step 1b â€” Download Example Data (Optional)\n\nIf you don't have access to MAF-supported HPC resources, you can download pre-processed example data from GitHub releases.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Step 1b â€” Download example data from GitHub releases (optional)\n\nimport shutil\nimport subprocess\nimport urllib.request\nfrom pathlib import Path\n\nSYMFLUENCE_CODE_DIR = Path.cwd().resolve()\n\n# Only download if data doesn't already exist\ndomain_data_dir = Path(config.get('SYMFLUENCE_DATA_DIR', str(SYMFLUENCE_CODE_DIR.parent / 'data' / 'SYMFLUENCE_data'))) / f\"domain_{config['DOMAIN_NAME']}\"\n\nif not domain_data_dir.exists() or not any(domain_data_dir.iterdir()):\n    print(\"ðŸ“¥ Downloading example data from GitHub releases...\")\n    release_tag = \"examples-data-v0.6.0\"\n    zip_filename = \"example_data_v0.6.0.zip\"\n    zip_file = Path(f\"/tmp/{zip_filename}\")\n    extract_dir = Path(\"/tmp/symfluence_example_data\")\n    \n    # Direct URL download (no gh CLI authentication required)\n    download_url = f\"https://github.com/DarriEy/SYMFLUENCE/releases/download/{release_tag}/{zip_filename}\"\n    \n    try:\n        print(f\"   Downloading from: {download_url}\")\n        urllib.request.urlretrieve(download_url, zip_file)\n        print(f\"âœ… Downloaded {zip_file}\")\n        \n        # Extract to temp directory first\n        extract_dir.mkdir(parents=True, exist_ok=True)\n        print(f\"ðŸ“¦ Extracting to temp directory...\")\n        subprocess.run([\"unzip\", \"-q\", \"-o\", str(zip_file), \"-d\", str(extract_dir)], check=True)\n        \n        # Copy domain directories to SYMFLUENCE_DATA_DIR\n        SYMFLUENCE_DATA_DIR = Path(config.get('SYMFLUENCE_DATA_DIR', str(SYMFLUENCE_CODE_DIR.parent / 'data' / 'SYMFLUENCE_data')))\n        SYMFLUENCE_DATA_DIR.mkdir(parents=True, exist_ok=True)\n        \n        # Find and copy all domain_* directories from extracted content\n        extracted_root = extract_dir / \"example_data_v0.6.0\"\n        if extracted_root.exists():\n            for domain_dir in extracted_root.glob(\"domain_*\"):\n                dest_dir = SYMFLUENCE_DATA_DIR / domain_dir.name\n                print(f\"   Copying {domain_dir.name} -> {dest_dir}\")\n                if dest_dir.exists():\n                    shutil.rmtree(dest_dir)\n                shutil.copytree(domain_dir, dest_dir)\n        \n        # Cleanup temp files\n        zip_file.unlink()\n        shutil.rmtree(extract_dir)\n        print(f\"âœ… Example data installed to {SYMFLUENCE_DATA_DIR}\")\n        \n    except urllib.error.HTTPError as e:\n        print(f\"âš ï¸  HTTP Error {e.code}: {e.reason}\")\n        print(\"   Download manually from: https://github.com/DarriEy/SYMFLUENCE/releases\")\n    except urllib.error.URLError as e:\n        print(f\"âš ï¸  Could not download: {e.reason}\")\n        print(\"   Download manually from: https://github.com/DarriEy/SYMFLUENCE/releases\")\n    except subprocess.CalledProcessError as e:\n        print(f\"âš ï¸  Extraction failed: {e}\")\nelse:\n    print(f\"âœ… Data already exists at: {domain_data_dir}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 â€” Domain definition\n",
    "\n",
    "For basin-scale modeling, we delineate the watershed boundary and create a single lumped HRU representing the entire catchment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2a â€” Geospatial attribute acquisition - **Only available through MAF supported HPCs**\n",
    "\n",
    "Acquires watershed attributes (elevation, land cover, soils) that will be spatially averaged for the lumped representation.\n",
    "\n",
    "- If using downloaded example data, copy attributes, forcing, and observation directories into the domain directory from Step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2a â€” Attribute acquisition\n",
    "# If using MAF supported HPC, uncomment the line below\n",
    "# symfluence.managers['data'].acquire_attributes()\n",
    "print(\"âœ… Attribute acquisition complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2b â€” Watershed delineation\n",
    "\n",
    "Delineates the basin boundary using automated watershed analysis from the pour point coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Step 2b â€” Watershed delineation\n",
    "watershed_path = symfluence.managers['domain'].define_domain()\n",
    "print(\"âœ… Watershed delineation complete\")\n",
    "print(f\"Watershed file: {watershed_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2c â€” Domain discretization\n",
    "\n",
    "Creates a single HRU that represents the lumped basin with spatially-averaged characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2c â€” Discretization (single lumped HRU)\n",
    "hru_path = symfluence.managers['domain'].discretize_domain()\n",
    "print(\"âœ… Domain discretization complete\")\n",
    "print(f\"HRU file: {hru_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2d â€” Visualization\n",
    "\n",
    "Quick visualization of the lumped basin boundary and pour point location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2d â€” Basin visualization\n",
    "\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load spatial data\n",
    "basin_path = project_dir / 'shapefiles' / 'river_basins' / f\"{config['DOMAIN_NAME']}_riverBasins_lumped.shp\"\n",
    "hru_file = project_dir / 'shapefiles' / 'catchment' / f\"{config['DOMAIN_NAME']}_HRUs_GRUs.shp\"\n",
    "\n",
    "watershed_gdf = gpd.read_file(str(basin_path))\n",
    "hru_gdf = gpd.read_file(str(hru_file))\n",
    "pour_point_gdf = gpd.read_file(pour_point_path)\n",
    "\n",
    "# Calculate area\n",
    "watershed_proj = watershed_gdf.to_crs('EPSG:32611')  # UTM Zone 11N\n",
    "area_km2 = watershed_proj.geometry.area.sum() / 1e6\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "watershed_gdf.boundary.plot(ax=ax, color='blue', linewidth=2, label='Watershed')\n",
    "hru_gdf.plot(ax=ax, facecolor='lightblue', edgecolor='blue', alpha=0.3)\n",
    "pour_point_gdf.plot(ax=ax, color='red', markersize=100, marker='*', label='Pour Point')\n",
    "\n",
    "ax.set_title(f'{config[\"DOMAIN_NAME\"]}\\n'\n",
    "             f'Area: {area_km2:.0f} kmÂ²', fontweight='bold')\n",
    "ax.legend()\n",
    "ax.set_xlabel('Longitude')\n",
    "ax.set_ylabel('Latitude')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Watershed area: {area_km2:.0f} kmÂ²\")\n",
    "print(f\"Number of HRUs: {len(hru_gdf)} (lumped)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 â€” Data acquisition and preprocessing\n",
    "\n",
    "Process streamflow observations, meteorological forcing data, and prepare model-ready inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3a â€” Streamflow observations\n",
    "\n",
    "Download and process Water Survey of Canada streamflow data for model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3a â€” Streamflow data processing\n",
    "# If using MAF supported HPC, uncomment the line below\n",
    "# symfluence.managers['data'].process_observed_data()\n",
    "print(\"âœ… Streamflow data processing complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3b â€” Meteorological forcing\n",
    "\n",
    "Acquire and spatially average meteorological forcing data over the basin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3b â€” Forcing acquisition\n",
    "# If using MAF supported HPC, uncomment the line below\n",
    "# symfluence.managers['data'].acquire_forcings()\n",
    "print(\"âœ… Forcing acquisition complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3c â€” Model-agnostic preprocessing\n",
    "\n",
    "Standardize variable names, units, and time steps for model consumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Step 3c â€” Model-agnostic preprocessing\n",
    "symfluence.managers['data'].run_model_agnostic_preprocessing()\n",
    "print(\"âœ… Model-agnostic preprocessing complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 â€” Model configuration and execution\n",
    "\n",
    "Configure SUMMA for basin-scale simulation with mizuRoute routing, then execute the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4a â€” SUMMA-specific preprocessing\n",
    "symfluence.managers['model'].preprocess_models()\n",
    "print(\"âœ… Model configuration complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4b â€” Model execution\n",
    "print(f\"Running {config['HYDROLOGICAL_MODEL']} with {config.get('ROUTING_MODEL', 'no routing')}...\")\n",
    "symfluence.managers['model'].run_models()\n",
    "print(\"âœ… Basin-scale simulation complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 â€” Streamflow evaluation\n",
    "\n",
    "Compare simulated and observed streamflow using standard hydrological metrics and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5 â€” Streamflow evaluation\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "\n",
    "# Load basin area from shapefile\n",
    "basin_path = project_dir / 'shapefiles' / 'river_basins' / f\"{config['DOMAIN_NAME']}_riverBasins_lumped.shp\"\n",
    "watershed_gdf = gpd.read_file(str(basin_path))\n",
    "watershed_proj = watershed_gdf.to_crs('EPSG:32611')  # UTM Zone 11N for accurate area calculation\n",
    "basin_area_m2 = watershed_proj.geometry.area.sum()  # Basin area in mÂ²\n",
    "basin_area_km2 = basin_area_m2 / 1e6  # Basin area in kmÂ²\n",
    "\n",
    "print(f\"Basin area: {basin_area_km2:.2f} kmÂ²\")\n",
    "\n",
    "# Load observed streamflow\n",
    "obs_path = project_dir / \"observations\" / \"streamflow\" / \"preprocessed\" / f\"{config['DOMAIN_NAME']}_streamflow_processed.csv\"\n",
    "obs_df = pd.read_csv(obs_path, parse_dates=['datetime'])\n",
    "obs_df.set_index('datetime', inplace=True)\n",
    "\n",
    "# Load simulated streamflow from SUMMA output\n",
    "routing_dir = project_dir / \"simulations\" / config['EXPERIMENT_ID'] / \"SUMMA\"\n",
    "sim_files = list(routing_dir.glob('*_timestep.nc'))\n",
    "if not sim_files:\n",
    "    raise FileNotFoundError(f\"No SUMMA output found in: {routing_dir}\")\n",
    "\n",
    "import xarray as xr\n",
    "sim_ds = xr.open_dataset(sim_files[0])\n",
    "sim_df = sim_ds['averageRoutedRunoff'].to_dataframe().reset_index()\n",
    "sim_df = sim_df.rename(columns={'time': 'datetime', 'averageRoutedRunoff': 'discharge_m_s'})\n",
    "sim_df.set_index('datetime', inplace=True)\n",
    "\n",
    "# Convert from m/s to mÂ³/s\n",
    "sim_df['discharge_sim'] = sim_df['discharge_m_s'] * basin_area_m2\n",
    "\n",
    "# Parse spinup period from config and exclude it\n",
    "spinup_end = pd.to_datetime(config['SPINUP_PERIOD'].split(',')[1].strip())\n",
    "print(f\"Excluding spinup period up to: {spinup_end}\")\n",
    "\n",
    "# Merge and align, then filter out spinup period\n",
    "eval_df = obs_df.join(sim_df[['discharge_sim']], how='inner')\n",
    "eval_df = eval_df[eval_df.index > spinup_end]  # Exclude spinup period\n",
    "\n",
    "obs_valid = eval_df['discharge_cms'].dropna()\n",
    "sim_valid = eval_df.loc[obs_valid.index, 'discharge_sim']\n",
    "\n",
    "print(f\"Evaluation period: {obs_valid.index[0]} to {obs_valid.index[-1]}\")\n",
    "print(f\"Number of timesteps: {len(obs_valid)}\")\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "def nse(obs, sim):\n",
    "    return float(1 - np.sum((obs - sim)**2) / np.sum((obs - obs.mean())**2))\n",
    "\n",
    "def kge(obs, sim):\n",
    "    r = obs.corr(sim)\n",
    "    alpha = sim.std() / obs.std()\n",
    "    beta = sim.mean() / obs.mean()\n",
    "    return float(1 - np.sqrt((r-1)**2 + (alpha-1)**2 + (beta-1)**2))\n",
    "\n",
    "def pbias(obs, sim):\n",
    "    return float(100 * (sim.sum() - obs.sum()) / obs.sum())\n",
    "\n",
    "metrics = {\n",
    "    'NSE': round(nse(obs_valid, sim_valid), 3),\n",
    "    'KGE': round(kge(obs_valid, sim_valid), 3),\n",
    "    'PBIAS': round(pbias(obs_valid, sim_valid), 1)\n",
    "}\n",
    "\n",
    "print(\"\\nPerformance Metrics:\")\n",
    "for k, v in metrics.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Time series (top left)\n",
    "axes[0, 0].plot(obs_valid.index, obs_valid.values, 'b-', label='Observed', linewidth=1.2, alpha=0.7)\n",
    "axes[0, 0].plot(sim_valid.index, sim_valid.values, 'r-', label='Simulated', linewidth=1.2, alpha=0.7)\n",
    "axes[0, 0].set_ylabel('Discharge (mÂ³/s)')\n",
    "axes[0, 0].set_title('Streamflow Time Series')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "axes[0, 0].text(0.02, 0.95, f\"NSE: {metrics['NSE']}\\nKGE: {metrics['KGE']}\\nBias: {metrics['PBIAS']}%\",\n",
    "                transform=axes[0, 0].transAxes, verticalalignment='top',\n",
    "                bbox=dict(facecolor='white', alpha=0.8), fontsize=9)\n",
    "\n",
    "# Scatter (top right)\n",
    "axes[0, 1].scatter(obs_valid, sim_valid, alpha=0.5, s=10)\n",
    "max_val = max(obs_valid.max(), sim_valid.max())\n",
    "axes[0, 1].plot([0, max_val], [0, max_val], 'k--', alpha=0.5)\n",
    "axes[0, 1].set_xlabel('Observed (mÂ³/s)')\n",
    "axes[0, 1].set_ylabel('Simulated (mÂ³/s)')\n",
    "axes[0, 1].set_title('Observed vs Simulated')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Monthly climatology (bottom left)\n",
    "monthly_obs = obs_valid.groupby(obs_valid.index.month).mean()\n",
    "monthly_sim = sim_valid.groupby(sim_valid.index.month).mean()\n",
    "month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n",
    "               'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "axes[1, 0].plot(monthly_obs.index, monthly_obs.values, 'b-o', label='Observed', markersize=6)\n",
    "axes[1, 0].plot(monthly_sim.index, monthly_sim.values, 'r-o', label='Simulated', markersize=6)\n",
    "axes[1, 0].set_xticks(range(1, 13))\n",
    "axes[1, 0].set_xticklabels(month_names)\n",
    "axes[1, 0].set_ylabel('Mean Discharge (mÂ³/s)')\n",
    "axes[1, 0].set_title('Seasonal Flow Regime')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Flow duration curve (bottom right)\n",
    "obs_sorted = obs_valid.sort_values(ascending=False)\n",
    "sim_sorted = sim_valid.sort_values(ascending=False)\n",
    "obs_ranks = np.arange(1., len(obs_sorted) + 1) / len(obs_sorted) * 100\n",
    "sim_ranks = np.arange(1., len(sim_sorted) + 1) / len(sim_sorted) * 100\n",
    "axes[1, 1].semilogy(obs_ranks, obs_sorted, 'b-', label='Observed', linewidth=2)\n",
    "axes[1, 1].semilogy(sim_ranks, sim_sorted, 'r-', label='Simulated', linewidth=2)\n",
    "axes[1, 1].set_xlabel('Exceedance Probability (%)')\n",
    "axes[1, 1].set_ylabel('Discharge (mÂ³/s)')\n",
    "axes[1, 1].set_title('Flow Duration Curve')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle(f'Lumped Basin Evaluation â€” {config[\"DOMAIN_NAME\"]}', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ… Streamflow evaluation complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5b â€” Run calibration \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_file = symfluence.managers['optimization'].calibrate_model()  \n",
    "print(\"Calibration results file:\", results_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (symfluence-root)",
   "language": "python",
   "name": "symfluence-root"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}