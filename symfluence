#!/bin/bash
#
# SYMFLUENCE Shell Wrapper with Python Environment Management
#
# Usage: symfluence [options]
# Example: symfluence --install
#
set -e

# Error handler for better debugging
error_handler() {
    local line=$1
    echo "Error: Script failed at line $line" >&2
    exit 1
}
trap 'error_handler $LINENO' ERR

# ----------------------------------------------------------------------
# Platform Detection
# ----------------------------------------------------------------------
detect_platform() {
    # Detect OS and set platform-specific variables
    case "$(uname -s)" in
        MINGW*|MSYS*|CYGWIN*)
            export PLATFORM="windows"
            export VENV_ACTIVATE="Scripts/activate"
            export VENV_BIN="Scripts"
            export EXE_EXT=".exe"
            ;;
        Darwin*)
            export PLATFORM="macos"
            export VENV_ACTIVATE="bin/activate"
            export VENV_BIN="bin"
            export EXE_EXT=""
            ;;
        Linux*)
            export PLATFORM="linux"
            export VENV_ACTIVATE="bin/activate"
            export VENV_BIN="bin"
            export EXE_EXT=""
            ;;
        *)
            print_warning "Unknown platform: $(uname -s), assuming Unix-like"
            export PLATFORM="unix"
            export VENV_ACTIVATE="bin/activate"
            export VENV_BIN="bin"
            export EXE_EXT=""
            ;;
    esac
}

# Detect platform before anything else
detect_platform

# ----------------------------------------------------------------------
# 2i2c / JupyterHub Cloud Detection
# ----------------------------------------------------------------------
IS_2I2C_ENVIRONMENT=false
CONDA_ENV_PATH=""

detect_2i2c_environment() {
    # Detect if running in 2i2c JupyterHub or similar restricted cloud environment
    # Indicators:
    #   1. /srv/conda/envs/notebook exists (2i2c standard)
    #   2. Home directory has limited quota (NFS mount)
    #   3. System conda gcc is broken (missing libgcc)
    #   4. User is 'jovyan' (JupyterHub default)

    if [[ -d "/srv/conda/envs/notebook" ]]; then
        IS_2I2C_ENVIRONMENT=true
        print_info "Detected 2i2c/JupyterHub cloud environment"
        return 0
    fi

    # Check for jovyan user with conda environment
    if [[ "$(whoami)" == "jovyan" && -n "${CONDA_DEFAULT_ENV:-}" ]]; then
        IS_2I2C_ENVIRONMENT=true
        print_info "Detected JupyterHub environment (jovyan user)"
        return 0
    fi

    return 1
}

setup_2i2c_conda_env() {
    # Set up a conda environment for 2i2c that:
    # 1. Uses /tmp for storage (overlay filesystem has space)
    # 2. Installs GDAL and rpy2 via conda (pre-built, no compilation)
    # 3. Sets system compilers to avoid broken conda gcc

    local env_path="${1:-/tmp/symfluence}"

    print_info "Setting up 2i2c-compatible conda environment at: $env_path"

    # Check if conda is available
    if ! command -v conda >/dev/null 2>&1; then
        print_error "conda not found - required for 2i2c environment setup"
        return 1
    fi

    # Create conda environment with pre-built packages
    # Include cmake, compilers (for ABI compatibility), openmpi (for TauDEM),
    # netcdf-fortran (for SUMMA/mizuRoute/FUSE builds), and m4/flex/bison (for rhessys)
    if [[ ! -d "$env_path" ]]; then
        print_info "Creating conda environment with GDAL, compilers, and build tools..."
        conda create -p "$env_path" python=3.11 gdal numpy rpy2 cmake compilers openmpi netcdf-fortran m4 flex bison -c conda-forge -y || {
            print_warning "Full conda env creation failed, trying minimal..."
            conda create -p "$env_path" python=3.11 gdal numpy cmake compilers openmpi netcdf-fortran m4 flex bison -c conda-forge -y || {
                print_error "Failed to create conda environment"
                return 1
            }
        }
    else
        print_info "Conda environment already exists at: $env_path"
        # Ensure cmake, compilers, netcdf-fortran, and build tools are installed in existing env
        print_info "Ensuring build dependencies are installed..."
        conda install -p "$env_path" cmake compilers openmpi netcdf-fortran m4 flex bison -c conda-forge -y 2>/dev/null || true
    fi

    # Activate the environment
    print_info "Activating conda environment..."
    source "$(conda info --base)/etc/profile.d/conda.sh"
    conda activate "$env_path" || {
        print_error "Failed to activate conda environment"
        return 1
    }

    # Use conda compilers for ABI compatibility with conda-forge libraries (GDAL, etc.)
    # The conda compilers package provides GCC that matches the ABI of conda-forge builds
    local conda_gcc="$env_path/bin/x86_64-conda-linux-gnu-gcc"
    local conda_gxx="$env_path/bin/x86_64-conda-linux-gnu-g++"
    local conda_fc="$env_path/bin/x86_64-conda-linux-gnu-gfortran"
    if [[ -x "$conda_gcc" && -x "$conda_gxx" ]]; then
        export CC="$conda_gcc"
        export CXX="$conda_gxx"
        print_info "Using conda compilers for ABI compatibility: CC=$CC"
    else
        # Fallback to system compilers if conda compilers not available
        print_warning "Conda compilers not found, falling back to system compilers"
        export CC=/usr/bin/gcc
        export CXX=/usr/bin/g++
        export SYMFLUENCE_USE_SYSTEM_COMPILERS=true
    fi
    # Set Fortran compiler if available
    if [[ -x "$conda_fc" ]]; then
        export FC="$conda_fc"
        print_info "Using conda Fortran compiler: FC=$FC"
    fi
    # Ensure conda bin is first in PATH for cmake, mpicc, etc.
    export PATH="$env_path/bin:$PATH"
    # Export CONDA_PREFIX so build scripts can find libraries
    export CONDA_PREFIX="$env_path"
    print_info "Prepended conda bin to PATH for build tools"

    CONDA_ENV_PATH="$env_path"
    VENV_BIN_PATH="$env_path/bin"

    print_success "2i2c conda environment ready"
    return 0
}

# ----------------------------------------------------------------------
# Configuration
# ----------------------------------------------------------------------
SCRIPT_NAME="symfluence"
PROJECT_MARKER="pyproject.toml"  # Used to detect SYMFLUENCE project directory
MIN_PYTHON_VERSION="3.11"
REQUIRED_PYTHON_VERSION="3.11"

# ----------------------------------------------------------------------
# Colors
# ----------------------------------------------------------------------
if [[ -t 1 ]]; then
    RED='\033[0;31m'
    GREEN='\033[0;32m'
    YELLOW='\033[1;33m'
    BLUE='\033[0;34m'
    NC='\033[0m'
else
    RED=''; GREEN=''; YELLOW=''; BLUE=''; NC='';
fi

print_error()   { echo -e "${RED}Error:${NC} $1" >&2; }
print_warning() { echo -e "${YELLOW}Warning:${NC} $1" >&2; }
print_info()    { echo -e "${BLUE}Info:${NC} $1"; }
print_success() { echo -e "${GREEN}Success:${NC} $1"; }

# ----------------------------------------------------------------------
# Default path helpers (derive from current working directory)
# ----------------------------------------------------------------------
_is_placeholder_or_empty() {
  # Return 0 (true) if empty or looks like a placeholder path
  local v="${1:-}"
  [[ -z "$v" || "$v" == "default" || "$v" == "DEFAULT" || \
     "$v" == "/path" || "$v" == "/path/" || "$v" == "/path/to" || \
     "$v" == "/path/to/" || "$v" == *"/path/to/"* || "$v" == */path/to/* ]]
}

set_default_symfluence_paths() {
  # Be safe if script runs with `set -u`
  : "${SYMFLUENCE_CODE_DIR:=}"
  : "${SYMFLUENCE_DATA_DIR:=}"

  # Prefer repo root if available; otherwise use PWD
  local repo_root
  if repo_root="$(git rev-parse --show-toplevel 2>/dev/null)"; then
    :
  else
    repo_root="$PWD"
  fi

  # code dir = repo root; data dir = parent-of-repo/SYMFLUENCE_data
  local pwd_code_dir="$repo_root"
  local pwd_data_dir
  pwd_data_dir="$(cd "$repo_root/.." && pwd)/SYMFLUENCE_data"

  if _is_placeholder_or_empty "${SYMFLUENCE_CODE_DIR}"; then
    export SYMFLUENCE_CODE_DIR="$pwd_code_dir"
    { command -v print_info >/dev/null 2>&1 && print_info "Set SYMFLUENCE_CODE_DIR to $SYMFLUENCE_CODE_DIR"; } || echo "Set SYMFLUENCE_CODE_DIR to $SYMFLUENCE_CODE_DIR"
  fi

  if _is_placeholder_or_empty "${SYMFLUENCE_DATA_DIR}"; then
    export SYMFLUENCE_DATA_DIR="$pwd_data_dir"
    mkdir -p "$SYMFLUENCE_DATA_DIR"
    { command -v print_info >/dev/null 2>&1 && print_info "Set SYMFLUENCE_DATA_DIR to $SYMFLUENCE_DATA_DIR"; } || echo "Set SYMFLUENCE_DATA_DIR to $SYMFLUENCE_DATA_DIR"
  fi
}

resolve_python_scripts_path() {
  local py_bin="${1:-python}"
  local fallback_prefix="${2:-}"
  local scripts_dir=""

  scripts_dir=$("$py_bin" - <<'PY'
import sysconfig
print(sysconfig.get_path("scripts"))
PY
) 2>/dev/null || true

  if [[ -n "$scripts_dir" && -d "$scripts_dir" ]]; then
      VENV_BIN_PATH="$scripts_dir"
  elif [[ -n "${CONDA_PREFIX:-}" && -d "${CONDA_PREFIX}/${VENV_BIN}" ]]; then
      VENV_BIN_PATH="${CONDA_PREFIX}/${VENV_BIN}"
  elif [[ -n "$fallback_prefix" && -d "${fallback_prefix}/${VENV_BIN}" ]]; then
      VENV_BIN_PATH="${fallback_prefix}/${VENV_BIN}"
  fi
}

find_cli_candidate() {
    local base="$1"
    shift || true
    for candidate in "${base}${EXE_EXT}" "${base}.exe" "${base}.bat" "${base}-script.py" "$base"; do
        if [[ -x "$candidate" ]]; then
            echo "$candidate"
            return 0
        fi
    done
    return 1
}


# ----------------------------------------------------------------------
# R / rpy2 environment helpers (enhanced)
# ----------------------------------------------------------------------
setup_r_environment() {
    print_info "Auto-detecting R environment..."

    if ! command -v R >/dev/null 2>&1; then
        print_error "R is not available in PATH"
        print_info  "Please load R module before running installation, e.g.:"
        print_info  "  module load r/4.5.0  # or your platform's R module"
        return 1
    fi

    local r_version
    r_version=$(R --version | head -1 || true)
    [[ -n "$r_version" ]] && print_success "Found R: $r_version"

    if [[ -z "$R_HOME" ]]; then
        print_info "R_HOME not set, auto-detecting..."
        local detected_r_home
        detected_r_home=$(R RHOME 2>/dev/null || true)
        if [[ -n "$detected_r_home" && -d "$detected_r_home" ]]; then
            export R_HOME="$detected_r_home"
            print_success "Set R_HOME=$R_HOME"
        else
            print_warning "Could not detect R_HOME"
            print_info    "You may need to set it manually: export R_HOME=\$(R RHOME)"
        fi
    else
        print_success "R_HOME already set: $R_HOME"
    fi

    if [[ -n "$R_HOME" && -d "$R_HOME/lib" ]]; then
        if [[ ":$LD_LIBRARY_PATH:" != *":$R_HOME/lib:"* ]]; then
            export LD_LIBRARY_PATH="$R_HOME/lib:${LD_LIBRARY_PATH:-}"
            print_info "Added $R_HOME/lib to LD_LIBRARY_PATH"
        fi
    fi

    setup_rpy2_compiler_flags
    check_rpy2_dependencies
    return 0
}

setup_rpy2_compiler_flags() {
    print_info "Setting up compiler environment for rpy2..."
    local lib_paths=()
    if [[ -n "$LD_LIBRARY_PATH" ]]; then IFS=':' read -ra _p <<< "$LD_LIBRARY_PATH"; lib_paths+=("${_p[@]}"); fi
    if [[ -n "$LIBRARY_PATH" ]]; then IFS=':' read -ra _p <<< "$LIBRARY_PATH"; lib_paths+=("${_p[@]}"); fi

    local potential_lib_dirs=("/usr/lib64" "/usr/lib" "/lib64" "/lib")
    for d in "${potential_lib_dirs[@]}"; do [[ -d "$d" ]] && lib_paths+=("$d"); done

    for prog in xz bzip2; do
        if command -v "$prog" >/dev/null 2>&1; then
            local p dir
            p=$(dirname "$(command -v "$prog")")
            for dir in ../lib ../lib64; do
                [[ -d "$p/$dir" ]] && lib_paths+=("$(cd "$p/$dir" && pwd)")
            done
        fi
    done

    local ldflags="" cflags="" seen=()
    for path in "${lib_paths[@]}"; do
        if [[ -d "$path" && ! " ${seen[*]} " =~ " $path " ]]; then
            seen+=("$path")
            ldflags="$ldflags -L$path"
            local inc="${path/lib/include}"
            [[ -d "$inc" ]] && cflags="$cflags -I$inc"
        fi
    done
    [[ -n "$ldflags" ]] && export LDFLAGS="$ldflags ${LDFLAGS:-}" && print_info "Set LDFLAGS for rpy2 compilation"
    [[ -n "$cflags" ]] && export CFLAGS="$cflags ${CFLAGS:-}" && print_info "Set CFLAGS for rpy2 compilation"
}

check_rpy2_dependencies() {
    print_info "Checking for libraries required by rpy2..."
    local required_libs=("lzma" "bz2" "z" "tirpc")
    local missing=() found=()

    if command -v ldconfig >/dev/null 2>&1; then
        for lib in "${required_libs[@]}"; do
            ldconfig -p 2>/dev/null | grep -q "lib${lib}\.so" && found+=("$lib") || missing+=("$lib")
        done
    else
        local search=("/usr/lib" "/usr/lib64" "/lib" "/lib64")
        [[ -n "$LD_LIBRARY_PATH" ]] && IFS=':' read -ra _a <<< "$LD_LIBRARY_PATH" && search+=("${_a[@]}")
        [[ -n "$LIBRARY_PATH" ]] && IFS=':' read -ra _b <<< "$LIBRARY_PATH" && search+=("${_b[@]}")
        for lib in "${required_libs[@]}"; do
            local ok=false
            for p in "${search[@]}"; do
                [[ -f "$p/lib${lib}.so" || -f "$p/lib${lib}.a" ]] && ok=true && break
            done
            $ok && found+=("$lib") || missing+=("$lib")
        done
    fi

    [[ ${#found[@]} -gt 0 ]] && print_success "Found libraries: ${found[*]}"
    if [[ ${#missing[@]} -gt 0 ]]; then
        print_warning "Could not detect libraries: ${missing[*]}"
        print_info "Load modules providing these before install (examples):"
        for lib in "${missing[@]}"; do
            case "$lib" in
                lzma)  print_info "  module load xz" ;;
                bz2)   print_info "  module load bzip2" ;;
                tirpc) print_info "  module load libtirpc" ;;
                z)     print_info "  module load zlib" ;;
            esac
        done
        read -p "Press Enter to continue anyway, or Ctrl+C to abort..." _tmp || true
    fi
}

install_gdal_python() {
    # Check if GDAL Python bindings are already installed
    if python -c "from osgeo import gdal" >/dev/null 2>&1; then
        local installed_version
        installed_version=$(python -c "from osgeo import gdal; print(gdal.__version__)" 2>/dev/null || echo "unknown")
        print_success "GDAL Python bindings already installed (version: $installed_version)"
        return 0
    fi

    print_info "Detecting system GDAL version..."
    local v=""

    # Try gdal-config first
    if command -v gdal-config >/dev/null 2>&1; then
        v=$(gdal-config --version 2>/dev/null || true)
    fi

    # Fallback to GDAL_VERSION environment variable (set by Windows conda setup)
    if [[ -z "$v" && -n "${GDAL_VERSION:-}" ]]; then
        v="$GDAL_VERSION"
        print_info "Using GDAL version from environment: $v"
    fi

    # If still no version, skip
    if [[ -z "$v" ]]; then
        print_warning "Could not detect GDAL version (gdal-config not found and GDAL_VERSION not set)"
        return 0
    fi

    print_success "Found system GDAL: $v"
    print_info "Installing matching GDAL Python bindings..."

    # Try exact version first
    if python -m pip install "GDAL==$v" 2>/dev/null; then
        print_success "Installed GDAL Python bindings $v"
        return 0
    fi

    # Extract version components, handling potential suffixes like 3.12.0_1
    local GDAL_MAJOR GDAL_MINOR GDAL_PATCH NEXT_PATCH
    GDAL_MAJOR=$(echo "$v" | cut -d. -f1)
    GDAL_MINOR=$(echo "$v" | cut -d. -f2)
    GDAL_PATCH=$(echo "$v" | cut -d. -f3 | cut -d_ -f1)
    NEXT_PATCH=$((GDAL_PATCH + 1))

    # Try version range that allows same patch + post-releases, but not next patch
    # E.g., for GDAL 3.12.0: allows 3.12.0, 3.12.0.post1, etc. but not 3.12.1
    print_info "Trying GDAL>=${GDAL_MAJOR}.${GDAL_MINOR}.${GDAL_PATCH},<${GDAL_MAJOR}.${GDAL_MINOR}.${NEXT_PATCH}..."
    if python -m pip install "GDAL>=${GDAL_MAJOR}.${GDAL_MINOR}.${GDAL_PATCH},<${GDAL_MAJOR}.${GDAL_MINOR}.${NEXT_PATCH}"; then
        print_success "Installed GDAL Python bindings compatible with $v"
        return 0
    fi

    print_error "Failed to install GDAL Python bindings. You may try: python -m pip install GDAL==$v"
    return 1
}

install_python_requirements() {
    local req="$1"; local use_break="${2:-true}"
    [[ ! -f "$req" ]] && { print_error "Requirements file not found: $req"; return 1; }

    local pip_flags=""
    if [[ -z "$VIRTUAL_ENV" && -z "$CONDA_DEFAULT_ENV" && "$use_break" == "true" ]]; then
        pip_flags="--break-system-packages"
    fi

    print_info "Installing Python dependencies from: $req"
    local tmp="${req}.tmp"

    # Filter out GDAL and rpy2 from the pass, we’ll handle them explicitly
    grep -v -iE "^(GDAL|rpy2)([>=<~!]|$)" "$req" > "$tmp" 2>/dev/null || cp "$req" "$tmp"
    local gdal_filtered=false rpy2_filtered=false
    grep -qiE "^GDAL([>=<~!]|$)" "$req" && gdal_filtered=true
    grep -qiE "^rpy2([>=<~!]|$)" "$req" && rpy2_filtered=true

    # Try API mode first
    [[ -z "$RPY2_CFFI_MODE" ]] && export RPY2_CFFI_MODE=API

    if python -m pip install -r "$tmp" $pip_flags; then
        rm -f "$tmp"
        [[ "$gdal_filtered" == "true" ]] && install_gdal_python || true
        if [[ "$rpy2_filtered" == "true" ]]; then
            print_info "Attempting rpy2 install (RPY2_CFFI_MODE=$RPY2_CFFI_MODE)..."
            python -m pip install rpy2 $pip_flags || print_warning "rpy2 install failed (continuing)"
        fi
        command -v gdal-config >/dev/null 2>&1 && install_gdal_python || true
        print_success "Core dependencies installed"
        return 0
    fi

    # Retry with ABI mode
    print_warning "Install failed with RPY2_CFFI_MODE=$RPY2_CFFI_MODE; retrying with ABI..."
    export RPY2_CFFI_MODE=ABI
    if python -m pip install -r "$tmp" $pip_flags; then
        rm -f "$tmp"
        [[ "$gdal_filtered" == "true" ]] && install_gdal_python || true
        if [[ "$rpy2_filtered" == "true" ]]; then
            print_info "Attempting rpy2 install in ABI mode..."
            python -m pip install rpy2 $pip_flags || print_warning "rpy2 install failed (continuing)"
        fi
        command -v gdal-config >/dev/null 2>&1 && install_gdal_python || true
        print_success "Dependencies installed in ABI mode"
        return 0
    fi

    rm -f "$tmp"
    print_error "Failed to install dependencies"
    return 1
}

_is_bad_path() {
    # returns 0 (true) if the value is empty/placeholder or the directory doesn't exist
    local v="$1"
    [[ -z "$v" || "$v" == "default" || "$v" == "DEFAULT" || "$v" == "/path" || "$v" == "/path/" || "$v" == "/path/to" || "$v" == "/path/to/" || "$v" == *"/path/to/"* || ! -d "$v" ]]
}

update_config_paths_in_yaml() {
    # $1: path to YAML config (e.g., ./config.yaml)
    local cfg="$1"
    local CODE="${SYMFLUENCE_CODE_DIR:-$PWD}"
    # Use SYMFLUENCE_DATA_DIR if set, otherwise fall back to PWD/../SYMFLUENCE_data
    local DATA
    if [[ -n "${SYMFLUENCE_DATA_DIR:-}" && -d "${SYMFLUENCE_DATA_DIR}" ]]; then
        DATA="${SYMFLUENCE_DATA_DIR}"
    elif [[ -n "${SYMFLUENCE_DATA:-}" && -d "${SYMFLUENCE_DATA}" ]]; then
        DATA="${SYMFLUENCE_DATA}"
    else
        local DATA_BASE="$PWD/../SYMFLUENCE_data"; mkdir -p "$DATA_BASE"; DATA="$(cd "$DATA_BASE" && pwd)"
    fi

    # Ensure file exists
    if [[ ! -f "$cfg" ]]; then
        mkdir -p "$(dirname "$cfg")"
        printf "SYMFLUENCE_CODE_DIR: %s\nSYMFLUENCE_DATA_DIR: %s\n" "$CODE" "$DATA" > "$cfg"
        print_info "Created $cfg with default SYMFLUENCE_* paths"
        return 0
    fi

    # Try yq first (cleanest). Fallback to sed/awk if yq is missing.
    if command -v yq >/dev/null 2>&1; then
        # Read current values (empty string if missing)
        local cur_code cur_data
        cur_code="$(yq -r '.SYMFLUENCE_CODE_DIR // ""' "$cfg" 2>/dev/null)"
        cur_data="$(yq -r '.SYMFLUENCE_DATA_DIR // ""' "$cfg" 2>/dev/null)"

        local set_code=0 set_data=0
        _is_bad_path "$cur_code"; set_code=$?
        _is_bad_path "$cur_data"; set_data=$?

        # _is_bad_path returns 0 when bad → we should set it
        if [[ $set_code -eq 0 ]]; then
            SYM_CODE_NEW="$CODE" yq -i '.SYMFLUENCE_CODE_DIR = strenv(SYM_CODE_NEW)' "$cfg"
            print_info "Updated SYMFLUENCE_CODE_DIR -> $CODE in $cfg"
        fi
        if [[ $set_data -eq 0 ]]; then
            SYM_DATA_NEW="$DATA" yq -i '.SYMFLUENCE_DATA_DIR = strenv(SYM_DATA_NEW)' "$cfg"
            print_info "Updated SYMFLUENCE_DATA_DIR -> $DATA in $cfg"
        fi
        return 0
    fi

    # ---- Fallback without yq (portable; works on macOS/BSD + GNU) ----
    # Read current values (simple top-level key parse)
    local cur_code cur_data
    cur_code="$(grep -E '^[[:space:]]*SYMFLUENCE_CODE_DIR:' "$cfg" | head -1 | sed 's/^[^:]*:[[:space:]]*//')"
    cur_data="$(grep -E '^[[:space:]]*SYMFLUENCE_DATA_DIR:' "$cfg" | head -1 | sed 's/^[^:]*:[[:space:]]*//')"

    local need_code=1 need_data=1
    _is_bad_path "$cur_code" || need_code=0
    _is_bad_path "$cur_data" || need_data=0

    # If neither needs change, we're done
    if [[ $need_code -eq 0 && $need_data -eq 0 ]]; then
        return 0
    fi

    # Make a backup and write a temp file portably (macOS sed -i is quirky)
    local tmp="${cfg}.tmp.$$"
    cp "$cfg" "${cfg}.bak"

    # Start from original and rewrite lines if present; if absent, append at end.
    awk -v code="$CODE" -v data="$DATA" -v need_code="$need_code" -v need_data="$need_data" '
        BEGIN { saw_code=0; saw_data=0; }
        /^[[:space:]]*SYMFLUENCE_CODE_DIR:/ {
            saw_code=1;
            if (need_code==1) { print "SYMFLUENCE_CODE_DIR: " code; next }
        }
        /^[[:space:]]*SYMFLUENCE_DATA_DIR:/ {
            saw_data=1;
            if (need_data==1) { print "SYMFLUENCE_DATA_DIR: " data; next }
        }
        { print }
        END {
            if (saw_code==0) print "SYMFLUENCE_CODE_DIR: " code;
            if (saw_data==0) print "SYMFLUENCE_DATA_DIR: " data;
        }
    ' "$cfg" > "$tmp" && mv "$tmp" "$cfg"

    if [[ $need_code -eq 1 ]]; then print_info "Updated SYMFLUENCE_CODE_DIR -> $CODE in $cfg"; fi
    if [[ $need_data -eq 1 ]]; then print_info "Updated SYMFLUENCE_DATA_DIR -> $DATA in $cfg"; fi
}

# ----------------------------------------------------------------------
# Locate SYMFLUENCE project directory (looks for pyproject.toml)
# ----------------------------------------------------------------------
find_project_dir() {
    local script_dir
    script_dir=$(dirname "$(readlink -f "${BASH_SOURCE[0]}" 2>/dev/null || echo "${BASH_SOURCE[0]}")")

    local search_paths=(
        "${script_dir}"
        "${script_dir}/.."
        "."
        "${PWD}"
    )

    if [[ -n "${SYMFLUENCE_CODE_DIR}" ]]; then
        search_paths=("${SYMFLUENCE_CODE_DIR}" "${search_paths[@]}")
    fi

    local dir
    for dir in "${search_paths[@]}"; do
        if [[ -f "$dir/${PROJECT_MARKER}" ]]; then
            # Resolve to absolute path
            echo "$(cd "$dir" && pwd)"
            return 0
        fi
    done
    return 1
}

# ----------------------------------------------------------------------
# Python finder (prefers 3.11–3.13; rejects 3.14+)
# ----------------------------------------------------------------------
find_python() {
    # If SYMFLUENCE_PYTHON is set, use it first
    if [[ -n "${SYMFLUENCE_PYTHON:-}" ]]; then
        if command -v "$SYMFLUENCE_PYTHON" >/dev/null 2>&1; then
            echo "$SYMFLUENCE_PYTHON"
            return 0
        fi
    fi

    local python_candidates=("python3.11" "python3.12" "python3.13" "python3" "python")
    local cmd version major minor
    for cmd in "${python_candidates[@]}"; do
        if command -v "$cmd" >/dev/null 2>&1; then
            version=$($cmd -c "import sys; print(f'{sys.version_info.major}.{sys.version_info.minor}')" 2>/dev/null || true)
            if [[ -n "$version" ]]; then
                major=${version%%.*}
                minor=${version#*.}
                if [[ "$major" -eq 3 && "$minor" -gt 13 ]]; then
                    continue
                fi
                if $cmd -c "import sys; current=tuple(map(int,'$version'.split('.'))); required=tuple(map(int,'$MIN_PYTHON_VERSION'.split('.'))); import sys; sys.exit(0 if current>=required else 1)" 2>/dev/null; then
                    echo "$cmd"
                    return 0
                fi
            fi
        fi
    done
    return 1
}

# ----------------------------------------------------------------------
# Virtual env activator (clears PYTHONPATH)
# ----------------------------------------------------------------------
check_virtual_env() {
    local project_dir="$1"
    local venv_paths=(
        "${project_dir}/venv"
        "${project_dir}/.venv"
        "${project_dir}/env"
        "${project_dir}/.env"
    )

    if [[ -n "${VIRTUAL_ENV}" ]]; then
        print_info "Using active virtual environment: ${VIRTUAL_ENV}"
        return 0
    fi

    local venv_path
    for venv_path in "${venv_paths[@]}"; do
        if [[ -f "${venv_path}/${VENV_ACTIVATE}" ]]; then
            print_info "Found virtual environment: ${venv_path}"
            print_info "Activating virtual environment..."
            export PYTHONPATH="${PYTHONPATH-}"
            source "${venv_path}/${VENV_ACTIVATE}"
            if [[ -n "$PYTHONPATH" ]]; then
                export PYTHONPATH=""
            fi
            return 0
        fi
    done
    return 0
}

# ----------------------------------------------------------------------
# Wrapper UX
# ----------------------------------------------------------------------
show_symfluence_help() {
    cat << EOF
${SCRIPT_NAME}: SYMFLUENCE project directory not found

This wrapper looks for ${PROJECT_MARKER} in:
  - Current directory and parent directories
  - \$SYMFLUENCE_CODE_DIR

Fix:
  1) Run this from the SYMFLUENCE project dir, or
  2) export SYMFLUENCE_CODE_DIR=/path/to/symfluence

Docs: https://github.com/DarriEy/symfluence
EOF
}

handle_wrapper_flags() {
    case "$1" in
        --wrapper-help)
            cat << EOF
SYMFLUENCE Shell Wrapper Help

Wrapper-only options:
  --wrapper-help     Show this help message
  --wrapper-info     Show wrapper and environment information
  --wrapper-debug    Run wrapper in debug mode
  --install          Set up Python environment and install external tools

All other options are passed to the symfluence CLI (see 'symfluence --help').
EOF
            exit 0
            ;;
        --wrapper-info)
            local project_dir
            project_dir=$(find_project_dir || true)
            local python_cmd
            python_cmd=$(find_python || true)

            echo "SYMFLUENCE Wrapper Information"
            echo "=============================="
            echo "Wrapper script: $(readlink -f "${BASH_SOURCE[0]}" 2>/dev/null || echo "${BASH_SOURCE[0]}")"
            echo "Project directory: ${project_dir:-'Not found'}"
            echo "Python command: ${python_cmd:-'Not found'}"
            echo "Python version: $(${python_cmd} --version 2>/dev/null || echo 'Unknown')"
            echo "Virtual env: ${VIRTUAL_ENV:-'None active'}"
            echo "Working directory: $(pwd)"
            echo "SYMFLUENCE_CODE_DIR: ${SYMFLUENCE_CODE_DIR:-'Not set'}"
            exit 0
            ;;
        --wrapper-debug) set -x; return 1 ;;
        --install)       return 1 ;;
        *)               return 1 ;;
    esac
}

# ----------------------------------------------------------------------
# Windows-specific setup (conda/micromamba)
# ----------------------------------------------------------------------
setup_windows_dependencies() {
    if [[ "$PLATFORM" != "windows" ]]; then
        return 0
    fi

    print_info "Setting up Windows dependencies..."

    # Check if conda/mamba is available
    if command -v mamba >/dev/null 2>&1; then
        print_info "Using mamba for package management"
        CONDA_CMD="mamba"
    elif command -v conda >/dev/null 2>&1; then
        print_info "Using conda for package management"
        CONDA_CMD="conda"
    elif command -v micromamba >/dev/null 2>&1; then
        print_info "Using micromamba for package management"
        CONDA_CMD="micromamba"
    else
        print_warning "No conda/mamba/micromamba found in PATH"
        print_info "Attempting to use system conda if available..."

        # Try common conda locations
        for conda_path in \
            "$HOME/miniconda3/condabin/conda" \
            "$HOME/anaconda3/condabin/conda" \
            "/c/ProgramData/Miniconda3/condabin/conda" \
            "/c/ProgramData/Anaconda3/condabin/conda"; do
            if [[ -f "$conda_path" ]]; then
                print_info "Found conda at: $conda_path"
                export PATH="$(dirname "$conda_path"):$PATH"
                CONDA_CMD="conda"
                break
            fi
        done

        if [[ -z "${CONDA_CMD:-}" ]]; then
            print_warning "Conda not found. Skipping Windows-specific dependencies."
            print_info "Manual installation required: gdal, netcdf4, hdf5, cmake, ninja"
            print_info "You can install via: conda install -c conda-forge gdal netcdf4 hdf5 cmake ninja"
            return 0
        fi
    fi

    # Install essential Windows dependencies via conda
    # Install C libraries and Python bindings - pip build from source often fails on Windows
    print_info "Installing Windows build dependencies via ${CONDA_CMD}..."
    $CONDA_CMD install -c conda-forge -y \
        cmake \
        ninja \
        libgdal=3.11 \
        gdal \
        netcdf4 \
        hdf5 \
        || print_warning "Some conda packages may have failed to install"

    # Add conda Library paths to environment for Windows
    if [[ -d "$CONDA/Library" ]]; then
        export PATH="$CONDA/Library/bin:$PATH"
        export PATH="$CONDA/Library/mingw-w64/bin:$PATH"
        export GDAL_DATA="$CONDA/Library/share/gdal"
        export PROJ_LIB="$CONDA/Library/share/proj"

        # Set compiler flags for pip to find GDAL headers/libs
        export INCLUDE="$CONDA/Library/include${INCLUDE:+;$INCLUDE}"
        export LIB="$CONDA/Library/lib${LIB:+;$LIB}"

        # Set GDAL version for pip (matching conda libgdal version)
        # libgdal=3.11 means any 3.11.x version
        export GDAL_VERSION="3.11.4"

        # Set UTF-8 encoding for Python to handle emoji output on Windows
        export PYTHONIOENCODING="utf-8"

        print_info "Added conda Library paths to environment"
        print_info "GDAL version for pip: $GDAL_VERSION"
    fi

    print_success "Windows dependencies setup complete"
}

# ----------------------------------------------------------------------
# Main
# ----------------------------------------------------------------------
main() {
    local run_install=false

    # Parse wrapper flags
    local arg
    for arg in "$@"; do
        if handle_wrapper_flags "$arg"; then
            return 0
        fi
        [[ "$arg" == "--install" ]] && run_install=true
    done

    # Set sane defaults for SYMFLUENCE_* based on working dir
    #set_default_symfluence_paths

    # Update config.yaml with PWD-based paths if current values are bad/missing (optional)
    local CONFIG_YAML="./config.yaml"
    if [[ -f "$CONFIG_YAML" ]] && declare -f update_config_paths_in_yaml >/dev/null 2>&1; then
        update_config_paths_in_yaml "$CONFIG_YAML" || {
            print_warning "Config update failed, continuing without update"
        }
    fi

    # Find SYMFLUENCE project directory
    local symfluence_dir
    if ! symfluence_dir=$(find_project_dir); then
        print_error "SYMFLUENCE project directory not found"
        echo
        show_symfluence_help
        exit 1
    fi

    # Find Python interpreter
    local python_cmd
    if ! python_cmd=$(find_python); then
        print_error "Python ${MIN_PYTHON_VERSION}+ not found"
        print_info  "Please install or load Python ${MIN_PYTHON_VERSION} or later"
        exit 1
    fi

    # ---------------- Installation mode (enhanced) ----------------
    if [[ "$run_install" == "true" ]]; then
        print_info "SYMFLUENCE installation mode"
        print_info "Platform: $PLATFORM"
        echo ""
        print_info "Prerequisites:"
        print_info "  - Python 3.11+"
        print_info "  - R (optional, for rpy2 features)"
        print_info "  - Required libs/modules (xz, bzip2, libtirpc, zlib, netcdf, gdal, etc.)"
        echo ""

        # Setup Windows dependencies if on Windows
        if [[ "$PLATFORM" == "windows" ]]; then
            setup_windows_dependencies || {
                print_warning "Windows dependency setup had issues, continuing..."
            }
        fi

        # Detect 2i2c/JupyterHub environment
        detect_2i2c_environment || true

        # Create venv if needed, unless in a conda env or explicitly disabled
        local venv_path="${symfluence_dir}/venv"

        if [[ "$IS_2I2C_ENVIRONMENT" == "true" ]]; then
            # 2i2c environments need special handling:
            # - Use /tmp for conda env (home often has quota limits)
            # - Install GDAL/rpy2 via conda (avoid compilation issues)
            # - Use system compilers (conda gcc often broken)
            print_info "Using 2i2c-optimized installation path"
            setup_2i2c_conda_env "/tmp/symfluence" || {
                print_error "2i2c environment setup failed"
                print_info "You may need to manually run:"
                print_info "  conda create -p /tmp/symfluence python=3.11 gdal numpy -c conda-forge -y"
                print_info "  conda activate /tmp/symfluence"
                print_info "  pip install -e . --no-deps"
                exit 1
            }
            python_cmd="python"
        elif [[ -n "${CONDA_DEFAULT_ENV:-}" && "${CONDA_DEFAULT_ENV}" != "base" ]]; then
            print_info "Using active Conda environment: ${CONDA_DEFAULT_ENV}"
            VENV_BIN_PATH=$(dirname "$(which python)")
        elif [[ "${SYMFLUENCE_NO_VENV:-}" == "true" ]]; then
            print_info "Virtual environment creation disabled by SYMFLUENCE_NO_VENV"
            VENV_BIN_PATH=$(dirname "$(which python)")
        elif [[ ! -d "$venv_path" ]]; then
            print_info "Creating Python virtual environment..."
            if ! $python_cmd -m venv "$venv_path"; then
                print_error "Failed to create virtual environment"
                exit 1
            fi
            source "${venv_path}/${VENV_ACTIVATE}"
            VENV_BIN_PATH="${venv_path}/${VENV_BIN}"
        else
            # Already exists, just activate
            source "${venv_path}/${VENV_ACTIVATE}"
            VENV_BIN_PATH="${venv_path}/${VENV_BIN}"
        fi

        # Clear PYTHONPATH to isolate environment
        if [[ -n "$PYTHONPATH" ]]; then
            print_warning "Clearing PYTHONPATH to isolate venv"
            export PYTHONPATH=""
        fi
        # Make clearing persistent for future activations
        if ! grep -q "Clear PYTHONPATH" "${venv_path}/${VENV_ACTIVATE}" 2>/dev/null; then
            if [[ -w "${venv_path}/${VENV_ACTIVATE}" ]]; then
                cat >> "${venv_path}/${VENV_ACTIVATE}" << 'EOF'

# Clear PYTHONPATH to prevent system package conflicts
if [ -n "$PYTHONPATH" ]; then
    export _OLD_SYMFLUENCE_PYTHONPATH="$PYTHONPATH"
    unset PYTHONPATH
fi
EOF
            else
                print_warning "Cannot modify activate script (read-only), PYTHONPATH cleared for this session only"
            fi
        fi

        resolve_python_scripts_path "$python_cmd" "$venv_path"

        print_info "Upgrading pip and preparing environment..."
        # Always use python -m pip to ensure correct Python version is used
        $python_cmd -m pip install --upgrade pip || print_warning "pip upgrade failed"

        setup_r_environment || print_warning "R setup had issues, continuing..."

        # Generate requirements.txt from pyproject.toml (source of truth)
        local req_file="${symfluence_dir}/requirements.txt"
        local pyproj_path="${symfluence_dir}/pyproject.toml"
        if [[ "$PLATFORM" == "windows" ]]; then
            pyproj_path=$(cygpath -w "$pyproj_path")
        fi

        if [[ -f "${symfluence_dir}/pyproject.toml" ]]; then
            print_info "Generating requirements.txt from pyproject.toml..."
            $python_cmd -c "
import sys
try:
    import tomllib
except ImportError:
    import tomli as tomllib

with open('${pyproj_path}', 'rb') as f:
    data = tomllib.load(f)
deps = data.get('project', {}).get('dependencies', [])
if deps:
    lines = ['# Auto-generated from pyproject.toml', '']
    lines.extend(deps)
    with open('${req_file}', 'w') as out:
        out.write('\n'.join(lines) + '\n')
    print(f'Generated {len(deps)} dependencies')
else:
    sys.exit(1)
" || print_warning "Could not auto-generate requirements.txt"
        fi

        if [[ -f "$req_file" ]]; then
            if [[ "$IS_2I2C_ENVIRONMENT" == "true" ]]; then
                # 2i2c: GDAL and rpy2 already installed via conda, skip them in pip
                print_info "Installing pip dependencies (excluding conda-provided packages)..."
                local filtered_req="/tmp/requirements_filtered.txt"
                grep -viE "^(gdal|rpy2)" "$req_file" > "$filtered_req" 2>/dev/null || cp "$req_file" "$filtered_req"
                python -m pip install -r "$filtered_req" || {
                    print_error "Dependency installation failed"; exit 1;
                }
                rm -f "$filtered_req"
            else
                # Use enhanced installer that handles rpy2/GDAL specially
                install_python_requirements "$req_file" "false" || {
                    print_error "Dependency installation failed"; exit 1;
                }
            fi
        else
            print_warning "requirements.txt not found - installing a minimal set..."
            $python_cmd -m pip install numpy pandas geopandas rasterio netCDF4 PyYAML shapely rasterstats psutil || {
                print_error "Failed to install minimal dependencies"; exit 1;
            }
            if [[ "$IS_2I2C_ENVIRONMENT" != "true" ]]; then
                print_info "Attempting to install rpy2 (optional)..."
                $python_cmd -m pip install rpy2 || print_warning "rpy2 installation failed (continuing)"
                command -v gdal-config >/dev/null 2>&1 && install_gdal_python || true
            fi
        fi

        print_success "Python environment setup complete"

        # Install SYMFLUENCE package in editable mode
        print_info "Installing SYMFLUENCE package..."
        # Use --no-deps because we already installed them from requirements.txt
        # This prevents pip from trying to build GDAL from source on Windows
        python -m pip install -e . --no-deps || {
            print_error "SYMFLUENCE package installation failed"
            exit 1
        }
        # Ensure rich is installed (needed for CLI console output)
        python -m pip install "rich>=13.0.0" --quiet || true
        print_success "SYMFLUENCE package installed"

        # External tools - use installed symfluence command with full path
        # (bash may have cached the wrapper path before pip created the venv CLI)
        cd "$symfluence_dir"
        local venv_cli_base="${VENV_BIN_PATH}/symfluence"
        local venv_cli
        if ! venv_cli=$(find_cli_candidate "$venv_cli_base"); then
            print_error "CLI not found at expected path: ${venv_cli_base}${EXE_EXT}"
            exit 1
        fi
        # Re-export 2i2c compiler settings before binary install (ensures they persist)
        if [[ "$IS_2I2C_ENVIRONMENT" == "true" ]]; then
            print_info "Ensuring 2i2c compiler settings for binary builds..."
            local conda_env="${CONDA_ENV_PATH:-/tmp/symfluence}"
            local conda_gcc="${conda_env}/bin/x86_64-conda-linux-gnu-gcc"
            local conda_gxx="${conda_env}/bin/x86_64-conda-linux-gnu-g++"
            local conda_fc="${conda_env}/bin/x86_64-conda-linux-gnu-gfortran"
            if [[ -x "$conda_gcc" && -x "$conda_gxx" ]]; then
                export CC="$conda_gcc"
                export CXX="$conda_gxx"
                print_info "Using conda compilers: CC=$CC"
            else
                export CC=/usr/bin/gcc
                export CXX=/usr/bin/g++
                export SYMFLUENCE_USE_SYSTEM_COMPILERS=true
                print_warning "Falling back to system compilers"
            fi
            if [[ -x "$conda_fc" ]]; then
                export FC="$conda_fc"
                print_info "Using conda Fortran: FC=$FC"
            fi
            export PATH="${conda_env}/bin:$PATH"
            # Ensure CONDA_PREFIX is set for build scripts to find libraries
            export CONDA_PREFIX="${conda_env}"
        fi

        print_info "Installing external tools..."
        "$venv_cli" binary install || {
            print_error "External tools installation failed"
            exit 1
        }
        print_info "Validating installation..."
        "$venv_cli" binary validate || {
            print_error "Binary validation failed"
            exit 1
        }

        echo ""
        print_success "Installation complete!"
        if [[ "$IS_2I2C_ENVIRONMENT" == "true" ]]; then
            print_info "To use SYMFLUENCE: conda activate ${CONDA_ENV_PATH:-/tmp/symfluence}"
            print_warning "Note: /tmp environment won't persist across server restarts"
            print_info "Re-run './symfluence --install' after JupyterHub restarts"
        else
            print_info "To use SYMFLUENCE: source ${venv_path}/${VENV_ACTIVATE}"
        fi
        exit 0
    fi

    # ---------------- Normal execution ----------------
    # Look for installed symfluence CLI in venv
    local symfluence_cli=""

    if symfluence_cli=$(find_cli_candidate "${symfluence_dir}/venv/${VENV_BIN}/symfluence"); then
        print_info "Using venv CLI: ${symfluence_cli}"
    elif symfluence_cli=$(find_cli_candidate "${symfluence_dir}/.venv/${VENV_BIN}/symfluence"); then
        print_info "Using .venv CLI: ${symfluence_cli}"
    elif command -v symfluence >/dev/null 2>&1; then
        symfluence_cli="$(command -v symfluence)"
        print_info "Using system CLI: ${symfluence_cli}"
    fi

    if [[ -z "$symfluence_cli" ]]; then
        print_error "SYMFLUENCE CLI not found"
        print_info "Run: ./symfluence --install"
        exit 1
    fi

    # Change to SYMFLUENCE directory
    if [[ "$symfluence_dir" != "." && -d "$symfluence_dir" ]]; then
        cd "$symfluence_dir" || {
            print_error "Failed to change to directory: $symfluence_dir"
            exit 1
        }
        print_info "Changed directory to: $(pwd)"
    fi

    # Debug output
    print_info "Launching SYMFLUENCE..."
    print_info "  CLI: ${symfluence_cli}"
    print_info "  Args: $*"
    print_info "  Working dir: $(pwd)"

    # Execute (replace current process with CLI)
    exec "$symfluence_cli" "$@"
}

# Trap signals and run
trap 'echo -e "\nInterrupted"; exit 130' INT TERM
main "$@"
